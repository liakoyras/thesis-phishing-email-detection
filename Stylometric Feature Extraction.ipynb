{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1802f673",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "pd.options.display.max_colwidth = 160\n",
    "\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk import sent_tokenize\n",
    "\n",
    "import features as util\n",
    "from features import language_tool_python\n",
    "from preprocessing import tokenize, impute_mean\n",
    "from raw_utils import save_to_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b9f5f8",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2af55909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path\n",
    "cwd = os.getcwd()\n",
    "csv_path = os.path.join(cwd, 'data/csv/')\n",
    "\n",
    "train_text = ['train_balanced_text.csv', 'train_imbalanced_text.csv']\n",
    "test_text = ['test_balanced_text.csv', 'test_imbalanced_text.csv']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ac3b15",
   "metadata": {},
   "source": [
    "#### Email Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b48a6eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_balanced_text = pd.read_csv(os.path.join(csv_path, train_text[0]), index_col=0)\n",
    "test_balanced_text = pd.read_csv(os.path.join(csv_path, test_text[0]), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e93526e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imbalanced_text = pd.read_csv(os.path.join(csv_path, train_text[1]), index_col=0)\n",
    "test_imbalanced_text = pd.read_csv(os.path.join(csv_path, test_text[1]), index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27680c4a",
   "metadata": {},
   "source": [
    "After the preprocessing, the data look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f271a3a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>body</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2377</td>\n",
       "      <td>please print\\n----- Forwarded by Steven J Kean/NA/Enron on 10/16/2000 10:27 AM -----\\n\\n\\tCynthia Sandherr\\n\\t10/12/2000 07:43 PM\\n\\t\\t \\n\\t\\t To: Thomas E ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>592</td>\n",
       "      <td>Server Message \\n  \\n\\n \\n   Dear &lt;emailaddress&gt;  Our record indicates that you recently made a request to deactivate email And this request will be process...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1049</td>\n",
       "      <td>Please see the attached articles:</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1087</td>\n",
       "      <td>Please Click Here&lt;urladdress&gt; to Update e-mail Password\\n\\n\\n\\nIT Security immediately/\\n\\n________________________________\\nSEED IS PROUD TO BE A 21st CENT...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>725</td>\n",
       "      <td>Wednesday afternoon Febuary 6th, 2002, the Enron building experienced a brief power outage.  The building is powered by one of two Reliant circuits.  Yester...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  \\\n",
       "0  2377   \n",
       "1   592   \n",
       "2  1049   \n",
       "3  1087   \n",
       "4   725   \n",
       "\n",
       "                                                                                                                                                              body  \\\n",
       "0  please print\\n----- Forwarded by Steven J Kean/NA/Enron on 10/16/2000 10:27 AM -----\\n\\n\\tCynthia Sandherr\\n\\t10/12/2000 07:43 PM\\n\\t\\t \\n\\t\\t To: Thomas E ...   \n",
       "1  Server Message \\n  \\n\\n \\n   Dear <emailaddress>  Our record indicates that you recently made a request to deactivate email And this request will be process...   \n",
       "2                                                                                                                                Please see the attached articles:   \n",
       "3  Please Click Here<urladdress> to Update e-mail Password\\n\\n\\n\\nIT Security immediately/\\n\\n________________________________\\nSEED IS PROUD TO BE A 21st CENT...   \n",
       "4  Wednesday afternoon Febuary 6th, 2002, the Enron building experienced a brief power outage.  The building is powered by one of two Reliant circuits.  Yester...   \n",
       "\n",
       "   class  \n",
       "0  False  \n",
       "1   True  \n",
       "2  False  \n",
       "3   True  \n",
       "4  False  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_balanced_text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948acf1c",
   "metadata": {},
   "source": [
    "#### Email Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e28707c",
   "metadata": {},
   "source": [
    "Since the .csv files with the already tokenized emails have been subject to further preprocessing like lemmatization and stopword removal, a simple tokenization (at word and sentence level) will also be run here for the purposes of feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c970d2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_balanced_text['tokens'] = train_balanced_text['body'].apply(tokenize)\n",
    "test_balanced_text['tokens'] = test_balanced_text['body'].apply(tokenize)\n",
    "train_imbalanced_text['tokens'] = train_imbalanced_text['body'].apply(tokenize)\n",
    "test_imbalanced_text['tokens'] = test_imbalanced_text['body'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e357899",
   "metadata": {},
   "source": [
    "Note that for the sentence-level tokenization, `nltk.sent_tokenization` is used, so any sentences separated by a newline without punctuation will be considered simply as wrapped text, and not new, different sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2a3ad87",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_balanced_text['sentences'] = train_balanced_text['body'].apply(sent_tokenize)\n",
    "test_balanced_text['sentences'] = test_balanced_text['body'].apply(sent_tokenize)\n",
    "train_imbalanced_text['sentences'] = train_imbalanced_text['body'].apply(sent_tokenize)\n",
    "test_imbalanced_text['sentences'] = test_imbalanced_text['body'].apply(sent_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fdcf9b",
   "metadata": {},
   "source": [
    "# Stylometric Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374f9c06",
   "metadata": {},
   "source": [
    "Useful markers of whether an email is phishing or not should stem from the writing style of the author.<br>\n",
    "With this in mind, several features that have been previously used in the literature will be extracted, in order to be compared and combined with the text-only baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe758756",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_balanced_style = train_balanced_text[['id', 'class']].copy()\n",
    "test_balanced_style = test_balanced_text[['id', 'class']].copy()\n",
    "train_imbalanced_style = train_imbalanced_text[['id', 'class']].copy()\n",
    "test_imbalanced_style = test_imbalanced_text[['id', 'class']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad6019e",
   "metadata": {},
   "source": [
    "### Simple Counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bbfcb7",
   "metadata": {},
   "source": [
    "The simplest kind of features would be simple counts of various parts of the emails, like characters and words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1f771bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_balanced_style['num_chars'] = train_balanced_text['body'].apply(util.count_chars)\n",
    "train_balanced_style['num_newlines'] = train_balanced_text['body'].apply(util.count_newlines)\n",
    "train_balanced_style['num_special_chars'] = train_balanced_text['body'].apply(util.count_special_chars)\n",
    "train_balanced_style['num_words'] = train_balanced_text['tokens'].apply(util.count_words)\n",
    "train_balanced_style['num_unique_words'] = train_balanced_text['tokens'].apply(util.count_unique_words)\n",
    "train_balanced_style['sentences'] = train_balanced_text['sentences'].apply(util.count_sentences)\n",
    "train_balanced_style[['num_sentences', 'num_upper_sentences', 'num_lower_sentences']] = pd.DataFrame(train_balanced_style['sentences'].tolist(), index=train_balanced_style.index)\n",
    "train_balanced_style = train_balanced_style.drop('sentences', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98b11e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_balanced_style['num_chars'] = test_balanced_text['body'].apply(util.count_chars)\n",
    "test_balanced_style['num_newlines'] = test_balanced_text['body'].apply(util.count_newlines)\n",
    "test_balanced_style['num_special_chars'] = test_balanced_text['body'].apply(util.count_special_chars)\n",
    "test_balanced_style['num_words'] = test_balanced_text['tokens'].apply(util.count_words)\n",
    "test_balanced_style['num_unique_words'] = test_balanced_text['tokens'].apply(util.count_unique_words)\n",
    "test_balanced_style['sentences'] = test_balanced_text['sentences'].apply(util.count_sentences)\n",
    "test_balanced_style[['num_sentences', 'num_upper_sentences', 'num_lower_sentences']] = pd.DataFrame(test_balanced_style['sentences'].tolist(), index=test_balanced_style.index)\n",
    "test_balanced_style = test_balanced_style.drop('sentences', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "058d0e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imbalanced_style['num_chars'] = train_imbalanced_text['body'].apply(util.count_chars)\n",
    "train_imbalanced_style['num_newlines'] = train_imbalanced_text['body'].apply(util.count_newlines)\n",
    "train_imbalanced_style['num_special_chars'] = train_imbalanced_text['body'].apply(util.count_special_chars)\n",
    "train_imbalanced_style['num_words'] = train_imbalanced_text['tokens'].apply(util.count_words)\n",
    "train_imbalanced_style['num_unique_words'] = train_imbalanced_text['tokens'].apply(util.count_unique_words)\n",
    "train_imbalanced_style['sentences'] = train_imbalanced_text['sentences'].apply(util.count_sentences)\n",
    "train_imbalanced_style[['num_sentences', 'num_upper_sentences', 'num_lower_sentences']] = pd.DataFrame(train_imbalanced_style['sentences'].tolist(), index=train_imbalanced_style.index)\n",
    "train_imbalanced_style = train_imbalanced_style.drop('sentences', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88450b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imbalanced_style['num_chars'] = test_imbalanced_text['body'].apply(util.count_chars)\n",
    "test_imbalanced_style['num_newlines'] = test_imbalanced_text['body'].apply(util.count_newlines)\n",
    "test_imbalanced_style['num_special_chars'] = test_imbalanced_text['body'].apply(util.count_special_chars)\n",
    "test_imbalanced_style['num_words'] = test_imbalanced_text['tokens'].apply(util.count_words)\n",
    "test_imbalanced_style['num_unique_words'] = test_imbalanced_text['tokens'].apply(util.count_unique_words)\n",
    "test_imbalanced_style['sentences'] = test_imbalanced_text['sentences'].apply(util.count_sentences)\n",
    "test_imbalanced_style[['num_sentences', 'num_upper_sentences', 'num_lower_sentences']] = pd.DataFrame(test_imbalanced_style['sentences'].tolist(), index=test_imbalanced_style.index)\n",
    "test_imbalanced_style = test_imbalanced_style.drop('sentences', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefcdc73",
   "metadata": {},
   "source": [
    "## Word Size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d89241",
   "metadata": {},
   "source": [
    "Another category of features are those that related to the size of words, like the average size and counts or frequencies of smaller or bigger words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9586db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_balanced_style['avg_word_size'] = train_balanced_text['tokens'].apply(util.average_word_length)\n",
    "train_balanced_style['small_words'] = train_balanced_text['tokens'].apply(util.small_words)\n",
    "train_balanced_style[['num_small_words', 'freq_small_words']] = pd.DataFrame(train_balanced_style['small_words'].tolist(), index=train_balanced_style.index)\n",
    "train_balanced_style['big_words'] = train_balanced_text['tokens'].apply(util.big_words)\n",
    "train_balanced_style[['num_big_words', 'freq_big_words']] = pd.DataFrame(train_balanced_style['big_words'].tolist(), index=train_balanced_style.index)\n",
    "train_balanced_style['huge_words'] = train_balanced_text['tokens'].apply(util.huge_words)\n",
    "train_balanced_style[['num_huge_words', 'freq_huge_words']] = pd.DataFrame(train_balanced_style['huge_words'].tolist(), index=train_balanced_style.index)\n",
    "train_balanced_style = train_balanced_style.drop(['small_words', 'big_words', 'huge_words'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1bbded68",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_balanced_style['avg_word_size'] = test_balanced_text['tokens'].apply(util.average_word_length)\n",
    "test_balanced_style['small_words'] = test_balanced_text['tokens'].apply(util.small_words)\n",
    "test_balanced_style[['num_small_words', 'freq_small_words']] = pd.DataFrame(test_balanced_style['small_words'].tolist(), index=test_balanced_style.index)\n",
    "test_balanced_style['big_words'] = test_balanced_text['tokens'].apply(util.big_words)\n",
    "test_balanced_style[['num_big_words', 'freq_big_words']] = pd.DataFrame(test_balanced_style['big_words'].tolist(), index=test_balanced_style.index)\n",
    "test_balanced_style['huge_words'] = test_balanced_text['tokens'].apply(util.huge_words)\n",
    "test_balanced_style[['num_huge_words', 'freq_huge_words']] = pd.DataFrame(test_balanced_style['huge_words'].tolist(), index=test_balanced_style.index)\n",
    "test_balanced_style = test_balanced_style.drop(['small_words', 'big_words', 'huge_words'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54525efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imbalanced_style['avg_word_size'] = train_imbalanced_text['tokens'].apply(util.average_word_length)\n",
    "train_imbalanced_style['small_words'] = train_imbalanced_text['tokens'].apply(util.small_words)\n",
    "train_imbalanced_style[['num_small_words', 'freq_small_words']] = pd.DataFrame(train_imbalanced_style['small_words'].tolist(), index=train_imbalanced_style.index)\n",
    "train_imbalanced_style['big_words'] = train_imbalanced_text['tokens'].apply(util.big_words)\n",
    "train_imbalanced_style[['num_big_words', 'freq_big_words']] = pd.DataFrame(train_imbalanced_style['big_words'].tolist(), index=train_imbalanced_style.index)\n",
    "train_imbalanced_style['huge_words'] = train_imbalanced_text['tokens'].apply(util.huge_words)\n",
    "train_imbalanced_style[['num_huge_words', 'freq_huge_words']] = pd.DataFrame(train_imbalanced_style['huge_words'].tolist(), index=train_imbalanced_style.index)\n",
    "train_imbalanced_style = train_imbalanced_style.drop(['small_words', 'big_words', 'huge_words'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44b712d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imbalanced_style['avg_word_size'] = test_imbalanced_text['tokens'].apply(util.average_word_length)\n",
    "test_imbalanced_style['small_words'] = test_imbalanced_text['tokens'].apply(util.small_words)\n",
    "test_imbalanced_style[['num_small_words', 'freq_small_words']] = pd.DataFrame(test_imbalanced_style['small_words'].tolist(), index=test_imbalanced_style.index)\n",
    "test_imbalanced_style['big_words'] = test_imbalanced_text['tokens'].apply(util.big_words)\n",
    "test_imbalanced_style[['num_big_words', 'freq_big_words']] = pd.DataFrame(test_imbalanced_style['big_words'].tolist(), index=test_imbalanced_style.index)\n",
    "test_imbalanced_style['huge_words'] = test_imbalanced_text['tokens'].apply(util.huge_words)\n",
    "test_imbalanced_style[['num_huge_words', 'freq_huge_words']] = pd.DataFrame(test_imbalanced_style['huge_words'].tolist(), index=test_imbalanced_style.index)\n",
    "test_imbalanced_style = test_imbalanced_style.drop(['small_words', 'big_words', 'huge_words'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a91765",
   "metadata": {},
   "source": [
    "## Sentence Size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d0aedb",
   "metadata": {},
   "source": [
    "Another set of features could be related to various simple statistics about the size of a sentence, using both characters and words as a unit of size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02da8f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_balanced_style['avg_sent_size'] = train_balanced_text['sentences'].apply(util.average_sentence_length)\n",
    "train_balanced_style[['avg_sentence_chars', 'avg_sentence_words']] = pd.DataFrame(train_balanced_style['avg_sent_size'].tolist(), index=train_balanced_style.index)\n",
    "train_balanced_style['std_sent_size'] = train_balanced_text['sentences'].apply(util.std_sentence_length)\n",
    "train_balanced_style[['std_sentence_chars', 'std_sentence_words']] = pd.DataFrame(train_balanced_style['std_sent_size'].tolist(), index=train_balanced_style.index)\n",
    "train_balanced_style['min_sent_size'] = train_balanced_text['sentences'].apply(util.min_sentence_length)\n",
    "train_balanced_style[['min_sentence_chars', 'min_sentence_words']] = pd.DataFrame(train_balanced_style['min_sent_size'].tolist(), index=train_balanced_style.index)\n",
    "train_balanced_style['max_sent_size'] = train_balanced_text['sentences'].apply(util.max_sentence_length)\n",
    "train_balanced_style[['max_sentence_chars', 'max_sentence_words']] = pd.DataFrame(train_balanced_style['max_sent_size'].tolist(), index=train_balanced_style.index)\n",
    "train_balanced_style = train_balanced_style.drop(['avg_sent_size', 'std_sent_size', 'min_sent_size', 'max_sent_size'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "073706f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_balanced_style['avg_sent_size'] = test_balanced_text['sentences'].apply(util.average_sentence_length)\n",
    "test_balanced_style[['avg_sentence_chars', 'avg_sentence_words']] = pd.DataFrame(test_balanced_style['avg_sent_size'].tolist(), index=test_balanced_style.index)\n",
    "test_balanced_style['std_sent_size'] = test_balanced_text['sentences'].apply(util.std_sentence_length)\n",
    "test_balanced_style[['std_sentence_chars', 'std_sentence_words']] = pd.DataFrame(test_balanced_style['std_sent_size'].tolist(), index=test_balanced_style.index)\n",
    "test_balanced_style['min_sent_size'] = test_balanced_text['sentences'].apply(util.min_sentence_length)\n",
    "test_balanced_style[['min_sentence_chars', 'min_sentence_words']] = pd.DataFrame(test_balanced_style['min_sent_size'].tolist(), index=test_balanced_style.index)\n",
    "test_balanced_style['max_sent_size'] = test_balanced_text['sentences'].apply(util.max_sentence_length)\n",
    "test_balanced_style[['max_sentence_chars', 'max_sentence_words']] = pd.DataFrame(test_balanced_style['max_sent_size'].tolist(), index=test_balanced_style.index)\n",
    "test_balanced_style = test_balanced_style.drop(['avg_sent_size', 'std_sent_size', 'min_sent_size', 'max_sent_size'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f66ec9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imbalanced_style['avg_sent_size'] = train_imbalanced_text['sentences'].apply(util.average_sentence_length)\n",
    "train_imbalanced_style[['avg_sentence_chars', 'avg_sentence_words']] = pd.DataFrame(train_imbalanced_style['avg_sent_size'].tolist(), index=train_imbalanced_style.index)\n",
    "train_imbalanced_style['std_sent_size'] = train_imbalanced_text['sentences'].apply(util.std_sentence_length)\n",
    "train_imbalanced_style[['std_sentence_chars', 'std_sentence_words']] = pd.DataFrame(train_imbalanced_style['std_sent_size'].tolist(), index=train_imbalanced_style.index)\n",
    "train_imbalanced_style['min_sent_size'] = train_imbalanced_text['sentences'].apply(util.min_sentence_length)\n",
    "train_imbalanced_style[['min_sentence_chars', 'min_sentence_words']] = pd.DataFrame(train_imbalanced_style['min_sent_size'].tolist(), index=train_imbalanced_style.index)\n",
    "train_imbalanced_style['max_sent_size'] = train_imbalanced_text['sentences'].apply(util.max_sentence_length)\n",
    "train_imbalanced_style[['max_sentence_chars', 'max_sentence_words']] = pd.DataFrame(train_imbalanced_style['max_sent_size'].tolist(), index=train_imbalanced_style.index)\n",
    "train_imbalanced_style = train_imbalanced_style.drop(['avg_sent_size', 'std_sent_size', 'min_sent_size', 'max_sent_size'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20e5e04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imbalanced_style['avg_sent_size'] = test_imbalanced_text['sentences'].apply(util.average_sentence_length)\n",
    "test_imbalanced_style[['avg_sentence_chars', 'avg_sentence_words']] = pd.DataFrame(test_imbalanced_style['avg_sent_size'].tolist(), index=test_imbalanced_style.index)\n",
    "test_imbalanced_style['std_sent_size'] = test_imbalanced_text['sentences'].apply(util.std_sentence_length)\n",
    "test_imbalanced_style[['std_sentence_chars', 'std_sentence_words']] = pd.DataFrame(test_imbalanced_style['std_sent_size'].tolist(), index=test_imbalanced_style.index)\n",
    "test_imbalanced_style['min_sent_size'] = test_imbalanced_text['sentences'].apply(util.min_sentence_length)\n",
    "test_imbalanced_style[['min_sentence_chars', 'min_sentence_words']] = pd.DataFrame(test_imbalanced_style['min_sent_size'].tolist(), index=test_imbalanced_style.index)\n",
    "test_imbalanced_style['max_sent_size'] = test_imbalanced_text['sentences'].apply(util.max_sentence_length)\n",
    "test_imbalanced_style[['max_sentence_chars', 'max_sentence_words']] = pd.DataFrame(test_imbalanced_style['max_sent_size'].tolist(), index=test_imbalanced_style.index)\n",
    "test_imbalanced_style = test_imbalanced_style.drop(['avg_sent_size', 'std_sent_size', 'min_sent_size', 'max_sent_size'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff0f7d4",
   "metadata": {},
   "source": [
    "## Ratios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f4baee",
   "metadata": {},
   "source": [
    "There are also the ratios of various text elements (like specific characters to total characters or words to characters) that can be used as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df606b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_balanced_style['words_to_chars'] = util.series_ratio(train_balanced_style['num_words'], train_balanced_style['num_chars'])\n",
    "train_balanced_style['unique_words_to_words'] = util.series_ratio(train_balanced_style['num_unique_words'], train_balanced_style['num_words'])\n",
    "train_balanced_style['special_chars_to_chars'] = util.series_ratio(train_balanced_style['num_special_chars'], train_balanced_style['num_chars'])\n",
    "\n",
    "train_balanced_style['dots_to_chars'] = train_balanced_text['body'].apply(util.character_to_chars, character='.')\n",
    "train_balanced_style['commas_to_chars'] = train_balanced_text['body'].apply(util.character_to_chars, character=',')\n",
    "train_balanced_style['questionmark_to_chars'] = train_balanced_text['body'].apply(util.character_to_chars, character='?')\n",
    "train_balanced_style['exclamationmark_to_chars'] = train_balanced_text['body'].apply(util.character_to_chars, character='!')\n",
    "\n",
    "train_balanced_style['chars_to_lines'] = train_balanced_text['body'].apply(util.chars_to_lines)\n",
    "train_balanced_style['alpha_tokens_to_words'] = train_balanced_text['body'].apply(util.alpha_tokens_ratio)\n",
    "\n",
    "train_balanced_style['words_to_lines'] = train_balanced_style['words_to_chars'] * train_balanced_style['chars_to_lines']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5c11d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_balanced_style['words_to_chars'] = util.series_ratio(test_balanced_style['num_words'], test_balanced_style['num_chars'])\n",
    "test_balanced_style['unique_words_to_words'] = util.series_ratio(test_balanced_style['num_unique_words'], test_balanced_style['num_words'])\n",
    "test_balanced_style['special_chars_to_chars'] = util.series_ratio(test_balanced_style['num_special_chars'], test_balanced_style['num_chars'])\n",
    "\n",
    "test_balanced_style['dots_to_chars'] = test_balanced_text['body'].apply(util.character_to_chars, character='.')\n",
    "test_balanced_style['commas_to_chars'] = test_balanced_text['body'].apply(util.character_to_chars, character=',')\n",
    "test_balanced_style['questionmark_to_chars'] = test_balanced_text['body'].apply(util.character_to_chars, character='?')\n",
    "test_balanced_style['exclamationmark_to_chars'] = test_balanced_text['body'].apply(util.character_to_chars, character='!')\n",
    "\n",
    "test_balanced_style['chars_to_lines'] = test_balanced_text['body'].apply(util.chars_to_lines)\n",
    "test_balanced_style['alpha_tokens_to_words'] = test_balanced_text['body'].apply(util.alpha_tokens_ratio)\n",
    "\n",
    "test_balanced_style['words_to_lines'] = test_balanced_style['words_to_chars'] * test_balanced_style['chars_to_lines']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29cce630",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imbalanced_style['words_to_chars'] = util.series_ratio(train_imbalanced_style['num_words'], train_imbalanced_style['num_chars'])\n",
    "train_imbalanced_style['unique_words_to_words'] = util.series_ratio(train_imbalanced_style['num_unique_words'], train_imbalanced_style['num_words'])\n",
    "train_imbalanced_style['special_chars_to_chars'] = util.series_ratio(train_imbalanced_style['num_special_chars'], train_imbalanced_style['num_chars'])\n",
    "\n",
    "train_imbalanced_style['dots_to_chars'] = train_imbalanced_text['body'].apply(util.character_to_chars, character='.')\n",
    "train_imbalanced_style['commas_to_chars'] = train_imbalanced_text['body'].apply(util.character_to_chars, character=',')\n",
    "train_imbalanced_style['questionmark_to_chars'] = train_imbalanced_text['body'].apply(util.character_to_chars, character='?')\n",
    "train_imbalanced_style['exclamationmark_to_chars'] = train_imbalanced_text['body'].apply(util.character_to_chars, character='!')\n",
    "\n",
    "train_imbalanced_style['chars_to_lines'] = train_imbalanced_text['body'].apply(util.chars_to_lines)\n",
    "train_imbalanced_style['alpha_tokens_to_words'] = train_imbalanced_text['body'].apply(util.alpha_tokens_ratio)\n",
    "\n",
    "train_imbalanced_style['words_to_lines'] = train_imbalanced_style['words_to_chars'] * train_imbalanced_style['chars_to_lines']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac7736d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imbalanced_style['words_to_chars'] = util.series_ratio(test_imbalanced_style['num_words'], test_imbalanced_style['num_chars'])\n",
    "test_imbalanced_style['unique_words_to_words'] = util.series_ratio(test_imbalanced_style['num_unique_words'], test_imbalanced_style['num_words'])\n",
    "test_imbalanced_style['special_chars_to_chars'] = util.series_ratio(test_imbalanced_style['num_special_chars'], test_imbalanced_style['num_chars'])\n",
    "\n",
    "test_imbalanced_style['dots_to_chars'] = test_imbalanced_text['body'].apply(util.character_to_chars, character='.')\n",
    "test_imbalanced_style['commas_to_chars'] = test_imbalanced_text['body'].apply(util.character_to_chars, character=',')\n",
    "test_imbalanced_style['questionmark_to_chars'] = test_imbalanced_text['body'].apply(util.character_to_chars, character='?')\n",
    "test_imbalanced_style['exclamationmark_to_chars'] = test_imbalanced_text['body'].apply(util.character_to_chars, character='!')\n",
    "\n",
    "test_imbalanced_style['chars_to_lines'] = test_imbalanced_text['body'].apply(util.chars_to_lines)\n",
    "test_imbalanced_style['alpha_tokens_to_words'] = test_imbalanced_text['body'].apply(util.alpha_tokens_ratio)\n",
    "\n",
    "test_imbalanced_style['words_to_lines'] = test_imbalanced_style['words_to_chars'] * test_imbalanced_style['chars_to_lines']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be5e9a8",
   "metadata": {},
   "source": [
    "## Readability and Spelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ec2015",
   "metadata": {},
   "source": [
    "Finally, somewhat more advanced readability scores and spelling/grammatical errors can be used as features.<br>\n",
    "Note that the spellcheck is a time consuming procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d5798f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "language_tool = language_tool_python.LanguageTool('en-US', config={'cacheSize': 1000, 'pipelineCaching': True, 'maxCheckThreads': 12, 'maxSpellingSuggestions': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f8c6a404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time required for balanced train set spellcheck:  817.54  seconds.\n"
     ]
    }
   ],
   "source": [
    "train_balanced_style['readability'] = train_balanced_text['body'].apply(util.readability)\n",
    "train_balanced_style[['flesch_kincaid', 'flesch', 'gunning_fog', 'coleman_liau', 'dale_chall', 'automated_readability_index', 'linsear_write', 'spache']] = pd.DataFrame(train_balanced_style['readability'].tolist(), index=train_balanced_style.index)\n",
    "train_balanced_style = train_balanced_style.drop('readability', axis=1)\n",
    "\n",
    "t1 = time()\n",
    "train_balanced_style['errors'] = train_balanced_text['body'].apply(util.errors_check, tool=language_tool)\n",
    "t2 = time()\n",
    "print(\"Time required for balanced train set spellcheck: \", \"{:.2f}\".format(t2-t1), \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "828cce91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time required for balanced test set spellcheck:  54.03  seconds.\n"
     ]
    }
   ],
   "source": [
    "test_balanced_style['readability'] = test_balanced_text['body'].apply(util.readability)\n",
    "test_balanced_style[['flesch_kincaid', 'flesch', 'gunning_fog', 'coleman_liau', 'dale_chall', 'automated_readability_index', 'linsear_write', 'spache']] = pd.DataFrame(test_balanced_style['readability'].tolist(), index=test_balanced_style.index)\n",
    "test_balanced_style = test_balanced_style.drop('readability', axis=1)\n",
    "\n",
    "t1 = time()\n",
    "test_balanced_style['errors'] = test_balanced_text['body'].apply(util.errors_check, tool=language_tool)\n",
    "t2 = time()\n",
    "print(\"Time required for balanced test set spellcheck: \", \"{:.2f}\".format(t2-t1), \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9bcc44a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time required for imbalanced train set spellcheck:  2005.29  seconds.\n"
     ]
    }
   ],
   "source": [
    "train_imbalanced_style['readability'] = train_imbalanced_text['body'].apply(util.readability)\n",
    "train_imbalanced_style[['flesch_kincaid', 'flesch', 'gunning_fog', 'coleman_liau', 'dale_chall', 'automated_readability_index', 'linsear_write', 'spache']] = pd.DataFrame(train_imbalanced_style['readability'].tolist(), index=train_imbalanced_style.index)\n",
    "train_imbalanced_style = train_imbalanced_style.drop('readability', axis=1)\n",
    "\n",
    "t1 = time()\n",
    "train_imbalanced_style['errors'] = train_imbalanced_text['body'].apply(util.errors_check, tool=language_tool)\n",
    "t2 = time()\n",
    "print(\"Time required for imbalanced train set spellcheck: \", \"{:.2f}\".format(t2-t1), \" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "acfe434d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time required for imbalanced test set spellcheck:  355.67  seconds.\n"
     ]
    }
   ],
   "source": [
    "test_imbalanced_style['readability'] = test_imbalanced_text['body'].apply(util.readability)\n",
    "test_imbalanced_style[['flesch_kincaid', 'flesch', 'gunning_fog', 'coleman_liau', 'dale_chall', 'automated_readability_index', 'linsear_write', 'spache']] = pd.DataFrame(test_imbalanced_style['readability'].tolist(), index=test_imbalanced_style.index)\n",
    "test_imbalanced_style = test_imbalanced_style.drop('readability', axis=1)\n",
    "\n",
    "t1 = time()\n",
    "test_imbalanced_style['errors'] = test_imbalanced_text['body'].apply(util.errors_check, tool=language_tool)\n",
    "t2 = time()\n",
    "print(\"Time required for imbalanced test set spellcheck: \", \"{:.2f}\".format(t2-t1), \" seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f945a90",
   "metadata": {},
   "source": [
    "# Final Dataset Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1c0c14",
   "metadata": {},
   "source": [
    "The calculated features look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a4426907",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>num_chars</th>\n",
       "      <th>num_newlines</th>\n",
       "      <th>num_special_chars</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_unique_words</th>\n",
       "      <th>num_sentences</th>\n",
       "      <th>num_upper_sentences</th>\n",
       "      <th>num_lower_sentences</th>\n",
       "      <th>...</th>\n",
       "      <th>words_to_lines</th>\n",
       "      <th>flesch_kincaid</th>\n",
       "      <th>flesch</th>\n",
       "      <th>gunning_fog</th>\n",
       "      <th>coleman_liau</th>\n",
       "      <th>dale_chall</th>\n",
       "      <th>automated_readability_index</th>\n",
       "      <th>linsear_write</th>\n",
       "      <th>spache</th>\n",
       "      <th>errors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2377</td>\n",
       "      <td>False</td>\n",
       "      <td>1884</td>\n",
       "      <td>36</td>\n",
       "      <td>98</td>\n",
       "      <td>264</td>\n",
       "      <td>161</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>7.135135</td>\n",
       "      <td>13.682413</td>\n",
       "      <td>45.451678</td>\n",
       "      <td>15.960839</td>\n",
       "      <td>11.237179</td>\n",
       "      <td>11.723721</td>\n",
       "      <td>15.245087</td>\n",
       "      <td>18.363636</td>\n",
       "      <td>9.386350</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>592</td>\n",
       "      <td>True</td>\n",
       "      <td>1311</td>\n",
       "      <td>47</td>\n",
       "      <td>36</td>\n",
       "      <td>195</td>\n",
       "      <td>60</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.062500</td>\n",
       "      <td>13.520256</td>\n",
       "      <td>35.166410</td>\n",
       "      <td>13.384615</td>\n",
       "      <td>13.530462</td>\n",
       "      <td>10.784244</td>\n",
       "      <td>13.991949</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>7.554513</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1049</td>\n",
       "      <td>False</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1087</td>\n",
       "      <td>True</td>\n",
       "      <td>1636</td>\n",
       "      <td>18</td>\n",
       "      <td>66</td>\n",
       "      <td>242</td>\n",
       "      <td>82</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.736842</td>\n",
       "      <td>15.826939</td>\n",
       "      <td>23.471990</td>\n",
       "      <td>19.269388</td>\n",
       "      <td>14.887837</td>\n",
       "      <td>10.716557</td>\n",
       "      <td>16.369347</td>\n",
       "      <td>18.850000</td>\n",
       "      <td>8.260031</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>725</td>\n",
       "      <td>False</td>\n",
       "      <td>784</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>115</td>\n",
       "      <td>81</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>38.333333</td>\n",
       "      <td>12.405901</td>\n",
       "      <td>34.201739</td>\n",
       "      <td>13.527950</td>\n",
       "      <td>15.530783</td>\n",
       "      <td>10.630053</td>\n",
       "      <td>13.324112</td>\n",
       "      <td>11.785714</td>\n",
       "      <td>7.418037</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  class  num_chars  num_newlines  num_special_chars  num_words  \\\n",
       "0  2377  False       1884            36                 98        264   \n",
       "1   592   True       1311            47                 36        195   \n",
       "2  1049  False         33             0                  1          5   \n",
       "3  1087   True       1636            18                 66        242   \n",
       "4   725  False        784             2                 16        115   \n",
       "\n",
       "   num_unique_words  num_sentences  num_upper_sentences  num_lower_sentences  \\\n",
       "0               161             11                    9                    2   \n",
       "1                60              9                    9                    0   \n",
       "2                 5              1                    1                    0   \n",
       "3                82             10                   10                    0   \n",
       "4                81              7                    7                    0   \n",
       "\n",
       "   ...  words_to_lines  flesch_kincaid     flesch  gunning_fog  coleman_liau  \\\n",
       "0  ...        7.135135       13.682413  45.451678    15.960839     11.237179   \n",
       "1  ...        4.062500       13.520256  35.166410    13.384615     13.530462   \n",
       "2  ...        5.000000             NaN        NaN          NaN           NaN   \n",
       "3  ...       12.736842       15.826939  23.471990    19.269388     14.887837   \n",
       "4  ...       38.333333       12.405901  34.201739    13.527950     15.530783   \n",
       "\n",
       "   dale_chall  automated_readability_index  linsear_write    spache  errors  \n",
       "0   11.723721                    15.245087      18.363636  9.386350      22  \n",
       "1   10.784244                    13.991949      14.500000  7.554513      17  \n",
       "2         NaN                          NaN            NaN       NaN       0  \n",
       "3   10.716557                    16.369347      18.850000  8.260031       1  \n",
       "4   10.630053                    13.324112      11.785714  7.418037       2  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_balanced_style.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c2aadec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(674, 44)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_balanced_style.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91196e96",
   "metadata": {},
   "source": [
    "In total, 42 features where created."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf16d4d",
   "metadata": {},
   "source": [
    "## Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ae61fa",
   "metadata": {},
   "source": [
    "There are some missing values in the datasets created, since readability scores do not work for text shorter than 100 words and language tool will stop for very big messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "81f78a86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "flesch_kincaid                 1201\n",
       "flesch                         1201\n",
       "gunning_fog                    1201\n",
       "coleman_liau                   1201\n",
       "dale_chall                     1201\n",
       "automated_readability_index    1201\n",
       "linsear_write                  1201\n",
       "spache                         1201\n",
       "errors                            1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_balanced_style.isna().sum()[train_balanced_style.isna().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "edf505f3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "flesch_kincaid                 309\n",
       "flesch                         309\n",
       "gunning_fog                    309\n",
       "coleman_liau                   309\n",
       "dale_chall                     309\n",
       "automated_readability_index    309\n",
       "linsear_write                  309\n",
       "spache                         309\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_balanced_style.isna().sum()[test_balanced_style.isna().any()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b84e90",
   "metadata": {},
   "source": [
    "The missing value in errors can simply be replaced by a big number, for example 2x the time of the maximum value of the column of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8d5ecaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_balanced_style['errors'] = train_balanced_style['errors'].fillna(train_balanced_style['errors'].max() * 2)\n",
    "train_imbalanced_style['errors'] = train_imbalanced_style['errors'].fillna(train_imbalanced_style['errors'].max() * 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f268c12",
   "metadata": {},
   "source": [
    "As for the readability scores, it is obvious it is obvious from the following plot that there is not a linear relationship between the number of words and the readability score, and thus using a single value (either \"easy to read\" or \"hard to read\") for the missing scores (that consist of messages shorter than 100 words) would not make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d615f1ac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.scatter(train_imbalanced_style['num_words'], train_imbalanced_style['flesch_kincaid'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802ba0ac",
   "metadata": {},
   "source": [
    "Thus, the mean value of the training set will be used to replace the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "358ae01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_balanced_style, test_balanced_style = impute_mean(train_balanced_style, test_balanced_style)\n",
    "train_imbalanced_style, test_imbalanced_style = impute_mean(train_imbalanced_style, test_imbalanced_style)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb873bb0",
   "metadata": {},
   "source": [
    "## Change Column Names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f9f330",
   "metadata": {},
   "source": [
    "For consistency, change the id and class column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5e1f57be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_balanced_style = train_balanced_style.rename(columns={\"id\": \"email_id\", \"class\": \"email_class\"})\n",
    "test_balanced_style = test_balanced_style.rename(columns={\"id\": \"email_id\", \"class\": \"email_class\"})\n",
    "\n",
    "train_imbalanced_style = train_imbalanced_style.rename(columns={\"id\": \"email_id\", \"class\": \"email_class\"})\n",
    "test_imbalanced_style = test_imbalanced_style.rename(columns={\"id\": \"email_id\", \"class\": \"email_class\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94f8a74",
   "metadata": {},
   "source": [
    "## Saving Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a5035f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to /home/ichanis/projects/phishing_public/data/csv/style_train_balanced.csv\n",
      "Saving to /home/ichanis/projects/phishing_public/data/csv/style_test_balanced.csv\n",
      "Saving to /home/ichanis/projects/phishing_public/data/csv/style_train_imbalanced.csv\n",
      "Saving to /home/ichanis/projects/phishing_public/data/csv/style_test_imbalanced.csv\n"
     ]
    }
   ],
   "source": [
    "save_to_csv(train_balanced_style, csv_path, 'style_train_balanced.csv')\n",
    "save_to_csv(test_balanced_style, csv_path, 'style_test_balanced.csv')\n",
    "\n",
    "save_to_csv(train_imbalanced_style, csv_path, 'style_train_imbalanced.csv')\n",
    "save_to_csv(test_imbalanced_style, csv_path, 'style_test_imbalanced.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

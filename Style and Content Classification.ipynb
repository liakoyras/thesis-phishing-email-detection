{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e41204e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = 250\n",
    "\n",
    "import machine_learning as ml\n",
    "from preprocessing import separate_features_target\n",
    "\n",
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "702a8888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path\n",
    "cwd = os.getcwd()\n",
    "csv_path = os.path.join(cwd, 'data/csv/')\n",
    "\n",
    "train = {\n",
    "    'stylometric' : ['style_train_balanced.csv','style_train_imbalanced.csv'],\n",
    "    'word2vec' : ['word2vec_train_balanced.csv','word2vec_train_imbalanced.csv']\n",
    "}\n",
    "test = {\n",
    "    'stylometric' : ['style_test_balanced.csv','style_test_imbalanced.csv'],\n",
    "    'word2vec' : ['word2vec_test_balanced.csv','word2vec_test_imbalanced.csv']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424810a5",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02737f46",
   "metadata": {},
   "source": [
    "Since Word2Vec features outperformed the TF-IDF features, only those will be used to test the combination with content features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ebf18e",
   "metadata": {},
   "source": [
    "### Balanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19750b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "style_train_balanced_complete = pd.read_csv(os.path.join(csv_path, train['stylometric'][0]), index_col=0, dtype={'email_class': 'bool', 'email_id': 'int16'})\n",
    "style_test_balanced_complete = pd.read_csv(os.path.join(csv_path, test['stylometric'][0]), index_col=0, dtype={'email_class': 'bool', 'email_id': 'int16'})\n",
    "\n",
    "word2vec_train_balanced_complete = pd.read_csv(os.path.join(csv_path, train['word2vec'][0]), index_col=0, dtype={'email_class': 'bool', 'email_id': 'int16'})\n",
    "word2vec_test_balanced_complete = pd.read_csv(os.path.join(csv_path, test['word2vec'][0]), index_col=0, dtype={'email_class': 'bool', 'email_id': 'int16'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "117c14ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "style_train_balanced = separate_features_target(style_train_balanced_complete)\n",
    "style_test_balanced = separate_features_target(style_test_balanced_complete)\n",
    "\n",
    "word2vec_train_balanced = separate_features_target(word2vec_train_balanced_complete)\n",
    "word2vec_test_balanced = separate_features_target(word2vec_test_balanced_complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28b1832",
   "metadata": {},
   "source": [
    "### Imbalanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f07057f",
   "metadata": {},
   "outputs": [],
   "source": [
    "style_train_imbalanced_complete = pd.read_csv(os.path.join(csv_path, train['stylometric'][1]), index_col=0, dtype={'email_class': 'bool', 'email_id': 'int16'})\n",
    "style_test_imbalanced_complete = pd.read_csv(os.path.join(csv_path, test['stylometric'][1]), index_col=0, dtype={'email_class': 'bool', 'email_id': 'int16'})\n",
    "\n",
    "word2vec_train_imbalanced_complete = pd.read_csv(os.path.join(csv_path, train['word2vec'][1]), index_col=0, dtype={'email_class': 'bool', 'email_id': 'int16'})\n",
    "word2vec_test_imbalanced_complete = pd.read_csv(os.path.join(csv_path, test['word2vec'][1]), index_col=0, dtype={'email_class': 'bool', 'email_id': 'int16'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f680514",
   "metadata": {},
   "outputs": [],
   "source": [
    "style_train_imbalanced = separate_features_target(style_train_imbalanced_complete)\n",
    "style_test_imbalanced = separate_features_target(style_test_imbalanced_complete)\n",
    "\n",
    "word2vec_train_imbalanced = separate_features_target(word2vec_train_imbalanced_complete)\n",
    "word2vec_test_imbalanced = separate_features_target(word2vec_test_imbalanced_complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfda150",
   "metadata": {},
   "source": [
    "# Merging Feature Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464fccfe",
   "metadata": {},
   "source": [
    "The simplest way of combining the information of the two different feature sets is to simply merge them into one set and then perform the predictions based on this concatenated set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6cdc4a",
   "metadata": {},
   "source": [
    "## Balanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68f32c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "style_content_train_balanced = pd.concat([word2vec_train_balanced['features'], style_train_balanced['features']], axis=1)\n",
    "style_content_test_balanced = pd.concat([word2vec_test_balanced['features'], style_test_balanced['features']], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df122e5",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2957d9ed",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "828667e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9988864142538976\n",
      "CPU times: user 460 ms, sys: 645 ms, total: 1.1 s\n",
      "Wall time: 78.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr_style_content_balanced = ml.train_logistic_regression(style_content_train_balanced, style_train_balanced['target'], show_train_accuracy=1)\n",
    "lr_style_content_balanced, lr_style_content_balanced_scaler = lr_style_content_balanced['model'], lr_style_content_balanced['scaler']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6b7cd3",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76d32c44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.985894580549369\n",
      "CPU times: user 443 ms, sys: 858 ms, total: 1.3 s\n",
      "Wall time: 156 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dt_style_content_balanced = ml.train_decision_tree(style_content_train_balanced, style_train_balanced['target'], show_train_accuracy=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16daa374",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58232f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9855233853006682\n",
      "CPU times: user 150 ms, sys: 2.05 ms, total: 153 ms\n",
      "Wall time: 151 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rf_style_content_balanced = ml.train_random_forest(style_content_train_balanced, style_train_balanced['target'], show_train_accuracy=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322a604a",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edcc3d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9977728285077951\n",
      "CPU times: user 7.03 s, sys: 72 ms, total: 7.1 s\n",
      "Wall time: 7.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gb_style_content_balanced = ml.train_gradient_boost(style_content_train_balanced, style_train_balanced['target'], show_train_accuracy=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5118b57c",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6a120f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9665924276169265\n",
      "CPU times: user 73.9 ms, sys: 117 ms, total: 191 ms\n",
      "Wall time: 20 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nb_style_content_balanced = ml.train_naive_bayes(style_content_train_balanced, style_train_balanced['target'], show_train_accuracy=1, remove_negatives=True)\n",
    "nb_style_content_balanced, nb_style_content_balanced_scaler = nb_style_content_balanced['model'], nb_style_content_balanced['scaler']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafc39b7",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b043c4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [lr_style_content_balanced, dt_style_content_balanced, rf_style_content_balanced, gb_style_content_balanced, nb_style_content_balanced]\n",
    "names = ['Logistic Regression', 'Decision Tree', 'Random Forest', 'Gradient Boosting Tree', 'Naive Bayes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "893cc6dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 312 ms, sys: 571 ms, total: 884 ms\n",
      "Wall time: 55.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results_style_content_balanced = ml.multi_model_results(models, names, style_content_test_balanced, style_test_balanced['target'], lr_style_content_balanced_scaler, nb_style_content_balanced_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bec06c19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>Area Under ROC Curve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.964392</td>\n",
       "      <td>0.962857</td>\n",
       "      <td>0.968391</td>\n",
       "      <td>0.965616</td>\n",
       "      <td>0.039877</td>\n",
       "      <td>0.031609</td>\n",
       "      <td>0.980771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.951039</td>\n",
       "      <td>0.959184</td>\n",
       "      <td>0.945402</td>\n",
       "      <td>0.952243</td>\n",
       "      <td>0.042945</td>\n",
       "      <td>0.054598</td>\n",
       "      <td>0.936535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.973294</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.977011</td>\n",
       "      <td>0.974212</td>\n",
       "      <td>0.030675</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>0.995231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting Tree</th>\n",
       "      <td>0.979228</td>\n",
       "      <td>0.977143</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.979943</td>\n",
       "      <td>0.024540</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.996271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.961424</td>\n",
       "      <td>0.962644</td>\n",
       "      <td>0.962644</td>\n",
       "      <td>0.962644</td>\n",
       "      <td>0.039877</td>\n",
       "      <td>0.037356</td>\n",
       "      <td>0.987607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Accuracy  Precision    Recall  F1 Score  \\\n",
       "Logistic Regression     0.964392   0.962857  0.968391  0.965616   \n",
       "Decision Tree           0.951039   0.959184  0.945402  0.952243   \n",
       "Random Forest           0.973294   0.971429  0.977011  0.974212   \n",
       "Gradient Boosting Tree  0.979228   0.977143  0.982759  0.979943   \n",
       "Naive Bayes             0.961424   0.962644  0.962644  0.962644   \n",
       "\n",
       "                        False Positive Rate  False Negative Rate  \\\n",
       "Logistic Regression                0.039877             0.031609   \n",
       "Decision Tree                      0.042945             0.054598   \n",
       "Random Forest                      0.030675             0.022989   \n",
       "Gradient Boosting Tree             0.024540             0.017241   \n",
       "Naive Bayes                        0.039877             0.037356   \n",
       "\n",
       "                        Area Under ROC Curve  \n",
       "Logistic Regression                 0.980771  \n",
       "Decision Tree                       0.936535  \n",
       "Random Forest                       0.995231  \n",
       "Gradient Boosting Tree              0.996271  \n",
       "Naive Bayes                         0.987607  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_style_content_balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde64486",
   "metadata": {},
   "source": [
    "## Imbalanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3eee1e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "style_content_train_imbalanced = pd.concat([word2vec_train_imbalanced['features'], style_train_imbalanced['features']], axis=1)\n",
    "style_content_test_imbalanced = pd.concat([word2vec_test_imbalanced['features'], style_test_imbalanced['features']], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1fd2fd",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3615327d",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02d925c3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9955399378294364\n",
      "CPU times: user 11.2 s, sys: 13.1 s, total: 24.3 s\n",
      "Wall time: 1.55 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr_style_content_imbalanced = ml.train_logistic_regression(style_content_train_imbalanced, style_train_imbalanced['target'], show_train_accuracy=1)\n",
    "lr_style_content_imbalanced, lr_style_content_imbalanced_scaler = lr_style_content_imbalanced['model'], lr_style_content_imbalanced['scaler']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0c2c28",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1fb6866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9853358561967833\n",
      "CPU times: user 1.21 s, sys: 826 ms, total: 2.03 s\n",
      "Wall time: 903 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dt_style_content_imbalanced = ml.train_decision_tree(style_content_train_imbalanced, style_train_imbalanced['target'], show_train_accuracy=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400dbaf8",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e067945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9833085552101636\n",
      "CPU times: user 899 ms, sys: 2.58 ms, total: 901 ms\n",
      "Wall time: 898 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rf_style_content_imbalanced = ml.train_random_forest(style_content_train_imbalanced, style_train_imbalanced['target'], show_train_accuracy=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e41141",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7d65c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9966211650223004\n",
      "CPU times: user 1min, sys: 54.8 ms, total: 1min\n",
      "Wall time: 1min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gb_style_content_imbalanced = ml.train_gradient_boost(style_content_train_imbalanced, style_train_imbalanced['target'], show_train_accuracy=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9953740",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d16b266",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9080281119070145\n",
      "CPU times: user 165 ms, sys: 11.2 ms, total: 176 ms\n",
      "Wall time: 31.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nb_style_content_imbalanced = ml.train_naive_bayes(style_content_train_imbalanced, style_train_imbalanced['target'], show_train_accuracy=1, remove_negatives=True)\n",
    "nb_style_content_imbalanced, nb_style_content_imbalanced_scaler = nb_style_content_imbalanced['model'], nb_style_content_imbalanced['scaler']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c23e477",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "416794b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [lr_style_content_imbalanced, dt_style_content_imbalanced, rf_style_content_imbalanced, gb_style_content_imbalanced, nb_style_content_imbalanced]\n",
    "names = ['Logistic Regression', 'Decision Tree', 'Random Forest', 'Gradient Boosting Tree', 'Naive Bayes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a8046fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 542 ms, sys: 1.3 s, total: 1.84 s\n",
      "Wall time: 127 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ichanis/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results_style_content_imbalanced = ml.multi_model_results(models, names, style_content_test_imbalanced, style_test_imbalanced['target'], lr_style_content_imbalanced_scaler, nb_style_content_imbalanced_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa564bda",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>Area Under ROC Curve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.991622</td>\n",
       "      <td>0.971061</td>\n",
       "      <td>0.932099</td>\n",
       "      <td>0.951181</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>0.067901</td>\n",
       "      <td>0.993486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.980270</td>\n",
       "      <td>0.911475</td>\n",
       "      <td>0.858025</td>\n",
       "      <td>0.883943</td>\n",
       "      <td>0.007998</td>\n",
       "      <td>0.141975</td>\n",
       "      <td>0.960973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.981351</td>\n",
       "      <td>0.973978</td>\n",
       "      <td>0.808642</td>\n",
       "      <td>0.883642</td>\n",
       "      <td>0.002073</td>\n",
       "      <td>0.191358</td>\n",
       "      <td>0.994397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting Tree</th>\n",
       "      <td>0.991081</td>\n",
       "      <td>0.967846</td>\n",
       "      <td>0.929012</td>\n",
       "      <td>0.948031</td>\n",
       "      <td>0.002962</td>\n",
       "      <td>0.070988</td>\n",
       "      <td>0.998247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.912432</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Accuracy  Precision    Recall  F1 Score  \\\n",
       "Logistic Regression     0.991622   0.971061  0.932099  0.951181   \n",
       "Decision Tree           0.980270   0.911475  0.858025  0.883943   \n",
       "Random Forest           0.981351   0.973978  0.808642  0.883642   \n",
       "Gradient Boosting Tree  0.991081   0.967846  0.929012  0.948031   \n",
       "Naive Bayes             0.912432   0.000000  0.000000  0.000000   \n",
       "\n",
       "                        False Positive Rate  False Negative Rate  \\\n",
       "Logistic Regression                0.002666             0.067901   \n",
       "Decision Tree                      0.007998             0.141975   \n",
       "Random Forest                      0.002073             0.191358   \n",
       "Gradient Boosting Tree             0.002962             0.070988   \n",
       "Naive Bayes                        0.000000             1.000000   \n",
       "\n",
       "                        Area Under ROC Curve  \n",
       "Logistic Regression                 0.993486  \n",
       "Decision Tree                       0.960973  \n",
       "Random Forest                       0.994397  \n",
       "Gradient Boosting Tree              0.998247  \n",
       "Naive Bayes                         0.988985  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_style_content_imbalanced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e02783e",
   "metadata": {},
   "source": [
    "Comparing these with the content-only baseline, it is obvious that there is a at small improvement with GB and RF on the balanced dataset, while all algorithms except RF improved on the imbalanced dataset.<br>\n",
    "It seems that the extra features are helpful with the more robust algoritms in order to achieve better accuracy on the bigger dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2023540",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9003f184",
   "metadata": {},
   "source": [
    "In machine learning, stacking refers to the proccess of using different learners (each one working best at learning a different part of the problem) called level 0 models as intermediate steps and then use their outputs to train another learner, called level 1 model. Thus, the final model is sometimes able to outperform the individual ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93d4a2a",
   "metadata": {},
   "source": [
    "On this specific case, the different initial classifiers will be trained on both of the feature sets, and thus the final classifier essentially will combine information from both of them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea81e25c",
   "metadata": {},
   "source": [
    "#### Final Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338c2ddf",
   "metadata": {},
   "source": [
    "Only the three best classifiers will be used as a level 1 classifier, namely Logistic Regression (which is implemented by default), Random Forest and Gradient Boosting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c22e5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = ml.RandomForestClassifier(max_depth=5, n_estimators=20, random_state=ml.alg_random_state)\n",
    "gb = ml.GradientBoostingClassifier(loss='log_loss', max_depth=3, learning_rate=0.1, random_state=ml.alg_random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc58a2a5",
   "metadata": {},
   "source": [
    "## Balanced Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32941e90",
   "metadata": {},
   "source": [
    "#### Train Initial Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a8dda48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature_sets_balanced = [{'name': 'style', 'features': style_train_balanced['features']}, {'name': 'word2vec', 'features': word2vec_train_balanced['features']}]\n",
    "test_feature_sets_balanced = [{'name': 'style', 'features': style_test_balanced['features']}, {'name': 'word2vec', 'features': word2vec_test_balanced['features']}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9a5da859",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.4 s, sys: 7.81 s, total: 19.2 s\n",
      "Wall time: 8.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stacking_models_balanced = ml.train_models(train_feature_sets_balanced, style_train_balanced['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da494e3",
   "metadata": {},
   "source": [
    "### Single-algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2be1dce",
   "metadata": {},
   "source": [
    "First, the stacking will be done only on the same algorithms with different feature sets, while also testing for different final_classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f28e1c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stacking_balanced_single = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca8b5b4",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "da32f89a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36.9 s, sys: 16.4 s, total: 53.3 s\n",
      "Wall time: 30.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], exclude_models=['dt', 'rf', 'gb', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'rf', 'gb', 'nb'])\n",
    "results_stacking_balanced_single = pd.concat([results_stacking_balanced_single, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], exclude_models=['lr', 'rf', 'gb', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['lr', 'rf', 'gb', 'nb'])\n",
    "results_stacking_balanced_single = pd.concat([results_stacking_balanced_single, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], exclude_models=['lr', 'dt', 'gb', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['lr', 'dt', 'gb', 'nb'])\n",
    "results_stacking_balanced_single = pd.concat([results_stacking_balanced_single, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], exclude_models=['lr', 'dt', 'rf', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['lr', 'dt', 'rf', 'nb'])\n",
    "results_stacking_balanced_single = pd.concat([results_stacking_balanced_single, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], exclude_models=['lr', 'dt', 'rf', 'gb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['lr', 'dt', 'rf', 'gb'])\n",
    "results_stacking_balanced_single = pd.concat([results_stacking_balanced_single, stacked_preds['results']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa440123",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ff9069f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38.4 s, sys: 19 s, total: 57.4 s\n",
      "Wall time: 31.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=rf, exclude_models=['dt', 'rf', 'gb', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'rf', 'gb', 'nb'])\n",
    "results_stacking_balanced_single = pd.concat([results_stacking_balanced_single, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=rf, exclude_models=['lr', 'rf', 'gb', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['lr', 'rf', 'gb', 'nb'])\n",
    "results_stacking_balanced_single = pd.concat([results_stacking_balanced_single, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=rf, exclude_models=['lr', 'dt', 'gb', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['lr', 'dt', 'gb', 'nb'])\n",
    "results_stacking_balanced_single = pd.concat([results_stacking_balanced_single, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=rf, exclude_models=['lr', 'dt', 'rf', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['lr', 'dt', 'rf', 'nb'])\n",
    "results_stacking_balanced_single = pd.concat([results_stacking_balanced_single, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=rf, exclude_models=['lr', 'dt', 'rf', 'gb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['lr', 'dt', 'rf', 'gb'])\n",
    "results_stacking_balanced_single = pd.concat([results_stacking_balanced_single, stacked_preds['results']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d265000",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e5fa23d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38.9 s, sys: 18 s, total: 56.9 s\n",
      "Wall time: 31.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=gb, exclude_models=['dt', 'rf', 'gb', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'rf', 'gb', 'nb'])\n",
    "results_stacking_balanced_single = pd.concat([results_stacking_balanced_single, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=gb, exclude_models=['lr', 'rf', 'gb', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['lr', 'rf', 'gb', 'nb'])\n",
    "results_stacking_balanced_single = pd.concat([results_stacking_balanced_single, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=gb, exclude_models=['lr', 'dt', 'gb', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['lr', 'dt', 'gb', 'nb'])\n",
    "results_stacking_balanced_single = pd.concat([results_stacking_balanced_single, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=gb, exclude_models=['lr', 'dt', 'rf', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['lr', 'dt', 'rf', 'nb'])\n",
    "results_stacking_balanced_single = pd.concat([results_stacking_balanced_single, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=gb, exclude_models=['lr', 'dt', 'rf', 'gb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['lr', 'dt', 'rf', 'gb'])\n",
    "results_stacking_balanced_single = pd.concat([results_stacking_balanced_single, stacked_preds['results']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b5a4e25e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>Area Under ROC Curve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, with LogisticRegression</th>\n",
       "      <td>0.976261</td>\n",
       "      <td>0.979769</td>\n",
       "      <td>0.974138</td>\n",
       "      <td>0.976945</td>\n",
       "      <td>0.021472</td>\n",
       "      <td>0.025862</td>\n",
       "      <td>0.996739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: dt, with LogisticRegression</th>\n",
       "      <td>0.952522</td>\n",
       "      <td>0.961988</td>\n",
       "      <td>0.945402</td>\n",
       "      <td>0.953623</td>\n",
       "      <td>0.039877</td>\n",
       "      <td>0.054598</td>\n",
       "      <td>0.983142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, with LogisticRegression</th>\n",
       "      <td>0.971810</td>\n",
       "      <td>0.971347</td>\n",
       "      <td>0.974138</td>\n",
       "      <td>0.972740</td>\n",
       "      <td>0.030675</td>\n",
       "      <td>0.025862</td>\n",
       "      <td>0.995610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: gb, with LogisticRegression</th>\n",
       "      <td>0.976261</td>\n",
       "      <td>0.971591</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.977143</td>\n",
       "      <td>0.030675</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.997620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: nb, with LogisticRegression</th>\n",
       "      <td>0.962908</td>\n",
       "      <td>0.965418</td>\n",
       "      <td>0.962644</td>\n",
       "      <td>0.964029</td>\n",
       "      <td>0.036810</td>\n",
       "      <td>0.037356</td>\n",
       "      <td>0.987712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, with RandomForestClassifier</th>\n",
       "      <td>0.949555</td>\n",
       "      <td>0.951149</td>\n",
       "      <td>0.951149</td>\n",
       "      <td>0.951149</td>\n",
       "      <td>0.052147</td>\n",
       "      <td>0.048851</td>\n",
       "      <td>0.992027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: dt, with RandomForestClassifier</th>\n",
       "      <td>0.952522</td>\n",
       "      <td>0.961988</td>\n",
       "      <td>0.945402</td>\n",
       "      <td>0.953623</td>\n",
       "      <td>0.039877</td>\n",
       "      <td>0.054598</td>\n",
       "      <td>0.983680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, with RandomForestClassifier</th>\n",
       "      <td>0.964392</td>\n",
       "      <td>0.960227</td>\n",
       "      <td>0.971264</td>\n",
       "      <td>0.965714</td>\n",
       "      <td>0.042945</td>\n",
       "      <td>0.028736</td>\n",
       "      <td>0.995610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: gb, with RandomForestClassifier</th>\n",
       "      <td>0.976261</td>\n",
       "      <td>0.974286</td>\n",
       "      <td>0.979885</td>\n",
       "      <td>0.977077</td>\n",
       "      <td>0.027607</td>\n",
       "      <td>0.020115</td>\n",
       "      <td>0.997043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: nb, with RandomForestClassifier</th>\n",
       "      <td>0.961424</td>\n",
       "      <td>0.949721</td>\n",
       "      <td>0.977011</td>\n",
       "      <td>0.963173</td>\n",
       "      <td>0.055215</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>0.991736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, with GradientBoostingClassifier</th>\n",
       "      <td>0.946588</td>\n",
       "      <td>0.940678</td>\n",
       "      <td>0.956897</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.064417</td>\n",
       "      <td>0.043103</td>\n",
       "      <td>0.990269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: dt, with GradientBoostingClassifier</th>\n",
       "      <td>0.948071</td>\n",
       "      <td>0.967164</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.948755</td>\n",
       "      <td>0.033742</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.984918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, with GradientBoostingClassifier</th>\n",
       "      <td>0.968843</td>\n",
       "      <td>0.963173</td>\n",
       "      <td>0.977011</td>\n",
       "      <td>0.970043</td>\n",
       "      <td>0.039877</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>0.995443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: gb, with GradientBoostingClassifier</th>\n",
       "      <td>0.968843</td>\n",
       "      <td>0.973913</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.027607</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.996545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: nb, with GradientBoostingClassifier</th>\n",
       "      <td>0.956973</td>\n",
       "      <td>0.965015</td>\n",
       "      <td>0.951149</td>\n",
       "      <td>0.958032</td>\n",
       "      <td>0.036810</td>\n",
       "      <td>0.048851</td>\n",
       "      <td>0.992296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Accuracy  Precision  \\\n",
       "Algorithms: lr, with LogisticRegression          0.976261   0.979769   \n",
       "Algorithms: dt, with LogisticRegression          0.952522   0.961988   \n",
       "Algorithms: rf, with LogisticRegression          0.971810   0.971347   \n",
       "Algorithms: gb, with LogisticRegression          0.976261   0.971591   \n",
       "Algorithms: nb, with LogisticRegression          0.962908   0.965418   \n",
       "Algorithms: lr, with RandomForestClassifier      0.949555   0.951149   \n",
       "Algorithms: dt, with RandomForestClassifier      0.952522   0.961988   \n",
       "Algorithms: rf, with RandomForestClassifier      0.964392   0.960227   \n",
       "Algorithms: gb, with RandomForestClassifier      0.976261   0.974286   \n",
       "Algorithms: nb, with RandomForestClassifier      0.961424   0.949721   \n",
       "Algorithms: lr, with GradientBoostingClassifier  0.946588   0.940678   \n",
       "Algorithms: dt, with GradientBoostingClassifier  0.948071   0.967164   \n",
       "Algorithms: rf, with GradientBoostingClassifier  0.968843   0.963173   \n",
       "Algorithms: gb, with GradientBoostingClassifier  0.968843   0.973913   \n",
       "Algorithms: nb, with GradientBoostingClassifier  0.956973   0.965015   \n",
       "\n",
       "                                                   Recall  F1 Score  \\\n",
       "Algorithms: lr, with LogisticRegression          0.974138  0.976945   \n",
       "Algorithms: dt, with LogisticRegression          0.945402  0.953623   \n",
       "Algorithms: rf, with LogisticRegression          0.974138  0.972740   \n",
       "Algorithms: gb, with LogisticRegression          0.982759  0.977143   \n",
       "Algorithms: nb, with LogisticRegression          0.962644  0.964029   \n",
       "Algorithms: lr, with RandomForestClassifier      0.951149  0.951149   \n",
       "Algorithms: dt, with RandomForestClassifier      0.945402  0.953623   \n",
       "Algorithms: rf, with RandomForestClassifier      0.971264  0.965714   \n",
       "Algorithms: gb, with RandomForestClassifier      0.979885  0.977077   \n",
       "Algorithms: nb, with RandomForestClassifier      0.977011  0.963173   \n",
       "Algorithms: lr, with GradientBoostingClassifier  0.956897  0.948718   \n",
       "Algorithms: dt, with GradientBoostingClassifier  0.931034  0.948755   \n",
       "Algorithms: rf, with GradientBoostingClassifier  0.977011  0.970043   \n",
       "Algorithms: gb, with GradientBoostingClassifier  0.965517  0.969697   \n",
       "Algorithms: nb, with GradientBoostingClassifier  0.951149  0.958032   \n",
       "\n",
       "                                                 False Positive Rate  \\\n",
       "Algorithms: lr, with LogisticRegression                     0.021472   \n",
       "Algorithms: dt, with LogisticRegression                     0.039877   \n",
       "Algorithms: rf, with LogisticRegression                     0.030675   \n",
       "Algorithms: gb, with LogisticRegression                     0.030675   \n",
       "Algorithms: nb, with LogisticRegression                     0.036810   \n",
       "Algorithms: lr, with RandomForestClassifier                 0.052147   \n",
       "Algorithms: dt, with RandomForestClassifier                 0.039877   \n",
       "Algorithms: rf, with RandomForestClassifier                 0.042945   \n",
       "Algorithms: gb, with RandomForestClassifier                 0.027607   \n",
       "Algorithms: nb, with RandomForestClassifier                 0.055215   \n",
       "Algorithms: lr, with GradientBoostingClassifier             0.064417   \n",
       "Algorithms: dt, with GradientBoostingClassifier             0.033742   \n",
       "Algorithms: rf, with GradientBoostingClassifier             0.039877   \n",
       "Algorithms: gb, with GradientBoostingClassifier             0.027607   \n",
       "Algorithms: nb, with GradientBoostingClassifier             0.036810   \n",
       "\n",
       "                                                 False Negative Rate  \\\n",
       "Algorithms: lr, with LogisticRegression                     0.025862   \n",
       "Algorithms: dt, with LogisticRegression                     0.054598   \n",
       "Algorithms: rf, with LogisticRegression                     0.025862   \n",
       "Algorithms: gb, with LogisticRegression                     0.017241   \n",
       "Algorithms: nb, with LogisticRegression                     0.037356   \n",
       "Algorithms: lr, with RandomForestClassifier                 0.048851   \n",
       "Algorithms: dt, with RandomForestClassifier                 0.054598   \n",
       "Algorithms: rf, with RandomForestClassifier                 0.028736   \n",
       "Algorithms: gb, with RandomForestClassifier                 0.020115   \n",
       "Algorithms: nb, with RandomForestClassifier                 0.022989   \n",
       "Algorithms: lr, with GradientBoostingClassifier             0.043103   \n",
       "Algorithms: dt, with GradientBoostingClassifier             0.068966   \n",
       "Algorithms: rf, with GradientBoostingClassifier             0.022989   \n",
       "Algorithms: gb, with GradientBoostingClassifier             0.034483   \n",
       "Algorithms: nb, with GradientBoostingClassifier             0.048851   \n",
       "\n",
       "                                                 Area Under ROC Curve  \n",
       "Algorithms: lr, with LogisticRegression                      0.996739  \n",
       "Algorithms: dt, with LogisticRegression                      0.983142  \n",
       "Algorithms: rf, with LogisticRegression                      0.995610  \n",
       "Algorithms: gb, with LogisticRegression                      0.997620  \n",
       "Algorithms: nb, with LogisticRegression                      0.987712  \n",
       "Algorithms: lr, with RandomForestClassifier                  0.992027  \n",
       "Algorithms: dt, with RandomForestClassifier                  0.983680  \n",
       "Algorithms: rf, with RandomForestClassifier                  0.995610  \n",
       "Algorithms: gb, with RandomForestClassifier                  0.997043  \n",
       "Algorithms: nb, with RandomForestClassifier                  0.991736  \n",
       "Algorithms: lr, with GradientBoostingClassifier              0.990269  \n",
       "Algorithms: dt, with GradientBoostingClassifier              0.984918  \n",
       "Algorithms: rf, with GradientBoostingClassifier              0.995443  \n",
       "Algorithms: gb, with GradientBoostingClassifier              0.996545  \n",
       "Algorithms: nb, with GradientBoostingClassifier              0.992296  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_stacking_balanced_single"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1f7ca0",
   "metadata": {},
   "source": [
    "These results are on par with the baseline models, exept for Gradient Boosting that performed somewhat worse. Random Forest achieved better results. This is probably the result of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645cc568",
   "metadata": {},
   "source": [
    "The 6 best performing models will be kept to compare with other stacking configurations and the complete single-algorithm results dataset will be archived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0452feca",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stacking_balanced_full = results_stacking_balanced_single.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1b978634",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stacking_balanced_best = results_stacking_balanced_single.sort_values(by=['F1 Score'], ascending = [False]).head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c225b01",
   "metadata": {},
   "source": [
    "### Multi-algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e2dd8c",
   "metadata": {},
   "source": [
    "Of course, it is possible to also use the outputs of more than one classifier, on both feature sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7c646926",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stacking_balanced_multi = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6992754c",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8f058e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 26s, sys: 1min 7s, total: 3min 33s\n",
      "Wall time: 1min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], exclude_models=[])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=[], result_row_name=\"Algorithms: all, with LogisticRegression\")\n",
    "results_stacking_balanced_multi = pd.concat([results_stacking_balanced_multi, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], exclude_models=['dt', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb'])\n",
    "results_stacking_balanced_multi = pd.concat([results_stacking_balanced_multi, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], exclude_models=['dt', 'nb', 'lr'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'lr'])\n",
    "results_stacking_balanced_multi = pd.concat([results_stacking_balanced_multi, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], exclude_models=['dt', 'nb', 'rf'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'rf'])\n",
    "results_stacking_balanced_multi = pd.concat([results_stacking_balanced_multi, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], exclude_models=['dt', 'nb', 'gb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb'])\n",
    "results_stacking_balanced_multi = pd.concat([results_stacking_balanced_multi, stacked_preds['results']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15252f18",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4d1ac0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 28s, sys: 1min 8s, total: 3min 36s\n",
      "Wall time: 2min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=rf, exclude_models=[])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=[], result_row_name=\"Algorithms: all, with RandomForestClassifier\")\n",
    "results_stacking_balanced_multi = pd.concat([results_stacking_balanced_multi, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=rf, exclude_models=['dt', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb'])\n",
    "results_stacking_balanced_multi = pd.concat([results_stacking_balanced_multi, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=rf, exclude_models=['dt', 'nb', 'lr'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'lr'])\n",
    "results_stacking_balanced_multi = pd.concat([results_stacking_balanced_multi, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=rf, exclude_models=['dt', 'nb', 'rf'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'rf'])\n",
    "results_stacking_balanced_multi = pd.concat([results_stacking_balanced_multi, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=rf, exclude_models=['dt', 'nb', 'gb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb'])\n",
    "results_stacking_balanced_multi = pd.concat([results_stacking_balanced_multi, stacked_preds['results']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583405a9",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c6e30e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 30s, sys: 1min 11s, total: 3min 41s\n",
      "Wall time: 2min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=gb, exclude_models=[])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=[], result_row_name=\"Algorithms: all, with GradientBoostingClassifier\")\n",
    "results_stacking_balanced_multi = pd.concat([results_stacking_balanced_multi, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=gb, exclude_models=['dt', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb'])\n",
    "results_stacking_balanced_multi = pd.concat([results_stacking_balanced_multi, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=gb, exclude_models=['dt', 'nb', 'lr'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'lr'])\n",
    "results_stacking_balanced_multi = pd.concat([results_stacking_balanced_multi, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=gb, exclude_models=['dt', 'nb', 'rf'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'rf'])\n",
    "results_stacking_balanced_multi = pd.concat([results_stacking_balanced_multi, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=gb, exclude_models=['dt', 'nb', 'gb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb'])\n",
    "results_stacking_balanced_multi = pd.concat([results_stacking_balanced_multi, stacked_preds['results']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "49b34a9c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>Area Under ROC Curve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Algorithms: all, with LogisticRegression</th>\n",
       "      <td>0.980712</td>\n",
       "      <td>0.977208</td>\n",
       "      <td>0.985632</td>\n",
       "      <td>0.981402</td>\n",
       "      <td>0.024540</td>\n",
       "      <td>0.014368</td>\n",
       "      <td>0.998378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, rf, gb, with LogisticRegression</th>\n",
       "      <td>0.980712</td>\n",
       "      <td>0.977208</td>\n",
       "      <td>0.985632</td>\n",
       "      <td>0.981402</td>\n",
       "      <td>0.024540</td>\n",
       "      <td>0.014368</td>\n",
       "      <td>0.998493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, gb, with LogisticRegression</th>\n",
       "      <td>0.977745</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.027607</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.997602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, gb, with LogisticRegression</th>\n",
       "      <td>0.980712</td>\n",
       "      <td>0.977208</td>\n",
       "      <td>0.985632</td>\n",
       "      <td>0.981402</td>\n",
       "      <td>0.024540</td>\n",
       "      <td>0.014368</td>\n",
       "      <td>0.998598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, rf, with LogisticRegression</th>\n",
       "      <td>0.977745</td>\n",
       "      <td>0.971671</td>\n",
       "      <td>0.985632</td>\n",
       "      <td>0.978602</td>\n",
       "      <td>0.030675</td>\n",
       "      <td>0.014368</td>\n",
       "      <td>0.997576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: all, with RandomForestClassifier</th>\n",
       "      <td>0.977745</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.027607</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.997237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, rf, gb, with RandomForestClassifier</th>\n",
       "      <td>0.983680</td>\n",
       "      <td>0.980057</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.984263</td>\n",
       "      <td>0.021472</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.997695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, gb, with RandomForestClassifier</th>\n",
       "      <td>0.974777</td>\n",
       "      <td>0.966197</td>\n",
       "      <td>0.985632</td>\n",
       "      <td>0.975818</td>\n",
       "      <td>0.036810</td>\n",
       "      <td>0.014368</td>\n",
       "      <td>0.997104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, gb, with RandomForestClassifier</th>\n",
       "      <td>0.980712</td>\n",
       "      <td>0.977208</td>\n",
       "      <td>0.985632</td>\n",
       "      <td>0.981402</td>\n",
       "      <td>0.024540</td>\n",
       "      <td>0.014368</td>\n",
       "      <td>0.998510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, rf, with RandomForestClassifier</th>\n",
       "      <td>0.976261</td>\n",
       "      <td>0.974286</td>\n",
       "      <td>0.979885</td>\n",
       "      <td>0.977077</td>\n",
       "      <td>0.027607</td>\n",
       "      <td>0.020115</td>\n",
       "      <td>0.996928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: all, with GradientBoostingClassifier</th>\n",
       "      <td>0.979228</td>\n",
       "      <td>0.974432</td>\n",
       "      <td>0.985632</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.027607</td>\n",
       "      <td>0.014368</td>\n",
       "      <td>0.998078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, rf, gb, with GradientBoostingClassifier</th>\n",
       "      <td>0.976261</td>\n",
       "      <td>0.977011</td>\n",
       "      <td>0.977011</td>\n",
       "      <td>0.977011</td>\n",
       "      <td>0.024540</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>0.997770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, gb, with GradientBoostingClassifier</th>\n",
       "      <td>0.974777</td>\n",
       "      <td>0.971510</td>\n",
       "      <td>0.979885</td>\n",
       "      <td>0.975680</td>\n",
       "      <td>0.030675</td>\n",
       "      <td>0.020115</td>\n",
       "      <td>0.996893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, gb, with GradientBoostingClassifier</th>\n",
       "      <td>0.974777</td>\n",
       "      <td>0.974212</td>\n",
       "      <td>0.977011</td>\n",
       "      <td>0.975610</td>\n",
       "      <td>0.027607</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>0.998259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, rf, with GradientBoostingClassifier</th>\n",
       "      <td>0.974777</td>\n",
       "      <td>0.971510</td>\n",
       "      <td>0.979885</td>\n",
       "      <td>0.975680</td>\n",
       "      <td>0.030675</td>\n",
       "      <td>0.020115</td>\n",
       "      <td>0.997660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Accuracy  Precision  \\\n",
       "Algorithms: all, with LogisticRegression            0.980712   0.977208   \n",
       "Algorithms: lr, rf, gb, with LogisticRegression     0.980712   0.977208   \n",
       "Algorithms: rf, gb, with LogisticRegression         0.977745   0.974359   \n",
       "Algorithms: lr, gb, with LogisticRegression         0.980712   0.977208   \n",
       "Algorithms: lr, rf, with LogisticRegression         0.977745   0.971671   \n",
       "Algorithms: all, with RandomForestClassifier        0.977745   0.974359   \n",
       "Algorithms: lr, rf, gb, with RandomForestClassi...  0.983680   0.980057   \n",
       "Algorithms: rf, gb, with RandomForestClassifier     0.974777   0.966197   \n",
       "Algorithms: lr, gb, with RandomForestClassifier     0.980712   0.977208   \n",
       "Algorithms: lr, rf, with RandomForestClassifier     0.976261   0.974286   \n",
       "Algorithms: all, with GradientBoostingClassifier    0.979228   0.974432   \n",
       "Algorithms: lr, rf, gb, with GradientBoostingCl...  0.976261   0.977011   \n",
       "Algorithms: rf, gb, with GradientBoostingClassi...  0.974777   0.971510   \n",
       "Algorithms: lr, gb, with GradientBoostingClassi...  0.974777   0.974212   \n",
       "Algorithms: lr, rf, with GradientBoostingClassi...  0.974777   0.971510   \n",
       "\n",
       "                                                      Recall  F1 Score  \\\n",
       "Algorithms: all, with LogisticRegression            0.985632  0.981402   \n",
       "Algorithms: lr, rf, gb, with LogisticRegression     0.985632  0.981402   \n",
       "Algorithms: rf, gb, with LogisticRegression         0.982759  0.978541   \n",
       "Algorithms: lr, gb, with LogisticRegression         0.985632  0.981402   \n",
       "Algorithms: lr, rf, with LogisticRegression         0.985632  0.978602   \n",
       "Algorithms: all, with RandomForestClassifier        0.982759  0.978541   \n",
       "Algorithms: lr, rf, gb, with RandomForestClassi...  0.988506  0.984263   \n",
       "Algorithms: rf, gb, with RandomForestClassifier     0.985632  0.975818   \n",
       "Algorithms: lr, gb, with RandomForestClassifier     0.985632  0.981402   \n",
       "Algorithms: lr, rf, with RandomForestClassifier     0.979885  0.977077   \n",
       "Algorithms: all, with GradientBoostingClassifier    0.985632  0.980000   \n",
       "Algorithms: lr, rf, gb, with GradientBoostingCl...  0.977011  0.977011   \n",
       "Algorithms: rf, gb, with GradientBoostingClassi...  0.979885  0.975680   \n",
       "Algorithms: lr, gb, with GradientBoostingClassi...  0.977011  0.975610   \n",
       "Algorithms: lr, rf, with GradientBoostingClassi...  0.979885  0.975680   \n",
       "\n",
       "                                                    False Positive Rate  \\\n",
       "Algorithms: all, with LogisticRegression                       0.024540   \n",
       "Algorithms: lr, rf, gb, with LogisticRegression                0.024540   \n",
       "Algorithms: rf, gb, with LogisticRegression                    0.027607   \n",
       "Algorithms: lr, gb, with LogisticRegression                    0.024540   \n",
       "Algorithms: lr, rf, with LogisticRegression                    0.030675   \n",
       "Algorithms: all, with RandomForestClassifier                   0.027607   \n",
       "Algorithms: lr, rf, gb, with RandomForestClassi...             0.021472   \n",
       "Algorithms: rf, gb, with RandomForestClassifier                0.036810   \n",
       "Algorithms: lr, gb, with RandomForestClassifier                0.024540   \n",
       "Algorithms: lr, rf, with RandomForestClassifier                0.027607   \n",
       "Algorithms: all, with GradientBoostingClassifier               0.027607   \n",
       "Algorithms: lr, rf, gb, with GradientBoostingCl...             0.024540   \n",
       "Algorithms: rf, gb, with GradientBoostingClassi...             0.030675   \n",
       "Algorithms: lr, gb, with GradientBoostingClassi...             0.027607   \n",
       "Algorithms: lr, rf, with GradientBoostingClassi...             0.030675   \n",
       "\n",
       "                                                    False Negative Rate  \\\n",
       "Algorithms: all, with LogisticRegression                       0.014368   \n",
       "Algorithms: lr, rf, gb, with LogisticRegression                0.014368   \n",
       "Algorithms: rf, gb, with LogisticRegression                    0.017241   \n",
       "Algorithms: lr, gb, with LogisticRegression                    0.014368   \n",
       "Algorithms: lr, rf, with LogisticRegression                    0.014368   \n",
       "Algorithms: all, with RandomForestClassifier                   0.017241   \n",
       "Algorithms: lr, rf, gb, with RandomForestClassi...             0.011494   \n",
       "Algorithms: rf, gb, with RandomForestClassifier                0.014368   \n",
       "Algorithms: lr, gb, with RandomForestClassifier                0.014368   \n",
       "Algorithms: lr, rf, with RandomForestClassifier                0.020115   \n",
       "Algorithms: all, with GradientBoostingClassifier               0.014368   \n",
       "Algorithms: lr, rf, gb, with GradientBoostingCl...             0.022989   \n",
       "Algorithms: rf, gb, with GradientBoostingClassi...             0.020115   \n",
       "Algorithms: lr, gb, with GradientBoostingClassi...             0.022989   \n",
       "Algorithms: lr, rf, with GradientBoostingClassi...             0.020115   \n",
       "\n",
       "                                                    Area Under ROC Curve  \n",
       "Algorithms: all, with LogisticRegression                        0.998378  \n",
       "Algorithms: lr, rf, gb, with LogisticRegression                 0.998493  \n",
       "Algorithms: rf, gb, with LogisticRegression                     0.997602  \n",
       "Algorithms: lr, gb, with LogisticRegression                     0.998598  \n",
       "Algorithms: lr, rf, with LogisticRegression                     0.997576  \n",
       "Algorithms: all, with RandomForestClassifier                    0.997237  \n",
       "Algorithms: lr, rf, gb, with RandomForestClassi...              0.997695  \n",
       "Algorithms: rf, gb, with RandomForestClassifier                 0.997104  \n",
       "Algorithms: lr, gb, with RandomForestClassifier                 0.998510  \n",
       "Algorithms: lr, rf, with RandomForestClassifier                 0.996928  \n",
       "Algorithms: all, with GradientBoostingClassifier                0.998078  \n",
       "Algorithms: lr, rf, gb, with GradientBoostingCl...              0.997770  \n",
       "Algorithms: rf, gb, with GradientBoostingClassi...              0.996893  \n",
       "Algorithms: lr, gb, with GradientBoostingClassi...              0.998259  \n",
       "Algorithms: lr, rf, with GradientBoostingClassi...              0.997660  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_stacking_balanced_multi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4da4f4d",
   "metadata": {},
   "source": [
    "As expected, using more than one classifier consistently improves the classification accuracy for both LR and RF. The best level 1 classifier seems to be Random Forest, and Logistic Regression gives better results when used as a level 0 classifier. However, all combinations performed quite well, except for some time in Gradient Boosting.\n",
    "\n",
    "On the other hand, Naive Bayes and Decision Tree classifiers do not affect the result at all or even reduce the accuracy so from now on they will be excluded in order to reduce the execution time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b21358",
   "metadata": {},
   "source": [
    "The top 10 models will be added to the best model results dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "83adf932",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stacking_balanced_best = pd.concat([results_stacking_balanced_best, results_stacking_balanced_multi.sort_values(by=['F1 Score'], ascending = [False]).head(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8e49ade4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stacking_balanced_full = pd.concat([results_stacking_balanced_full, results_stacking_balanced_multi])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28750c26",
   "metadata": {},
   "source": [
    "### Appending all features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c16a89",
   "metadata": {},
   "source": [
    "Another variation of stacking includes appending the predictions to the other feature sets and then train the final classifier with all the features.<br>\n",
    "Since using both feature sets has been proven to improve accuracy on the baselines, the predictions will be appended to the merged feature set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "46e9a9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stacking_balanced_append = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d413228",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "db748200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 16s, sys: 1min 48s, total: 5min 4s\n",
      "Wall time: 2min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], exclude_models=[], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=[], append_features=True, result_row_name=\"Algorithms: all, with LogisticRegression (with appended features)\")\n",
    "results_stacking_balanced_append = pd.concat([results_stacking_balanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], exclude_models=['dt', 'nb'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb'], append_features=True)\n",
    "results_stacking_balanced_append = pd.concat([results_stacking_balanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], exclude_models=['dt', 'nb', 'lr'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'lr'], append_features=True)\n",
    "results_stacking_balanced_append = pd.concat([results_stacking_balanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], exclude_models=['dt', 'nb', 'rf'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'rf'], append_features=True)\n",
    "results_stacking_balanced_append = pd.concat([results_stacking_balanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], exclude_models=['dt', 'nb', 'gb'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb'], append_features=True)\n",
    "results_stacking_balanced_append = pd.concat([results_stacking_balanced_append, stacked_preds['results']])\n",
    "\n",
    "# Single level 0\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], exclude_models=['dt', 'nb', 'gb', 'rf'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb', 'rf'], append_features=True)\n",
    "results_stacking_balanced_append = pd.concat([results_stacking_balanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], exclude_models=['dt', 'nb', 'gb', 'lr'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb', 'lr'], append_features=True)\n",
    "results_stacking_balanced_append = pd.concat([results_stacking_balanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], exclude_models=['dt', 'nb', 'rf', 'lr'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'rf', 'lr'], append_features=True)\n",
    "results_stacking_balanced_append = pd.concat([results_stacking_balanced_append, stacked_preds['results']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0882cf89",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e8085c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 22s, sys: 2min 4s, total: 5min 26s\n",
      "Wall time: 2min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=rf, exclude_models=[], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=[], append_features=True, result_row_name=\"Algorithms: all, with RandomForestClassifier (with appended features)\")\n",
    "results_stacking_balanced_append = pd.concat([results_stacking_balanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=rf, exclude_models=['dt', 'nb'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb'], append_features=True)\n",
    "results_stacking_balanced_append = pd.concat([results_stacking_balanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=rf, exclude_models=['dt', 'nb', 'lr'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'lr'], append_features=True)\n",
    "results_stacking_balanced_append = pd.concat([results_stacking_balanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=rf, exclude_models=['dt', 'nb', 'rf'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'rf'], append_features=True)\n",
    "results_stacking_balanced_append = pd.concat([results_stacking_balanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=rf, exclude_models=['dt', 'nb', 'gb'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb'], append_features=True)\n",
    "results_stacking_balanced_append = pd.concat([results_stacking_balanced_append, stacked_preds['results']])\n",
    "\n",
    "# Single level 0\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=rf, exclude_models=['dt', 'nb', 'gb', 'rf'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb', 'rf'], append_features=True)\n",
    "results_stacking_balanced_append = pd.concat([results_stacking_balanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=rf, exclude_models=['dt', 'nb', 'gb', 'lr'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb', 'lr'], append_features=True)\n",
    "results_stacking_balanced_append = pd.concat([results_stacking_balanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=rf, exclude_models=['dt', 'nb', 'rf', 'lr'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'rf', 'lr'], append_features=True)\n",
    "results_stacking_balanced_append = pd.concat([results_stacking_balanced_append, stacked_preds['results']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbef30e",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0553dc00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 5s, sys: 1min 33s, total: 5min 39s\n",
      "Wall time: 3min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=gb, exclude_models=[], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=[], append_features=True, result_row_name=\"Algorithms: all, with GradientBoostingClassifier (with appended features)\")\n",
    "results_stacking_balanced_append = pd.concat([results_stacking_balanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=gb, exclude_models=['dt', 'nb'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb'], append_features=True)\n",
    "results_stacking_balanced_append = pd.concat([results_stacking_balanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=gb, exclude_models=['dt', 'nb', 'lr'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'lr'], append_features=True)\n",
    "results_stacking_balanced_append = pd.concat([results_stacking_balanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=gb, exclude_models=['dt', 'nb', 'rf'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'rf'], append_features=True)\n",
    "results_stacking_balanced_append = pd.concat([results_stacking_balanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=gb, exclude_models=['dt', 'nb', 'gb'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb'], append_features=True)\n",
    "results_stacking_balanced_append = pd.concat([results_stacking_balanced_append, stacked_preds['results']])\n",
    "\n",
    "# Single level 0\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=gb, exclude_models=['dt', 'nb', 'gb', 'rf'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb', 'rf'], append_features=True)\n",
    "results_stacking_balanced_append = pd.concat([results_stacking_balanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=gb, exclude_models=['dt', 'nb', 'gb', 'lr'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb', 'lr'], append_features=True)\n",
    "results_stacking_balanced_append = pd.concat([results_stacking_balanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=gb, exclude_models=['dt', 'nb', 'rf', 'lr'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'rf', 'lr'], append_features=True)\n",
    "results_stacking_balanced_append = pd.concat([results_stacking_balanced_append, stacked_preds['results']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dc780ce8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>Area Under ROC Curve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Algorithms: all, with LogisticRegression (with appended features)</th>\n",
       "      <td>0.964392</td>\n",
       "      <td>0.962857</td>\n",
       "      <td>0.968391</td>\n",
       "      <td>0.965616</td>\n",
       "      <td>0.039877</td>\n",
       "      <td>0.031609</td>\n",
       "      <td>0.985778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, rf, gb, with LogisticRegression (with appended features)</th>\n",
       "      <td>0.964392</td>\n",
       "      <td>0.962857</td>\n",
       "      <td>0.968391</td>\n",
       "      <td>0.965616</td>\n",
       "      <td>0.039877</td>\n",
       "      <td>0.031609</td>\n",
       "      <td>0.990044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, gb, with LogisticRegression (with appended features)</th>\n",
       "      <td>0.962908</td>\n",
       "      <td>0.962751</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.964132</td>\n",
       "      <td>0.039877</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.982336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, gb, with LogisticRegression (with appended features)</th>\n",
       "      <td>0.961424</td>\n",
       "      <td>0.957386</td>\n",
       "      <td>0.968391</td>\n",
       "      <td>0.962857</td>\n",
       "      <td>0.046012</td>\n",
       "      <td>0.031609</td>\n",
       "      <td>0.978558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, rf, with LogisticRegression (with appended features)</th>\n",
       "      <td>0.961424</td>\n",
       "      <td>0.957386</td>\n",
       "      <td>0.968391</td>\n",
       "      <td>0.962857</td>\n",
       "      <td>0.046012</td>\n",
       "      <td>0.031609</td>\n",
       "      <td>0.981229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, with LogisticRegression (with appended features)</th>\n",
       "      <td>0.964392</td>\n",
       "      <td>0.960227</td>\n",
       "      <td>0.971264</td>\n",
       "      <td>0.965714</td>\n",
       "      <td>0.042945</td>\n",
       "      <td>0.028736</td>\n",
       "      <td>0.990621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, with LogisticRegression (with appended features)</th>\n",
       "      <td>0.961424</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.962751</td>\n",
       "      <td>0.042945</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.985456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: gb, with LogisticRegression (with appended features)</th>\n",
       "      <td>0.962908</td>\n",
       "      <td>0.965418</td>\n",
       "      <td>0.962644</td>\n",
       "      <td>0.964029</td>\n",
       "      <td>0.036810</td>\n",
       "      <td>0.037356</td>\n",
       "      <td>0.984980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: all, with RandomForestClassifier (with appended features)</th>\n",
       "      <td>0.976261</td>\n",
       "      <td>0.974286</td>\n",
       "      <td>0.979885</td>\n",
       "      <td>0.977077</td>\n",
       "      <td>0.027607</td>\n",
       "      <td>0.020115</td>\n",
       "      <td>0.996747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, rf, gb, with RandomForestClassifier (with appended features)</th>\n",
       "      <td>0.979228</td>\n",
       "      <td>0.974432</td>\n",
       "      <td>0.985632</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.027607</td>\n",
       "      <td>0.014368</td>\n",
       "      <td>0.997611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, gb, with RandomForestClassifier (with appended features)</th>\n",
       "      <td>0.971810</td>\n",
       "      <td>0.971347</td>\n",
       "      <td>0.974138</td>\n",
       "      <td>0.972740</td>\n",
       "      <td>0.030675</td>\n",
       "      <td>0.025862</td>\n",
       "      <td>0.996016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, gb, with RandomForestClassifier (with appended features)</th>\n",
       "      <td>0.976261</td>\n",
       "      <td>0.974286</td>\n",
       "      <td>0.979885</td>\n",
       "      <td>0.977077</td>\n",
       "      <td>0.027607</td>\n",
       "      <td>0.020115</td>\n",
       "      <td>0.997946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, rf, with RandomForestClassifier (with appended features)</th>\n",
       "      <td>0.974777</td>\n",
       "      <td>0.968839</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.975749</td>\n",
       "      <td>0.033742</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.996765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, with RandomForestClassifier (with appended features)</th>\n",
       "      <td>0.974777</td>\n",
       "      <td>0.968839</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.975749</td>\n",
       "      <td>0.033742</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.997417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, with RandomForestClassifier (with appended features)</th>\n",
       "      <td>0.974777</td>\n",
       "      <td>0.971510</td>\n",
       "      <td>0.979885</td>\n",
       "      <td>0.975680</td>\n",
       "      <td>0.030675</td>\n",
       "      <td>0.020115</td>\n",
       "      <td>0.996060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: gb, with RandomForestClassifier (with appended features)</th>\n",
       "      <td>0.977745</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.027607</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.997118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: all, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.980712</td>\n",
       "      <td>0.977208</td>\n",
       "      <td>0.985632</td>\n",
       "      <td>0.981402</td>\n",
       "      <td>0.024540</td>\n",
       "      <td>0.014368</td>\n",
       "      <td>0.998413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, rf, gb, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.980712</td>\n",
       "      <td>0.977208</td>\n",
       "      <td>0.985632</td>\n",
       "      <td>0.981402</td>\n",
       "      <td>0.024540</td>\n",
       "      <td>0.014368</td>\n",
       "      <td>0.998131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, gb, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.980712</td>\n",
       "      <td>0.977208</td>\n",
       "      <td>0.985632</td>\n",
       "      <td>0.981402</td>\n",
       "      <td>0.024540</td>\n",
       "      <td>0.014368</td>\n",
       "      <td>0.997461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, gb, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.982196</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.985632</td>\n",
       "      <td>0.982808</td>\n",
       "      <td>0.021472</td>\n",
       "      <td>0.014368</td>\n",
       "      <td>0.998290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, rf, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.980712</td>\n",
       "      <td>0.979943</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.981349</td>\n",
       "      <td>0.021472</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.997391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.983680</td>\n",
       "      <td>0.980057</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.984263</td>\n",
       "      <td>0.021472</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.997611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.974777</td>\n",
       "      <td>0.976945</td>\n",
       "      <td>0.974138</td>\n",
       "      <td>0.975540</td>\n",
       "      <td>0.024540</td>\n",
       "      <td>0.025862</td>\n",
       "      <td>0.996139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: gb, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.982196</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.985632</td>\n",
       "      <td>0.982808</td>\n",
       "      <td>0.021472</td>\n",
       "      <td>0.014368</td>\n",
       "      <td>0.997893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Accuracy  Precision  \\\n",
       "Algorithms: all, with LogisticRegression (with ...  0.964392   0.962857   \n",
       "Algorithms: lr, rf, gb, with LogisticRegression...  0.964392   0.962857   \n",
       "Algorithms: rf, gb, with LogisticRegression (wi...  0.962908   0.962751   \n",
       "Algorithms: lr, gb, with LogisticRegression (wi...  0.961424   0.957386   \n",
       "Algorithms: lr, rf, with LogisticRegression (wi...  0.961424   0.957386   \n",
       "Algorithms: lr, with LogisticRegression (with a...  0.964392   0.960227   \n",
       "Algorithms: rf, with LogisticRegression (with a...  0.961424   0.960000   \n",
       "Algorithms: gb, with LogisticRegression (with a...  0.962908   0.965418   \n",
       "Algorithms: all, with RandomForestClassifier (w...  0.976261   0.974286   \n",
       "Algorithms: lr, rf, gb, with RandomForestClassi...  0.979228   0.974432   \n",
       "Algorithms: rf, gb, with RandomForestClassifier...  0.971810   0.971347   \n",
       "Algorithms: lr, gb, with RandomForestClassifier...  0.976261   0.974286   \n",
       "Algorithms: lr, rf, with RandomForestClassifier...  0.974777   0.968839   \n",
       "Algorithms: lr, with RandomForestClassifier (wi...  0.974777   0.968839   \n",
       "Algorithms: rf, with RandomForestClassifier (wi...  0.974777   0.971510   \n",
       "Algorithms: gb, with RandomForestClassifier (wi...  0.977745   0.974359   \n",
       "Algorithms: all, with GradientBoostingClassifie...  0.980712   0.977208   \n",
       "Algorithms: lr, rf, gb, with GradientBoostingCl...  0.980712   0.977208   \n",
       "Algorithms: rf, gb, with GradientBoostingClassi...  0.980712   0.977208   \n",
       "Algorithms: lr, gb, with GradientBoostingClassi...  0.982196   0.980000   \n",
       "Algorithms: lr, rf, with GradientBoostingClassi...  0.980712   0.979943   \n",
       "Algorithms: lr, with GradientBoostingClassifier...  0.983680   0.980057   \n",
       "Algorithms: rf, with GradientBoostingClassifier...  0.974777   0.976945   \n",
       "Algorithms: gb, with GradientBoostingClassifier...  0.982196   0.980000   \n",
       "\n",
       "                                                      Recall  F1 Score  \\\n",
       "Algorithms: all, with LogisticRegression (with ...  0.968391  0.965616   \n",
       "Algorithms: lr, rf, gb, with LogisticRegression...  0.968391  0.965616   \n",
       "Algorithms: rf, gb, with LogisticRegression (wi...  0.965517  0.964132   \n",
       "Algorithms: lr, gb, with LogisticRegression (wi...  0.968391  0.962857   \n",
       "Algorithms: lr, rf, with LogisticRegression (wi...  0.968391  0.962857   \n",
       "Algorithms: lr, with LogisticRegression (with a...  0.971264  0.965714   \n",
       "Algorithms: rf, with LogisticRegression (with a...  0.965517  0.962751   \n",
       "Algorithms: gb, with LogisticRegression (with a...  0.962644  0.964029   \n",
       "Algorithms: all, with RandomForestClassifier (w...  0.979885  0.977077   \n",
       "Algorithms: lr, rf, gb, with RandomForestClassi...  0.985632  0.980000   \n",
       "Algorithms: rf, gb, with RandomForestClassifier...  0.974138  0.972740   \n",
       "Algorithms: lr, gb, with RandomForestClassifier...  0.979885  0.977077   \n",
       "Algorithms: lr, rf, with RandomForestClassifier...  0.982759  0.975749   \n",
       "Algorithms: lr, with RandomForestClassifier (wi...  0.982759  0.975749   \n",
       "Algorithms: rf, with RandomForestClassifier (wi...  0.979885  0.975680   \n",
       "Algorithms: gb, with RandomForestClassifier (wi...  0.982759  0.978541   \n",
       "Algorithms: all, with GradientBoostingClassifie...  0.985632  0.981402   \n",
       "Algorithms: lr, rf, gb, with GradientBoostingCl...  0.985632  0.981402   \n",
       "Algorithms: rf, gb, with GradientBoostingClassi...  0.985632  0.981402   \n",
       "Algorithms: lr, gb, with GradientBoostingClassi...  0.985632  0.982808   \n",
       "Algorithms: lr, rf, with GradientBoostingClassi...  0.982759  0.981349   \n",
       "Algorithms: lr, with GradientBoostingClassifier...  0.988506  0.984263   \n",
       "Algorithms: rf, with GradientBoostingClassifier...  0.974138  0.975540   \n",
       "Algorithms: gb, with GradientBoostingClassifier...  0.985632  0.982808   \n",
       "\n",
       "                                                    False Positive Rate  \\\n",
       "Algorithms: all, with LogisticRegression (with ...             0.039877   \n",
       "Algorithms: lr, rf, gb, with LogisticRegression...             0.039877   \n",
       "Algorithms: rf, gb, with LogisticRegression (wi...             0.039877   \n",
       "Algorithms: lr, gb, with LogisticRegression (wi...             0.046012   \n",
       "Algorithms: lr, rf, with LogisticRegression (wi...             0.046012   \n",
       "Algorithms: lr, with LogisticRegression (with a...             0.042945   \n",
       "Algorithms: rf, with LogisticRegression (with a...             0.042945   \n",
       "Algorithms: gb, with LogisticRegression (with a...             0.036810   \n",
       "Algorithms: all, with RandomForestClassifier (w...             0.027607   \n",
       "Algorithms: lr, rf, gb, with RandomForestClassi...             0.027607   \n",
       "Algorithms: rf, gb, with RandomForestClassifier...             0.030675   \n",
       "Algorithms: lr, gb, with RandomForestClassifier...             0.027607   \n",
       "Algorithms: lr, rf, with RandomForestClassifier...             0.033742   \n",
       "Algorithms: lr, with RandomForestClassifier (wi...             0.033742   \n",
       "Algorithms: rf, with RandomForestClassifier (wi...             0.030675   \n",
       "Algorithms: gb, with RandomForestClassifier (wi...             0.027607   \n",
       "Algorithms: all, with GradientBoostingClassifie...             0.024540   \n",
       "Algorithms: lr, rf, gb, with GradientBoostingCl...             0.024540   \n",
       "Algorithms: rf, gb, with GradientBoostingClassi...             0.024540   \n",
       "Algorithms: lr, gb, with GradientBoostingClassi...             0.021472   \n",
       "Algorithms: lr, rf, with GradientBoostingClassi...             0.021472   \n",
       "Algorithms: lr, with GradientBoostingClassifier...             0.021472   \n",
       "Algorithms: rf, with GradientBoostingClassifier...             0.024540   \n",
       "Algorithms: gb, with GradientBoostingClassifier...             0.021472   \n",
       "\n",
       "                                                    False Negative Rate  \\\n",
       "Algorithms: all, with LogisticRegression (with ...             0.031609   \n",
       "Algorithms: lr, rf, gb, with LogisticRegression...             0.031609   \n",
       "Algorithms: rf, gb, with LogisticRegression (wi...             0.034483   \n",
       "Algorithms: lr, gb, with LogisticRegression (wi...             0.031609   \n",
       "Algorithms: lr, rf, with LogisticRegression (wi...             0.031609   \n",
       "Algorithms: lr, with LogisticRegression (with a...             0.028736   \n",
       "Algorithms: rf, with LogisticRegression (with a...             0.034483   \n",
       "Algorithms: gb, with LogisticRegression (with a...             0.037356   \n",
       "Algorithms: all, with RandomForestClassifier (w...             0.020115   \n",
       "Algorithms: lr, rf, gb, with RandomForestClassi...             0.014368   \n",
       "Algorithms: rf, gb, with RandomForestClassifier...             0.025862   \n",
       "Algorithms: lr, gb, with RandomForestClassifier...             0.020115   \n",
       "Algorithms: lr, rf, with RandomForestClassifier...             0.017241   \n",
       "Algorithms: lr, with RandomForestClassifier (wi...             0.017241   \n",
       "Algorithms: rf, with RandomForestClassifier (wi...             0.020115   \n",
       "Algorithms: gb, with RandomForestClassifier (wi...             0.017241   \n",
       "Algorithms: all, with GradientBoostingClassifie...             0.014368   \n",
       "Algorithms: lr, rf, gb, with GradientBoostingCl...             0.014368   \n",
       "Algorithms: rf, gb, with GradientBoostingClassi...             0.014368   \n",
       "Algorithms: lr, gb, with GradientBoostingClassi...             0.014368   \n",
       "Algorithms: lr, rf, with GradientBoostingClassi...             0.017241   \n",
       "Algorithms: lr, with GradientBoostingClassifier...             0.011494   \n",
       "Algorithms: rf, with GradientBoostingClassifier...             0.025862   \n",
       "Algorithms: gb, with GradientBoostingClassifier...             0.014368   \n",
       "\n",
       "                                                    Area Under ROC Curve  \n",
       "Algorithms: all, with LogisticRegression (with ...              0.985778  \n",
       "Algorithms: lr, rf, gb, with LogisticRegression...              0.990044  \n",
       "Algorithms: rf, gb, with LogisticRegression (wi...              0.982336  \n",
       "Algorithms: lr, gb, with LogisticRegression (wi...              0.978558  \n",
       "Algorithms: lr, rf, with LogisticRegression (wi...              0.981229  \n",
       "Algorithms: lr, with LogisticRegression (with a...              0.990621  \n",
       "Algorithms: rf, with LogisticRegression (with a...              0.985456  \n",
       "Algorithms: gb, with LogisticRegression (with a...              0.984980  \n",
       "Algorithms: all, with RandomForestClassifier (w...              0.996747  \n",
       "Algorithms: lr, rf, gb, with RandomForestClassi...              0.997611  \n",
       "Algorithms: rf, gb, with RandomForestClassifier...              0.996016  \n",
       "Algorithms: lr, gb, with RandomForestClassifier...              0.997946  \n",
       "Algorithms: lr, rf, with RandomForestClassifier...              0.996765  \n",
       "Algorithms: lr, with RandomForestClassifier (wi...              0.997417  \n",
       "Algorithms: rf, with RandomForestClassifier (wi...              0.996060  \n",
       "Algorithms: gb, with RandomForestClassifier (wi...              0.997118  \n",
       "Algorithms: all, with GradientBoostingClassifie...              0.998413  \n",
       "Algorithms: lr, rf, gb, with GradientBoostingCl...              0.998131  \n",
       "Algorithms: rf, gb, with GradientBoostingClassi...              0.997461  \n",
       "Algorithms: lr, gb, with GradientBoostingClassi...              0.998290  \n",
       "Algorithms: lr, rf, with GradientBoostingClassi...              0.997391  \n",
       "Algorithms: lr, with GradientBoostingClassifier...              0.997611  \n",
       "Algorithms: rf, with GradientBoostingClassifier...              0.996139  \n",
       "Algorithms: gb, with GradientBoostingClassifier...              0.997893  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_stacking_balanced_append"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dec3450",
   "metadata": {},
   "source": [
    "Adding the initial feature sets to the final classifier seems to mostly harm performance on the balanced dataset. This is most likely due to overfitting, since the level 1 classifier becomes extremely specialized at recognizing the emails provided in the training set and fails to generalize for the test set.\n",
    "\n",
    "However, when using Gradient Boosting as the final classifier, it manages at some cases to outperform the model without the appended features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e7f3f1",
   "metadata": {},
   "source": [
    "The top 12 of these models will be added to the best result dataset, for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eb3c8314",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stacking_balanced_best = pd.concat([results_stacking_balanced_best, results_stacking_balanced_append.sort_values(by=['F1 Score'], ascending = [False]).head(12)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cc366408",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stacking_balanced_full = pd.concat([results_stacking_balanced_full, results_stacking_balanced_append])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708c9fe3",
   "metadata": {},
   "source": [
    "### Merged Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842d8dac",
   "metadata": {},
   "source": [
    "Finally, for the sake of completeness, try stacking the level 0 classifiers that were trained with the merged dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "09253e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature_sets_balanced_merged = [{'name': 'merge', 'features': style_content_train_balanced}]\n",
    "test_feature_sets_balanced_merged = [{'name': 'merge', 'features': style_content_test_balanced}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0c764d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_merged_balanced = {'model' : lr_style_content_balanced, 'scaler': lr_style_content_balanced_scaler}\n",
    "nb_merged_balanced = {'model' : nb_style_content_balanced, 'scaler': nb_style_content_balanced_scaler}\n",
    "\n",
    "merged_models_balanced = [{'name' : 'lr', 'features' : 'merge', 'model' : lr_merged_balanced},\n",
    "                          {'name' : 'dt', 'features' : 'merge', 'model' : dt_style_content_balanced},\n",
    "                          {'name' : 'rf', 'features' : 'merge', 'model' : rf_style_content_balanced},\n",
    "                          {'name' : 'gb', 'features' : 'merge', 'model' : gb_style_content_balanced},\n",
    "                          {'name' : 'nb', 'features' : 'merge', 'model' : nb_merged_balanced}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e86b752c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stacking_balanced_merged = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2afbfb",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "556ed9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 3s, sys: 28.5 s, total: 3min 31s\n",
      "Wall time: 2min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stacked_clf = ml.train_stacked_models(merged_models_balanced, train_feature_sets_balanced_merged, style_train_balanced['target'], exclude_models=['dt', 'nb'], append_features=False)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_balanced, test_feature_sets_balanced_merged, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb'], append_features=False, result_row_name=\"Algorithms: lr, rf, gb merged, with LogisticRegression\")\n",
    "results_stacking_balanced_merged = pd.concat([results_stacking_balanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_balanced, train_feature_sets_balanced_merged, style_train_balanced['target'], exclude_models=['dt', 'nb', 'lr'], append_features=False)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_balanced, test_feature_sets_balanced_merged, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'lr'], append_features=False, result_row_name=\"Algorithms: rf, gb merged, with LogisticRegression\")\n",
    "results_stacking_balanced_merged = pd.concat([results_stacking_balanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_balanced, train_feature_sets_balanced_merged, style_train_balanced['target'], exclude_models=['dt', 'nb', 'rf'], append_features=False)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_balanced, test_feature_sets_balanced_merged, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'rf'], append_features=False, result_row_name=\"Algorithms: lr, gb merged, with LogisticRegression\")\n",
    "results_stacking_balanced_merged = pd.concat([results_stacking_balanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_balanced, train_feature_sets_balanced_merged, style_train_balanced['target'], exclude_models=['dt', 'nb', 'gb'], append_features=False)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_balanced, test_feature_sets_balanced_merged, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb'], append_features=False, result_row_name=\"Algorithms: rf, lr merged, with LogisticRegression\")\n",
    "results_stacking_balanced_merged = pd.concat([results_stacking_balanced_merged, stacked_preds['results']])\n",
    "\n",
    "# Append features\n",
    "stacked_clf = ml.train_stacked_models(merged_models_balanced, train_feature_sets_balanced_merged, style_train_balanced['target'], exclude_models=['dt', 'nb'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_balanced, test_feature_sets_balanced_merged, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb'], append_features=True, result_row_name=\"Algorithms: lr, rf, gb merged, with LogisticRegression (with appended features)\")\n",
    "results_stacking_balanced_merged = pd.concat([results_stacking_balanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_balanced, train_feature_sets_balanced_merged, style_train_balanced['target'], exclude_models=['dt', 'nb', 'lr'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_balanced, test_feature_sets_balanced_merged, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'lr'], append_features=True, result_row_name=\"Algorithms: rf, gb merged, with LogisticRegression (with appended features)\")\n",
    "results_stacking_balanced_merged = pd.concat([results_stacking_balanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_balanced, train_feature_sets_balanced_merged, style_train_balanced['target'], exclude_models=['dt', 'nb', 'rf'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_balanced, test_feature_sets_balanced_merged, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'rf'], append_features=True, result_row_name=\"Algorithms: lr, gb merged, with LogisticRegression (with appended features)\")\n",
    "results_stacking_balanced_merged = pd.concat([results_stacking_balanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_balanced, train_feature_sets_balanced_merged, style_train_balanced['target'], exclude_models=['dt', 'nb', 'gb'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_balanced, test_feature_sets_balanced_merged, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb'], append_features=True, result_row_name=\"Algorithms: rf, lr merged, with LogisticRegression (with appended features)\")\n",
    "results_stacking_balanced_merged = pd.concat([results_stacking_balanced_merged, stacked_preds['results']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c4f4bf",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b772f8b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 59s, sys: 20.1 s, total: 3min 19s\n",
      "Wall time: 2min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stacked_clf = ml.train_stacked_models(merged_models_balanced, train_feature_sets_balanced_merged, style_train_balanced['target'], final_classifier=rf, exclude_models=['dt', 'nb'], append_features=False)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_balanced, test_feature_sets_balanced_merged, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb'], append_features=False, result_row_name=\"Algorithms: lr, rf, gb merged, with RandomForestClassifier\")\n",
    "results_stacking_balanced_merged = pd.concat([results_stacking_balanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_balanced, train_feature_sets_balanced_merged, style_train_balanced['target'], final_classifier=rf, exclude_models=['dt', 'nb', 'lr'], append_features=False)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_balanced, test_feature_sets_balanced_merged, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'lr'], append_features=False, result_row_name=\"Algorithms: rf, gb merged, with RandomForestClassifier\")\n",
    "results_stacking_balanced_merged = pd.concat([results_stacking_balanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_balanced, train_feature_sets_balanced_merged, style_train_balanced['target'], final_classifier=rf, exclude_models=['dt', 'nb', 'rf'], append_features=False)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_balanced, test_feature_sets_balanced_merged, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'rf'], append_features=False, result_row_name=\"Algorithms: lr, gb merged, with RandomForestClassifier\")\n",
    "results_stacking_balanced_merged = pd.concat([results_stacking_balanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_balanced, train_feature_sets_balanced_merged, style_train_balanced['target'], final_classifier=rf, exclude_models=['dt', 'nb', 'gb'], append_features=False)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_balanced, test_feature_sets_balanced_merged, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb'], append_features=False, result_row_name=\"Algorithms: rf, lr merged, with RandomForestClassifier\")\n",
    "results_stacking_balanced_merged = pd.concat([results_stacking_balanced_merged, stacked_preds['results']])\n",
    "\n",
    "# Append features\n",
    "stacked_clf = ml.train_stacked_models(merged_models_balanced, train_feature_sets_balanced_merged, style_train_balanced['target'], final_classifier=rf, exclude_models=['dt', 'nb'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_balanced, test_feature_sets_balanced_merged, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb'], append_features=True, result_row_name=\"Algorithms: lr, rf, gb merged, with RandomForestClassifier (with appended features)\")\n",
    "results_stacking_balanced_merged = pd.concat([results_stacking_balanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_balanced, train_feature_sets_balanced_merged, style_train_balanced['target'], final_classifier=rf, exclude_models=['dt', 'nb', 'lr'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_balanced, test_feature_sets_balanced_merged, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'lr'], append_features=True, result_row_name=\"Algorithms: rf, gb merged, with RandomForestClassifier (with appended features)\")\n",
    "results_stacking_balanced_merged = pd.concat([results_stacking_balanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_balanced, train_feature_sets_balanced_merged, style_train_balanced['target'], final_classifier=rf, exclude_models=['dt', 'nb', 'rf'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_balanced, test_feature_sets_balanced_merged, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'rf'], append_features=True, result_row_name=\"Algorithms: lr, gb merged, with RandomForestClassifier (with appended features)\")\n",
    "results_stacking_balanced_merged = pd.concat([results_stacking_balanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_balanced, train_feature_sets_balanced_merged, style_train_balanced['target'], final_classifier=rf, exclude_models=['dt', 'nb', 'gb'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_balanced, test_feature_sets_balanced_merged, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb'], append_features=True, result_row_name=\"Algorithms: rf, lr merged, with RandomForestClassifier (with appended features)\")\n",
    "results_stacking_balanced_merged = pd.concat([results_stacking_balanced_merged, stacked_preds['results']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11ebbf7",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5a689a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 24s, sys: 18.9 s, total: 3min 43s\n",
      "Wall time: 3min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stacked_clf = ml.train_stacked_models(merged_models_balanced, train_feature_sets_balanced_merged, style_train_balanced['target'], final_classifier=gb, exclude_models=['dt', 'nb'], append_features=False)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_balanced, test_feature_sets_balanced_merged, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb'], append_features=False, result_row_name=\"Algorithms: lr, rf, gb merged, with GradientBoostingClassifier\")\n",
    "results_stacking_balanced_merged = pd.concat([results_stacking_balanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_balanced, train_feature_sets_balanced_merged, style_train_balanced['target'], final_classifier=gb, exclude_models=['dt', 'nb', 'lr'], append_features=False)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_balanced, test_feature_sets_balanced_merged, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'lr'], append_features=False, result_row_name=\"Algorithms: rf, gb merged, with GradientBoostingClassifier\")\n",
    "results_stacking_balanced_merged = pd.concat([results_stacking_balanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_balanced, train_feature_sets_balanced_merged, style_train_balanced['target'], final_classifier=gb, exclude_models=['dt', 'nb', 'rf'], append_features=False)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_balanced, test_feature_sets_balanced_merged, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'rf'], append_features=False, result_row_name=\"Algorithms: lr, gb merged, with GradientBoostingClassifier\")\n",
    "results_stacking_balanced_merged = pd.concat([results_stacking_balanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_balanced, train_feature_sets_balanced_merged, style_train_balanced['target'], final_classifier=gb, exclude_models=['dt', 'nb', 'gb'], append_features=False)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_balanced, test_feature_sets_balanced_merged, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb'], append_features=False, result_row_name=\"Algorithms: rf, lr merged, with GradientBoostingClassifier\")\n",
    "results_stacking_balanced_merged = pd.concat([results_stacking_balanced_merged, stacked_preds['results']])\n",
    "\n",
    "# Append features\n",
    "stacked_clf = ml.train_stacked_models(merged_models_balanced, train_feature_sets_balanced_merged, style_train_balanced['target'], final_classifier=gb, exclude_models=['dt', 'nb'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_balanced, test_feature_sets_balanced_merged, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb'], append_features=True, result_row_name=\"Algorithms: lr, rf, gb merged, with GradientBoostingClassifier (with appended features)\")\n",
    "results_stacking_balanced_merged = pd.concat([results_stacking_balanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_balanced, train_feature_sets_balanced_merged, style_train_balanced['target'], final_classifier=gb, exclude_models=['dt', 'nb', 'lr'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_balanced, test_feature_sets_balanced_merged, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'lr'], append_features=True, result_row_name=\"Algorithms: rf, gb merged, with GradientBoostingClassifier (with appended features)\")\n",
    "results_stacking_balanced_merged = pd.concat([results_stacking_balanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_balanced, train_feature_sets_balanced_merged, style_train_balanced['target'], final_classifier=gb, exclude_models=['dt', 'nb', 'rf'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_balanced, test_feature_sets_balanced_merged, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'rf'], append_features=True, result_row_name=\"Algorithms: lr, gb merged, with GradientBoostingClassifier (with appended features)\")\n",
    "results_stacking_balanced_merged = pd.concat([results_stacking_balanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_balanced, train_feature_sets_balanced_merged, style_train_balanced['target'], final_classifier=gb, exclude_models=['dt', 'nb', 'gb'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_balanced, test_feature_sets_balanced_merged, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb'], append_features=True, result_row_name=\"Algorithms: rf, lr merged, with GradientBoostingClassifier (with appended features)\")\n",
    "results_stacking_balanced_merged = pd.concat([results_stacking_balanced_merged, stacked_preds['results']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9ca845f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>Area Under ROC Curve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, rf, gb merged, with LogisticRegression</th>\n",
       "      <td>0.980712</td>\n",
       "      <td>0.979943</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.981349</td>\n",
       "      <td>0.021472</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.996959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, gb merged, with LogisticRegression</th>\n",
       "      <td>0.976261</td>\n",
       "      <td>0.974286</td>\n",
       "      <td>0.979885</td>\n",
       "      <td>0.977077</td>\n",
       "      <td>0.027607</td>\n",
       "      <td>0.020115</td>\n",
       "      <td>0.996421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, gb merged, with LogisticRegression</th>\n",
       "      <td>0.979228</td>\n",
       "      <td>0.977143</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.979943</td>\n",
       "      <td>0.024540</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.996474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, lr merged, with LogisticRegression</th>\n",
       "      <td>0.974777</td>\n",
       "      <td>0.971510</td>\n",
       "      <td>0.979885</td>\n",
       "      <td>0.975680</td>\n",
       "      <td>0.030675</td>\n",
       "      <td>0.020115</td>\n",
       "      <td>0.996509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, rf, gb merged, with LogisticRegression (with appended features)</th>\n",
       "      <td>0.971810</td>\n",
       "      <td>0.968661</td>\n",
       "      <td>0.977011</td>\n",
       "      <td>0.972818</td>\n",
       "      <td>0.033742</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>0.978660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, gb merged, with LogisticRegression (with appended features)</th>\n",
       "      <td>0.964392</td>\n",
       "      <td>0.957627</td>\n",
       "      <td>0.974138</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.046012</td>\n",
       "      <td>0.025862</td>\n",
       "      <td>0.979312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, gb merged, with LogisticRegression (with appended features)</th>\n",
       "      <td>0.965875</td>\n",
       "      <td>0.965616</td>\n",
       "      <td>0.968391</td>\n",
       "      <td>0.967001</td>\n",
       "      <td>0.036810</td>\n",
       "      <td>0.031609</td>\n",
       "      <td>0.983067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, lr merged, with LogisticRegression (with appended features)</th>\n",
       "      <td>0.964392</td>\n",
       "      <td>0.955056</td>\n",
       "      <td>0.977011</td>\n",
       "      <td>0.965909</td>\n",
       "      <td>0.049080</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>0.989987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, rf, gb merged, with RandomForestClassifier</th>\n",
       "      <td>0.980712</td>\n",
       "      <td>0.977208</td>\n",
       "      <td>0.985632</td>\n",
       "      <td>0.981402</td>\n",
       "      <td>0.024540</td>\n",
       "      <td>0.014368</td>\n",
       "      <td>0.997356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, gb merged, with RandomForestClassifier</th>\n",
       "      <td>0.979228</td>\n",
       "      <td>0.974432</td>\n",
       "      <td>0.985632</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.027607</td>\n",
       "      <td>0.014368</td>\n",
       "      <td>0.996620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, gb merged, with RandomForestClassifier</th>\n",
       "      <td>0.979228</td>\n",
       "      <td>0.979885</td>\n",
       "      <td>0.979885</td>\n",
       "      <td>0.979885</td>\n",
       "      <td>0.021472</td>\n",
       "      <td>0.020115</td>\n",
       "      <td>0.995941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, lr merged, with RandomForestClassifier</th>\n",
       "      <td>0.974777</td>\n",
       "      <td>0.968839</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.975749</td>\n",
       "      <td>0.033742</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.995976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, rf, gb merged, with RandomForestClassifier (with appended features)</th>\n",
       "      <td>0.977745</td>\n",
       "      <td>0.971671</td>\n",
       "      <td>0.985632</td>\n",
       "      <td>0.978602</td>\n",
       "      <td>0.030675</td>\n",
       "      <td>0.014368</td>\n",
       "      <td>0.995602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, gb merged, with RandomForestClassifier (with appended features)</th>\n",
       "      <td>0.974777</td>\n",
       "      <td>0.971510</td>\n",
       "      <td>0.979885</td>\n",
       "      <td>0.975680</td>\n",
       "      <td>0.030675</td>\n",
       "      <td>0.020115</td>\n",
       "      <td>0.994914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, gb merged, with RandomForestClassifier (with appended features)</th>\n",
       "      <td>0.980712</td>\n",
       "      <td>0.977208</td>\n",
       "      <td>0.985632</td>\n",
       "      <td>0.981402</td>\n",
       "      <td>0.024540</td>\n",
       "      <td>0.014368</td>\n",
       "      <td>0.995156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, lr merged, with RandomForestClassifier (with appended features)</th>\n",
       "      <td>0.977745</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.027607</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.994848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, rf, gb merged, with GradientBoostingClassifier</th>\n",
       "      <td>0.974777</td>\n",
       "      <td>0.974212</td>\n",
       "      <td>0.977011</td>\n",
       "      <td>0.975610</td>\n",
       "      <td>0.027607</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>0.997029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, gb merged, with GradientBoostingClassifier</th>\n",
       "      <td>0.974777</td>\n",
       "      <td>0.974212</td>\n",
       "      <td>0.977011</td>\n",
       "      <td>0.975610</td>\n",
       "      <td>0.027607</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>0.996836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, gb merged, with GradientBoostingClassifier</th>\n",
       "      <td>0.971810</td>\n",
       "      <td>0.971347</td>\n",
       "      <td>0.974138</td>\n",
       "      <td>0.972740</td>\n",
       "      <td>0.030675</td>\n",
       "      <td>0.025862</td>\n",
       "      <td>0.995646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, lr merged, with GradientBoostingClassifier</th>\n",
       "      <td>0.962908</td>\n",
       "      <td>0.968116</td>\n",
       "      <td>0.959770</td>\n",
       "      <td>0.963925</td>\n",
       "      <td>0.033742</td>\n",
       "      <td>0.040230</td>\n",
       "      <td>0.983600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, rf, gb merged, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.980712</td>\n",
       "      <td>0.982709</td>\n",
       "      <td>0.979885</td>\n",
       "      <td>0.981295</td>\n",
       "      <td>0.018405</td>\n",
       "      <td>0.020115</td>\n",
       "      <td>0.997391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, gb merged, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.979228</td>\n",
       "      <td>0.977143</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.979943</td>\n",
       "      <td>0.024540</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.996977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, gb merged, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.977745</td>\n",
       "      <td>0.979827</td>\n",
       "      <td>0.977011</td>\n",
       "      <td>0.978417</td>\n",
       "      <td>0.021472</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>0.997673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, lr merged, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.983680</td>\n",
       "      <td>0.982808</td>\n",
       "      <td>0.985632</td>\n",
       "      <td>0.984218</td>\n",
       "      <td>0.018405</td>\n",
       "      <td>0.014368</td>\n",
       "      <td>0.996783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Accuracy  Precision  \\\n",
       "Algorithms: lr, rf, gb merged, with LogisticReg...  0.980712   0.979943   \n",
       "Algorithms: rf, gb merged, with LogisticRegression  0.976261   0.974286   \n",
       "Algorithms: lr, gb merged, with LogisticRegression  0.979228   0.977143   \n",
       "Algorithms: rf, lr merged, with LogisticRegression  0.974777   0.971510   \n",
       "Algorithms: lr, rf, gb merged, with LogisticReg...  0.971810   0.968661   \n",
       "Algorithms: rf, gb merged, with LogisticRegress...  0.964392   0.957627   \n",
       "Algorithms: lr, gb merged, with LogisticRegress...  0.965875   0.965616   \n",
       "Algorithms: rf, lr merged, with LogisticRegress...  0.964392   0.955056   \n",
       "Algorithms: lr, rf, gb merged, with RandomFores...  0.980712   0.977208   \n",
       "Algorithms: rf, gb merged, with RandomForestCla...  0.979228   0.974432   \n",
       "Algorithms: lr, gb merged, with RandomForestCla...  0.979228   0.979885   \n",
       "Algorithms: rf, lr merged, with RandomForestCla...  0.974777   0.968839   \n",
       "Algorithms: lr, rf, gb merged, with RandomFores...  0.977745   0.971671   \n",
       "Algorithms: rf, gb merged, with RandomForestCla...  0.974777   0.971510   \n",
       "Algorithms: lr, gb merged, with RandomForestCla...  0.980712   0.977208   \n",
       "Algorithms: rf, lr merged, with RandomForestCla...  0.977745   0.974359   \n",
       "Algorithms: lr, rf, gb merged, with GradientBoo...  0.974777   0.974212   \n",
       "Algorithms: rf, gb merged, with GradientBoostin...  0.974777   0.974212   \n",
       "Algorithms: lr, gb merged, with GradientBoostin...  0.971810   0.971347   \n",
       "Algorithms: rf, lr merged, with GradientBoostin...  0.962908   0.968116   \n",
       "Algorithms: lr, rf, gb merged, with GradientBoo...  0.980712   0.982709   \n",
       "Algorithms: rf, gb merged, with GradientBoostin...  0.979228   0.977143   \n",
       "Algorithms: lr, gb merged, with GradientBoostin...  0.977745   0.979827   \n",
       "Algorithms: rf, lr merged, with GradientBoostin...  0.983680   0.982808   \n",
       "\n",
       "                                                      Recall  F1 Score  \\\n",
       "Algorithms: lr, rf, gb merged, with LogisticReg...  0.982759  0.981349   \n",
       "Algorithms: rf, gb merged, with LogisticRegression  0.979885  0.977077   \n",
       "Algorithms: lr, gb merged, with LogisticRegression  0.982759  0.979943   \n",
       "Algorithms: rf, lr merged, with LogisticRegression  0.979885  0.975680   \n",
       "Algorithms: lr, rf, gb merged, with LogisticReg...  0.977011  0.972818   \n",
       "Algorithms: rf, gb merged, with LogisticRegress...  0.974138  0.965812   \n",
       "Algorithms: lr, gb merged, with LogisticRegress...  0.968391  0.967001   \n",
       "Algorithms: rf, lr merged, with LogisticRegress...  0.977011  0.965909   \n",
       "Algorithms: lr, rf, gb merged, with RandomFores...  0.985632  0.981402   \n",
       "Algorithms: rf, gb merged, with RandomForestCla...  0.985632  0.980000   \n",
       "Algorithms: lr, gb merged, with RandomForestCla...  0.979885  0.979885   \n",
       "Algorithms: rf, lr merged, with RandomForestCla...  0.982759  0.975749   \n",
       "Algorithms: lr, rf, gb merged, with RandomFores...  0.985632  0.978602   \n",
       "Algorithms: rf, gb merged, with RandomForestCla...  0.979885  0.975680   \n",
       "Algorithms: lr, gb merged, with RandomForestCla...  0.985632  0.981402   \n",
       "Algorithms: rf, lr merged, with RandomForestCla...  0.982759  0.978541   \n",
       "Algorithms: lr, rf, gb merged, with GradientBoo...  0.977011  0.975610   \n",
       "Algorithms: rf, gb merged, with GradientBoostin...  0.977011  0.975610   \n",
       "Algorithms: lr, gb merged, with GradientBoostin...  0.974138  0.972740   \n",
       "Algorithms: rf, lr merged, with GradientBoostin...  0.959770  0.963925   \n",
       "Algorithms: lr, rf, gb merged, with GradientBoo...  0.979885  0.981295   \n",
       "Algorithms: rf, gb merged, with GradientBoostin...  0.982759  0.979943   \n",
       "Algorithms: lr, gb merged, with GradientBoostin...  0.977011  0.978417   \n",
       "Algorithms: rf, lr merged, with GradientBoostin...  0.985632  0.984218   \n",
       "\n",
       "                                                    False Positive Rate  \\\n",
       "Algorithms: lr, rf, gb merged, with LogisticReg...             0.021472   \n",
       "Algorithms: rf, gb merged, with LogisticRegression             0.027607   \n",
       "Algorithms: lr, gb merged, with LogisticRegression             0.024540   \n",
       "Algorithms: rf, lr merged, with LogisticRegression             0.030675   \n",
       "Algorithms: lr, rf, gb merged, with LogisticReg...             0.033742   \n",
       "Algorithms: rf, gb merged, with LogisticRegress...             0.046012   \n",
       "Algorithms: lr, gb merged, with LogisticRegress...             0.036810   \n",
       "Algorithms: rf, lr merged, with LogisticRegress...             0.049080   \n",
       "Algorithms: lr, rf, gb merged, with RandomFores...             0.024540   \n",
       "Algorithms: rf, gb merged, with RandomForestCla...             0.027607   \n",
       "Algorithms: lr, gb merged, with RandomForestCla...             0.021472   \n",
       "Algorithms: rf, lr merged, with RandomForestCla...             0.033742   \n",
       "Algorithms: lr, rf, gb merged, with RandomFores...             0.030675   \n",
       "Algorithms: rf, gb merged, with RandomForestCla...             0.030675   \n",
       "Algorithms: lr, gb merged, with RandomForestCla...             0.024540   \n",
       "Algorithms: rf, lr merged, with RandomForestCla...             0.027607   \n",
       "Algorithms: lr, rf, gb merged, with GradientBoo...             0.027607   \n",
       "Algorithms: rf, gb merged, with GradientBoostin...             0.027607   \n",
       "Algorithms: lr, gb merged, with GradientBoostin...             0.030675   \n",
       "Algorithms: rf, lr merged, with GradientBoostin...             0.033742   \n",
       "Algorithms: lr, rf, gb merged, with GradientBoo...             0.018405   \n",
       "Algorithms: rf, gb merged, with GradientBoostin...             0.024540   \n",
       "Algorithms: lr, gb merged, with GradientBoostin...             0.021472   \n",
       "Algorithms: rf, lr merged, with GradientBoostin...             0.018405   \n",
       "\n",
       "                                                    False Negative Rate  \\\n",
       "Algorithms: lr, rf, gb merged, with LogisticReg...             0.017241   \n",
       "Algorithms: rf, gb merged, with LogisticRegression             0.020115   \n",
       "Algorithms: lr, gb merged, with LogisticRegression             0.017241   \n",
       "Algorithms: rf, lr merged, with LogisticRegression             0.020115   \n",
       "Algorithms: lr, rf, gb merged, with LogisticReg...             0.022989   \n",
       "Algorithms: rf, gb merged, with LogisticRegress...             0.025862   \n",
       "Algorithms: lr, gb merged, with LogisticRegress...             0.031609   \n",
       "Algorithms: rf, lr merged, with LogisticRegress...             0.022989   \n",
       "Algorithms: lr, rf, gb merged, with RandomFores...             0.014368   \n",
       "Algorithms: rf, gb merged, with RandomForestCla...             0.014368   \n",
       "Algorithms: lr, gb merged, with RandomForestCla...             0.020115   \n",
       "Algorithms: rf, lr merged, with RandomForestCla...             0.017241   \n",
       "Algorithms: lr, rf, gb merged, with RandomFores...             0.014368   \n",
       "Algorithms: rf, gb merged, with RandomForestCla...             0.020115   \n",
       "Algorithms: lr, gb merged, with RandomForestCla...             0.014368   \n",
       "Algorithms: rf, lr merged, with RandomForestCla...             0.017241   \n",
       "Algorithms: lr, rf, gb merged, with GradientBoo...             0.022989   \n",
       "Algorithms: rf, gb merged, with GradientBoostin...             0.022989   \n",
       "Algorithms: lr, gb merged, with GradientBoostin...             0.025862   \n",
       "Algorithms: rf, lr merged, with GradientBoostin...             0.040230   \n",
       "Algorithms: lr, rf, gb merged, with GradientBoo...             0.020115   \n",
       "Algorithms: rf, gb merged, with GradientBoostin...             0.017241   \n",
       "Algorithms: lr, gb merged, with GradientBoostin...             0.022989   \n",
       "Algorithms: rf, lr merged, with GradientBoostin...             0.014368   \n",
       "\n",
       "                                                    Area Under ROC Curve  \n",
       "Algorithms: lr, rf, gb merged, with LogisticReg...              0.996959  \n",
       "Algorithms: rf, gb merged, with LogisticRegression              0.996421  \n",
       "Algorithms: lr, gb merged, with LogisticRegression              0.996474  \n",
       "Algorithms: rf, lr merged, with LogisticRegression              0.996509  \n",
       "Algorithms: lr, rf, gb merged, with LogisticReg...              0.978660  \n",
       "Algorithms: rf, gb merged, with LogisticRegress...              0.979312  \n",
       "Algorithms: lr, gb merged, with LogisticRegress...              0.983067  \n",
       "Algorithms: rf, lr merged, with LogisticRegress...              0.989987  \n",
       "Algorithms: lr, rf, gb merged, with RandomFores...              0.997356  \n",
       "Algorithms: rf, gb merged, with RandomForestCla...              0.996620  \n",
       "Algorithms: lr, gb merged, with RandomForestCla...              0.995941  \n",
       "Algorithms: rf, lr merged, with RandomForestCla...              0.995976  \n",
       "Algorithms: lr, rf, gb merged, with RandomFores...              0.995602  \n",
       "Algorithms: rf, gb merged, with RandomForestCla...              0.994914  \n",
       "Algorithms: lr, gb merged, with RandomForestCla...              0.995156  \n",
       "Algorithms: rf, lr merged, with RandomForestCla...              0.994848  \n",
       "Algorithms: lr, rf, gb merged, with GradientBoo...              0.997029  \n",
       "Algorithms: rf, gb merged, with GradientBoostin...              0.996836  \n",
       "Algorithms: lr, gb merged, with GradientBoostin...              0.995646  \n",
       "Algorithms: rf, lr merged, with GradientBoostin...              0.983600  \n",
       "Algorithms: lr, rf, gb merged, with GradientBoo...              0.997391  \n",
       "Algorithms: rf, gb merged, with GradientBoostin...              0.996977  \n",
       "Algorithms: lr, gb merged, with GradientBoostin...              0.997673  \n",
       "Algorithms: rf, lr merged, with GradientBoostin...              0.996783  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_stacking_balanced_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c386719d",
   "metadata": {},
   "source": [
    "In general, the addition of the initial features on the level 1 classifier gives better results, but, while consistent, the results were not great. The results of the single level 0 classifiers were surprisingly good though for Logistic Regression and Gradient Boosting.\n",
    "\n",
    "This is likely because the level 0 classifiers were more specialized compared to training on both feature sets separately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef38cbc",
   "metadata": {},
   "source": [
    "The top 13 results will be added to the dataset for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0674bc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stacking_balanced_best = pd.concat([results_stacking_balanced_best, results_stacking_balanced_merged.sort_values(by=['F1 Score'], ascending = [False]).head(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ae8f4eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stacking_balanced_full = pd.concat([results_stacking_balanced_full, results_stacking_balanced_merged])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "95ee2de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>Area Under ROC Curve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, rf, gb, with RandomForestClassifier</th>\n",
       "      <td>0.983680</td>\n",
       "      <td>0.980057</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.984263</td>\n",
       "      <td>0.021472</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.997695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.983680</td>\n",
       "      <td>0.980057</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.984263</td>\n",
       "      <td>0.021472</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.997611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, lr merged, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.983680</td>\n",
       "      <td>0.982808</td>\n",
       "      <td>0.985632</td>\n",
       "      <td>0.984218</td>\n",
       "      <td>0.018405</td>\n",
       "      <td>0.014368</td>\n",
       "      <td>0.996783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, gb, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.982196</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.985632</td>\n",
       "      <td>0.982808</td>\n",
       "      <td>0.021472</td>\n",
       "      <td>0.014368</td>\n",
       "      <td>0.998290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: gb, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.982196</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.985632</td>\n",
       "      <td>0.982808</td>\n",
       "      <td>0.021472</td>\n",
       "      <td>0.014368</td>\n",
       "      <td>0.997893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, gb, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.980712</td>\n",
       "      <td>0.977208</td>\n",
       "      <td>0.985632</td>\n",
       "      <td>0.981402</td>\n",
       "      <td>0.024540</td>\n",
       "      <td>0.014368</td>\n",
       "      <td>0.997461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, gb merged, with RandomForestClassifier (with appended features)</th>\n",
       "      <td>0.980712</td>\n",
       "      <td>0.977208</td>\n",
       "      <td>0.985632</td>\n",
       "      <td>0.981402</td>\n",
       "      <td>0.024540</td>\n",
       "      <td>0.014368</td>\n",
       "      <td>0.995156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: all, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.980712</td>\n",
       "      <td>0.977208</td>\n",
       "      <td>0.985632</td>\n",
       "      <td>0.981402</td>\n",
       "      <td>0.024540</td>\n",
       "      <td>0.014368</td>\n",
       "      <td>0.998413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, rf, gb, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.980712</td>\n",
       "      <td>0.977208</td>\n",
       "      <td>0.985632</td>\n",
       "      <td>0.981402</td>\n",
       "      <td>0.024540</td>\n",
       "      <td>0.014368</td>\n",
       "      <td>0.998131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: all, with LogisticRegression</th>\n",
       "      <td>0.980712</td>\n",
       "      <td>0.977208</td>\n",
       "      <td>0.985632</td>\n",
       "      <td>0.981402</td>\n",
       "      <td>0.024540</td>\n",
       "      <td>0.014368</td>\n",
       "      <td>0.998378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, rf, gb, with LogisticRegression</th>\n",
       "      <td>0.980712</td>\n",
       "      <td>0.977208</td>\n",
       "      <td>0.985632</td>\n",
       "      <td>0.981402</td>\n",
       "      <td>0.024540</td>\n",
       "      <td>0.014368</td>\n",
       "      <td>0.998493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, gb, with LogisticRegression</th>\n",
       "      <td>0.980712</td>\n",
       "      <td>0.977208</td>\n",
       "      <td>0.985632</td>\n",
       "      <td>0.981402</td>\n",
       "      <td>0.024540</td>\n",
       "      <td>0.014368</td>\n",
       "      <td>0.998598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, gb, with RandomForestClassifier</th>\n",
       "      <td>0.980712</td>\n",
       "      <td>0.977208</td>\n",
       "      <td>0.985632</td>\n",
       "      <td>0.981402</td>\n",
       "      <td>0.024540</td>\n",
       "      <td>0.014368</td>\n",
       "      <td>0.998510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Accuracy  Precision  \\\n",
       "Algorithms: lr, rf, gb, with RandomForestClassi...  0.983680   0.980057   \n",
       "Algorithms: lr, with GradientBoostingClassifier...  0.983680   0.980057   \n",
       "Algorithms: rf, lr merged, with GradientBoostin...  0.983680   0.982808   \n",
       "Algorithms: lr, gb, with GradientBoostingClassi...  0.982196   0.980000   \n",
       "Algorithms: gb, with GradientBoostingClassifier...  0.982196   0.980000   \n",
       "Algorithms: rf, gb, with GradientBoostingClassi...  0.980712   0.977208   \n",
       "Algorithms: lr, gb merged, with RandomForestCla...  0.980712   0.977208   \n",
       "Algorithms: all, with GradientBoostingClassifie...  0.980712   0.977208   \n",
       "Algorithms: lr, rf, gb, with GradientBoostingCl...  0.980712   0.977208   \n",
       "Algorithms: all, with LogisticRegression            0.980712   0.977208   \n",
       "Algorithms: lr, rf, gb, with LogisticRegression     0.980712   0.977208   \n",
       "Algorithms: lr, gb, with LogisticRegression         0.980712   0.977208   \n",
       "Algorithms: lr, gb, with RandomForestClassifier     0.980712   0.977208   \n",
       "\n",
       "                                                      Recall  F1 Score  \\\n",
       "Algorithms: lr, rf, gb, with RandomForestClassi...  0.988506  0.984263   \n",
       "Algorithms: lr, with GradientBoostingClassifier...  0.988506  0.984263   \n",
       "Algorithms: rf, lr merged, with GradientBoostin...  0.985632  0.984218   \n",
       "Algorithms: lr, gb, with GradientBoostingClassi...  0.985632  0.982808   \n",
       "Algorithms: gb, with GradientBoostingClassifier...  0.985632  0.982808   \n",
       "Algorithms: rf, gb, with GradientBoostingClassi...  0.985632  0.981402   \n",
       "Algorithms: lr, gb merged, with RandomForestCla...  0.985632  0.981402   \n",
       "Algorithms: all, with GradientBoostingClassifie...  0.985632  0.981402   \n",
       "Algorithms: lr, rf, gb, with GradientBoostingCl...  0.985632  0.981402   \n",
       "Algorithms: all, with LogisticRegression            0.985632  0.981402   \n",
       "Algorithms: lr, rf, gb, with LogisticRegression     0.985632  0.981402   \n",
       "Algorithms: lr, gb, with LogisticRegression         0.985632  0.981402   \n",
       "Algorithms: lr, gb, with RandomForestClassifier     0.985632  0.981402   \n",
       "\n",
       "                                                    False Positive Rate  \\\n",
       "Algorithms: lr, rf, gb, with RandomForestClassi...             0.021472   \n",
       "Algorithms: lr, with GradientBoostingClassifier...             0.021472   \n",
       "Algorithms: rf, lr merged, with GradientBoostin...             0.018405   \n",
       "Algorithms: lr, gb, with GradientBoostingClassi...             0.021472   \n",
       "Algorithms: gb, with GradientBoostingClassifier...             0.021472   \n",
       "Algorithms: rf, gb, with GradientBoostingClassi...             0.024540   \n",
       "Algorithms: lr, gb merged, with RandomForestCla...             0.024540   \n",
       "Algorithms: all, with GradientBoostingClassifie...             0.024540   \n",
       "Algorithms: lr, rf, gb, with GradientBoostingCl...             0.024540   \n",
       "Algorithms: all, with LogisticRegression                       0.024540   \n",
       "Algorithms: lr, rf, gb, with LogisticRegression                0.024540   \n",
       "Algorithms: lr, gb, with LogisticRegression                    0.024540   \n",
       "Algorithms: lr, gb, with RandomForestClassifier                0.024540   \n",
       "\n",
       "                                                    False Negative Rate  \\\n",
       "Algorithms: lr, rf, gb, with RandomForestClassi...             0.011494   \n",
       "Algorithms: lr, with GradientBoostingClassifier...             0.011494   \n",
       "Algorithms: rf, lr merged, with GradientBoostin...             0.014368   \n",
       "Algorithms: lr, gb, with GradientBoostingClassi...             0.014368   \n",
       "Algorithms: gb, with GradientBoostingClassifier...             0.014368   \n",
       "Algorithms: rf, gb, with GradientBoostingClassi...             0.014368   \n",
       "Algorithms: lr, gb merged, with RandomForestCla...             0.014368   \n",
       "Algorithms: all, with GradientBoostingClassifie...             0.014368   \n",
       "Algorithms: lr, rf, gb, with GradientBoostingCl...             0.014368   \n",
       "Algorithms: all, with LogisticRegression                       0.014368   \n",
       "Algorithms: lr, rf, gb, with LogisticRegression                0.014368   \n",
       "Algorithms: lr, gb, with LogisticRegression                    0.014368   \n",
       "Algorithms: lr, gb, with RandomForestClassifier                0.014368   \n",
       "\n",
       "                                                    Area Under ROC Curve  \n",
       "Algorithms: lr, rf, gb, with RandomForestClassi...              0.997695  \n",
       "Algorithms: lr, with GradientBoostingClassifier...              0.997611  \n",
       "Algorithms: rf, lr merged, with GradientBoostin...              0.996783  \n",
       "Algorithms: lr, gb, with GradientBoostingClassi...              0.998290  \n",
       "Algorithms: gb, with GradientBoostingClassifier...              0.997893  \n",
       "Algorithms: rf, gb, with GradientBoostingClassi...              0.997461  \n",
       "Algorithms: lr, gb merged, with RandomForestCla...              0.995156  \n",
       "Algorithms: all, with GradientBoostingClassifie...              0.998413  \n",
       "Algorithms: lr, rf, gb, with GradientBoostingCl...              0.998131  \n",
       "Algorithms: all, with LogisticRegression                        0.998378  \n",
       "Algorithms: lr, rf, gb, with LogisticRegression                 0.998493  \n",
       "Algorithms: lr, gb, with LogisticRegression                     0.998598  \n",
       "Algorithms: lr, gb, with RandomForestClassifier                 0.998510  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_stacking_balanced_best.sort_values(by=['F1 Score'], ascending = [False]).head(13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5d1e28",
   "metadata": {},
   "source": [
    "## Imbalanced Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fb5c5a",
   "metadata": {},
   "source": [
    "#### Train Initial Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cf171aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature_sets_imbalanced = [{'name': 'style', 'features': style_train_imbalanced['features']}, {'name': 'word2vec', 'features': word2vec_train_imbalanced['features']}]\n",
    "test_feature_sets_imbalanced = [{'name': 'style', 'features': style_test_imbalanced['features']}, {'name': 'word2vec', 'features': word2vec_test_imbalanced['features']}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ae15b4bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 52.2 s, sys: 8.44 s, total: 1min\n",
      "Wall time: 48.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stacking_models_imbalanced = ml.train_models(train_feature_sets_imbalanced, style_train_imbalanced['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1be2813",
   "metadata": {},
   "source": [
    "### Single-algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2ed7ff3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stacking_imbalanced_single = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35dffe2d",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "485e9f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 26s, sys: 37.8 s, total: 4min 4s\n",
      "Wall time: 3min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], exclude_models=['dt', 'rf', 'gb', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'rf', 'gb', 'nb'])\n",
    "results_stacking_imbalanced_single = pd.concat([results_stacking_imbalanced_single, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], exclude_models=['lr', 'rf', 'gb', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['lr', 'rf', 'gb', 'nb'])\n",
    "results_stacking_imbalanced_single = pd.concat([results_stacking_imbalanced_single, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], exclude_models=['lr', 'dt', 'gb', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['lr', 'dt', 'gb', 'nb'])\n",
    "results_stacking_imbalanced_single = pd.concat([results_stacking_imbalanced_single, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], exclude_models=['lr', 'dt', 'rf', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['lr', 'dt', 'rf', 'nb'])\n",
    "results_stacking_imbalanced_single = pd.concat([results_stacking_imbalanced_single, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], exclude_models=['lr', 'dt', 'rf', 'gb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['lr', 'dt', 'rf', 'gb'])\n",
    "results_stacking_imbalanced_single = pd.concat([results_stacking_imbalanced_single, stacked_preds['results']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4326cd1",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6db39d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 27s, sys: 32.6 s, total: 3min 59s\n",
      "Wall time: 3min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=rf, exclude_models=['dt', 'rf', 'gb', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'rf', 'gb', 'nb'])\n",
    "results_stacking_imbalanced_single = pd.concat([results_stacking_imbalanced_single, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=rf, exclude_models=['lr', 'rf', 'gb', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['lr', 'rf', 'gb', 'nb'])\n",
    "results_stacking_imbalanced_single = pd.concat([results_stacking_imbalanced_single, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=rf, exclude_models=['lr', 'dt', 'gb', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['lr', 'dt', 'gb', 'nb'])\n",
    "results_stacking_imbalanced_single = pd.concat([results_stacking_imbalanced_single, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=rf, exclude_models=['lr', 'dt', 'rf', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['lr', 'dt', 'rf', 'nb'])\n",
    "results_stacking_imbalanced_single = pd.concat([results_stacking_imbalanced_single, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=rf, exclude_models=['lr', 'dt', 'rf', 'gb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['lr', 'dt', 'rf', 'gb'])\n",
    "results_stacking_imbalanced_single = pd.concat([results_stacking_imbalanced_single, stacked_preds['results']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f835fa",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0216ce62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 33s, sys: 34.8 s, total: 4min 8s\n",
      "Wall time: 3min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=gb, exclude_models=['dt', 'rf', 'gb', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'rf', 'gb', 'nb'])\n",
    "results_stacking_imbalanced_single = pd.concat([results_stacking_imbalanced_single, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=gb, exclude_models=['lr', 'rf', 'gb', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['lr', 'rf', 'gb', 'nb'])\n",
    "results_stacking_imbalanced_single = pd.concat([results_stacking_imbalanced_single, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=gb, exclude_models=['lr', 'dt', 'gb', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['lr', 'dt', 'gb', 'nb'])\n",
    "results_stacking_imbalanced_single = pd.concat([results_stacking_imbalanced_single, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=gb, exclude_models=['lr', 'dt', 'rf', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['lr', 'dt', 'rf', 'nb'])\n",
    "results_stacking_imbalanced_single = pd.concat([results_stacking_imbalanced_single, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=gb, exclude_models=['lr', 'dt', 'rf', 'gb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['lr', 'dt', 'rf', 'gb'])\n",
    "results_stacking_imbalanced_single = pd.concat([results_stacking_imbalanced_single, stacked_preds['results']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8bf20b33",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>Area Under ROC Curve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, with LogisticRegression</th>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.970492</td>\n",
       "      <td>0.913580</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>0.086420</td>\n",
       "      <td>0.993451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: dt, with LogisticRegression</th>\n",
       "      <td>0.983514</td>\n",
       "      <td>0.925566</td>\n",
       "      <td>0.882716</td>\n",
       "      <td>0.903633</td>\n",
       "      <td>0.006813</td>\n",
       "      <td>0.117284</td>\n",
       "      <td>0.981280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, with LogisticRegression</th>\n",
       "      <td>0.988108</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.907407</td>\n",
       "      <td>0.930380</td>\n",
       "      <td>0.004147</td>\n",
       "      <td>0.092593</td>\n",
       "      <td>0.993587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: gb, with LogisticRegression</th>\n",
       "      <td>0.991351</td>\n",
       "      <td>0.962025</td>\n",
       "      <td>0.938272</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.003555</td>\n",
       "      <td>0.061728</td>\n",
       "      <td>0.997418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: nb, with LogisticRegression</th>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.836601</td>\n",
       "      <td>0.009479</td>\n",
       "      <td>0.209877</td>\n",
       "      <td>0.989689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, with RandomForestClassifier</th>\n",
       "      <td>0.989189</td>\n",
       "      <td>0.964052</td>\n",
       "      <td>0.910494</td>\n",
       "      <td>0.936508</td>\n",
       "      <td>0.003258</td>\n",
       "      <td>0.089506</td>\n",
       "      <td>0.993074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: dt, with RandomForestClassifier</th>\n",
       "      <td>0.984595</td>\n",
       "      <td>0.934853</td>\n",
       "      <td>0.885802</td>\n",
       "      <td>0.909667</td>\n",
       "      <td>0.005924</td>\n",
       "      <td>0.114198</td>\n",
       "      <td>0.983599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, with RandomForestClassifier</th>\n",
       "      <td>0.985946</td>\n",
       "      <td>0.935897</td>\n",
       "      <td>0.901235</td>\n",
       "      <td>0.918239</td>\n",
       "      <td>0.005924</td>\n",
       "      <td>0.098765</td>\n",
       "      <td>0.992394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: gb, with RandomForestClassifier</th>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.944272</td>\n",
       "      <td>0.941358</td>\n",
       "      <td>0.942813</td>\n",
       "      <td>0.005332</td>\n",
       "      <td>0.058642</td>\n",
       "      <td>0.998435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: nb, with RandomForestClassifier</th>\n",
       "      <td>0.979189</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.882716</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.011552</td>\n",
       "      <td>0.117284</td>\n",
       "      <td>0.991322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, with GradientBoostingClassifier</th>\n",
       "      <td>0.988649</td>\n",
       "      <td>0.963816</td>\n",
       "      <td>0.904321</td>\n",
       "      <td>0.933121</td>\n",
       "      <td>0.003258</td>\n",
       "      <td>0.095679</td>\n",
       "      <td>0.994593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: dt, with GradientBoostingClassifier</th>\n",
       "      <td>0.984324</td>\n",
       "      <td>0.929032</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.908517</td>\n",
       "      <td>0.006517</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.983485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, with GradientBoostingClassifier</th>\n",
       "      <td>0.983784</td>\n",
       "      <td>0.909938</td>\n",
       "      <td>0.904321</td>\n",
       "      <td>0.907121</td>\n",
       "      <td>0.008590</td>\n",
       "      <td>0.095679</td>\n",
       "      <td>0.994591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: gb, with GradientBoostingClassifier</th>\n",
       "      <td>0.991081</td>\n",
       "      <td>0.953271</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.948837</td>\n",
       "      <td>0.004443</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.998433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: nb, with GradientBoostingClassifier</th>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.879630</td>\n",
       "      <td>0.885093</td>\n",
       "      <td>0.010367</td>\n",
       "      <td>0.120370</td>\n",
       "      <td>0.991426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Accuracy  Precision  \\\n",
       "Algorithms: lr, with LogisticRegression          0.990000   0.970492   \n",
       "Algorithms: dt, with LogisticRegression          0.983514   0.925566   \n",
       "Algorithms: rf, with LogisticRegression          0.988108   0.954545   \n",
       "Algorithms: gb, with LogisticRegression          0.991351   0.962025   \n",
       "Algorithms: nb, with LogisticRegression          0.972973   0.888889   \n",
       "Algorithms: lr, with RandomForestClassifier      0.989189   0.964052   \n",
       "Algorithms: dt, with RandomForestClassifier      0.984595   0.934853   \n",
       "Algorithms: rf, with RandomForestClassifier      0.985946   0.935897   \n",
       "Algorithms: gb, with RandomForestClassifier      0.990000   0.944272   \n",
       "Algorithms: nb, with RandomForestClassifier      0.979189   0.880000   \n",
       "Algorithms: lr, with GradientBoostingClassifier  0.988649   0.963816   \n",
       "Algorithms: dt, with GradientBoostingClassifier  0.984324   0.929032   \n",
       "Algorithms: rf, with GradientBoostingClassifier  0.983784   0.909938   \n",
       "Algorithms: gb, with GradientBoostingClassifier  0.991081   0.953271   \n",
       "Algorithms: nb, with GradientBoostingClassifier  0.980000   0.890625   \n",
       "\n",
       "                                                   Recall  F1 Score  \\\n",
       "Algorithms: lr, with LogisticRegression          0.913580  0.941176   \n",
       "Algorithms: dt, with LogisticRegression          0.882716  0.903633   \n",
       "Algorithms: rf, with LogisticRegression          0.907407  0.930380   \n",
       "Algorithms: gb, with LogisticRegression          0.938272  0.950000   \n",
       "Algorithms: nb, with LogisticRegression          0.790123  0.836601   \n",
       "Algorithms: lr, with RandomForestClassifier      0.910494  0.936508   \n",
       "Algorithms: dt, with RandomForestClassifier      0.885802  0.909667   \n",
       "Algorithms: rf, with RandomForestClassifier      0.901235  0.918239   \n",
       "Algorithms: gb, with RandomForestClassifier      0.941358  0.942813   \n",
       "Algorithms: nb, with RandomForestClassifier      0.882716  0.881356   \n",
       "Algorithms: lr, with GradientBoostingClassifier  0.904321  0.933121   \n",
       "Algorithms: dt, with GradientBoostingClassifier  0.888889  0.908517   \n",
       "Algorithms: rf, with GradientBoostingClassifier  0.904321  0.907121   \n",
       "Algorithms: gb, with GradientBoostingClassifier  0.944444  0.948837   \n",
       "Algorithms: nb, with GradientBoostingClassifier  0.879630  0.885093   \n",
       "\n",
       "                                                 False Positive Rate  \\\n",
       "Algorithms: lr, with LogisticRegression                     0.002666   \n",
       "Algorithms: dt, with LogisticRegression                     0.006813   \n",
       "Algorithms: rf, with LogisticRegression                     0.004147   \n",
       "Algorithms: gb, with LogisticRegression                     0.003555   \n",
       "Algorithms: nb, with LogisticRegression                     0.009479   \n",
       "Algorithms: lr, with RandomForestClassifier                 0.003258   \n",
       "Algorithms: dt, with RandomForestClassifier                 0.005924   \n",
       "Algorithms: rf, with RandomForestClassifier                 0.005924   \n",
       "Algorithms: gb, with RandomForestClassifier                 0.005332   \n",
       "Algorithms: nb, with RandomForestClassifier                 0.011552   \n",
       "Algorithms: lr, with GradientBoostingClassifier             0.003258   \n",
       "Algorithms: dt, with GradientBoostingClassifier             0.006517   \n",
       "Algorithms: rf, with GradientBoostingClassifier             0.008590   \n",
       "Algorithms: gb, with GradientBoostingClassifier             0.004443   \n",
       "Algorithms: nb, with GradientBoostingClassifier             0.010367   \n",
       "\n",
       "                                                 False Negative Rate  \\\n",
       "Algorithms: lr, with LogisticRegression                     0.086420   \n",
       "Algorithms: dt, with LogisticRegression                     0.117284   \n",
       "Algorithms: rf, with LogisticRegression                     0.092593   \n",
       "Algorithms: gb, with LogisticRegression                     0.061728   \n",
       "Algorithms: nb, with LogisticRegression                     0.209877   \n",
       "Algorithms: lr, with RandomForestClassifier                 0.089506   \n",
       "Algorithms: dt, with RandomForestClassifier                 0.114198   \n",
       "Algorithms: rf, with RandomForestClassifier                 0.098765   \n",
       "Algorithms: gb, with RandomForestClassifier                 0.058642   \n",
       "Algorithms: nb, with RandomForestClassifier                 0.117284   \n",
       "Algorithms: lr, with GradientBoostingClassifier             0.095679   \n",
       "Algorithms: dt, with GradientBoostingClassifier             0.111111   \n",
       "Algorithms: rf, with GradientBoostingClassifier             0.095679   \n",
       "Algorithms: gb, with GradientBoostingClassifier             0.055556   \n",
       "Algorithms: nb, with GradientBoostingClassifier             0.120370   \n",
       "\n",
       "                                                 Area Under ROC Curve  \n",
       "Algorithms: lr, with LogisticRegression                      0.993451  \n",
       "Algorithms: dt, with LogisticRegression                      0.981280  \n",
       "Algorithms: rf, with LogisticRegression                      0.993587  \n",
       "Algorithms: gb, with LogisticRegression                      0.997418  \n",
       "Algorithms: nb, with LogisticRegression                      0.989689  \n",
       "Algorithms: lr, with RandomForestClassifier                  0.993074  \n",
       "Algorithms: dt, with RandomForestClassifier                  0.983599  \n",
       "Algorithms: rf, with RandomForestClassifier                  0.992394  \n",
       "Algorithms: gb, with RandomForestClassifier                  0.998435  \n",
       "Algorithms: nb, with RandomForestClassifier                  0.991322  \n",
       "Algorithms: lr, with GradientBoostingClassifier              0.994593  \n",
       "Algorithms: dt, with GradientBoostingClassifier              0.983485  \n",
       "Algorithms: rf, with GradientBoostingClassifier              0.994591  \n",
       "Algorithms: gb, with GradientBoostingClassifier              0.998433  \n",
       "Algorithms: nb, with GradientBoostingClassifier              0.991426  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_stacking_imbalanced_single"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80470bc3",
   "metadata": {},
   "source": [
    "The results were somewhat consistent and slightly better at some cases with the results of the imbalanced dataset. Random Forest showed significant improvement and even NB managed to classify something. Compared to the merged feature sets, RF performed significantly better and GB too managed to outperformed it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "db737c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stacking_imbalanced_full = results_stacking_imbalanced_single.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bd461c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stacking_imbalanced_best = results_stacking_imbalanced_single.sort_values(by=['F1 Score'], ascending = [False]).head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec2738d",
   "metadata": {},
   "source": [
    "### Multi-algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ea7df94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stacking_imbalanced_multi = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62f9ca6",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1e0223b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13min 52s, sys: 2min 49s, total: 16min 42s\n",
      "Wall time: 12min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], exclude_models=[])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=[], result_row_name=\"Algorithms: all, with LogisticRegression\")\n",
    "results_stacking_imbalanced_multi = pd.concat([results_stacking_imbalanced_multi, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], exclude_models=['dt', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb'])\n",
    "results_stacking_imbalanced_multi = pd.concat([results_stacking_imbalanced_multi, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], exclude_models=['dt', 'nb', 'lr'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'lr'])\n",
    "results_stacking_imbalanced_multi = pd.concat([results_stacking_imbalanced_multi, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], exclude_models=['dt', 'nb', 'rf'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'rf'])\n",
    "results_stacking_imbalanced_multi = pd.concat([results_stacking_imbalanced_multi, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], exclude_models=['dt', 'nb', 'gb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb'])\n",
    "results_stacking_imbalanced_multi = pd.concat([results_stacking_imbalanced_multi, stacked_preds['results']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7af8cb",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7b6008eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13min 49s, sys: 2min 25s, total: 16min 15s\n",
      "Wall time: 12min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=rf, exclude_models=[])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=[], result_row_name=\"Algorithms: all, with RandomForestClassifier\")\n",
    "results_stacking_imbalanced_multi = pd.concat([results_stacking_imbalanced_multi, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=rf, exclude_models=['dt', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb'])\n",
    "results_stacking_imbalanced_multi = pd.concat([results_stacking_imbalanced_multi, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=rf, exclude_models=['dt', 'nb', 'lr'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'lr'])\n",
    "results_stacking_imbalanced_multi = pd.concat([results_stacking_imbalanced_multi, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=rf, exclude_models=['dt', 'nb', 'rf'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'rf'])\n",
    "results_stacking_imbalanced_multi = pd.concat([results_stacking_imbalanced_multi, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=rf, exclude_models=['dt', 'nb', 'gb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb'])\n",
    "results_stacking_imbalanced_multi = pd.concat([results_stacking_imbalanced_multi, stacked_preds['results']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c102a6",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6188f736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13min 57s, sys: 2min 22s, total: 16min 20s\n",
      "Wall time: 12min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=gb, exclude_models=[])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=[], result_row_name=\"Algorithms: all, with GradientBoostingClassifier\")\n",
    "results_stacking_imbalanced_multi = pd.concat([results_stacking_imbalanced_multi, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=gb, exclude_models=['dt', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb'])\n",
    "results_stacking_imbalanced_multi = pd.concat([results_stacking_imbalanced_multi, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=gb, exclude_models=['dt', 'nb', 'lr'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'lr'])\n",
    "results_stacking_imbalanced_multi = pd.concat([results_stacking_imbalanced_multi, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=gb, exclude_models=['dt', 'nb', 'rf'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'rf'])\n",
    "results_stacking_imbalanced_multi = pd.concat([results_stacking_imbalanced_multi, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=gb, exclude_models=['dt', 'nb', 'gb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb'])\n",
    "results_stacking_imbalanced_multi = pd.concat([results_stacking_imbalanced_multi, stacked_preds['results']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8314c00c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>Area Under ROC Curve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Algorithms: all, with LogisticRegression</th>\n",
       "      <td>0.993784</td>\n",
       "      <td>0.983923</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.963780</td>\n",
       "      <td>0.001481</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.996701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, rf, gb, with LogisticRegression</th>\n",
       "      <td>0.993243</td>\n",
       "      <td>0.974603</td>\n",
       "      <td>0.947531</td>\n",
       "      <td>0.960876</td>\n",
       "      <td>0.002370</td>\n",
       "      <td>0.052469</td>\n",
       "      <td>0.996843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, gb, with LogisticRegression</th>\n",
       "      <td>0.989459</td>\n",
       "      <td>0.946708</td>\n",
       "      <td>0.932099</td>\n",
       "      <td>0.939347</td>\n",
       "      <td>0.005036</td>\n",
       "      <td>0.067901</td>\n",
       "      <td>0.996567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, gb, with LogisticRegression</th>\n",
       "      <td>0.993514</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.001777</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.997376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, rf, with LogisticRegression</th>\n",
       "      <td>0.991351</td>\n",
       "      <td>0.974026</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.949367</td>\n",
       "      <td>0.002370</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.995751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: all, with RandomForestClassifier</th>\n",
       "      <td>0.993243</td>\n",
       "      <td>0.974603</td>\n",
       "      <td>0.947531</td>\n",
       "      <td>0.960876</td>\n",
       "      <td>0.002370</td>\n",
       "      <td>0.052469</td>\n",
       "      <td>0.998764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, rf, gb, with RandomForestClassifier</th>\n",
       "      <td>0.993243</td>\n",
       "      <td>0.980707</td>\n",
       "      <td>0.941358</td>\n",
       "      <td>0.960630</td>\n",
       "      <td>0.001777</td>\n",
       "      <td>0.058642</td>\n",
       "      <td>0.998818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, gb, with RandomForestClassifier</th>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.947040</td>\n",
       "      <td>0.938272</td>\n",
       "      <td>0.942636</td>\n",
       "      <td>0.005036</td>\n",
       "      <td>0.061728</td>\n",
       "      <td>0.998558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, gb, with RandomForestClassifier</th>\n",
       "      <td>0.992973</td>\n",
       "      <td>0.974522</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.959248</td>\n",
       "      <td>0.002370</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.998934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, rf, with RandomForestClassifier</th>\n",
       "      <td>0.990270</td>\n",
       "      <td>0.964516</td>\n",
       "      <td>0.922840</td>\n",
       "      <td>0.943218</td>\n",
       "      <td>0.003258</td>\n",
       "      <td>0.077160</td>\n",
       "      <td>0.998321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: all, with GradientBoostingClassifier</th>\n",
       "      <td>0.992703</td>\n",
       "      <td>0.968454</td>\n",
       "      <td>0.947531</td>\n",
       "      <td>0.957878</td>\n",
       "      <td>0.002962</td>\n",
       "      <td>0.052469</td>\n",
       "      <td>0.999003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, rf, gb, with GradientBoostingClassifier</th>\n",
       "      <td>0.993243</td>\n",
       "      <td>0.974603</td>\n",
       "      <td>0.947531</td>\n",
       "      <td>0.960876</td>\n",
       "      <td>0.002370</td>\n",
       "      <td>0.052469</td>\n",
       "      <td>0.998923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, gb, with GradientBoostingClassifier</th>\n",
       "      <td>0.991081</td>\n",
       "      <td>0.953271</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.948837</td>\n",
       "      <td>0.004443</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.998514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, gb, with GradientBoostingClassifier</th>\n",
       "      <td>0.993784</td>\n",
       "      <td>0.974763</td>\n",
       "      <td>0.953704</td>\n",
       "      <td>0.964119</td>\n",
       "      <td>0.002370</td>\n",
       "      <td>0.046296</td>\n",
       "      <td>0.998875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, rf, with GradientBoostingClassifier</th>\n",
       "      <td>0.991892</td>\n",
       "      <td>0.971154</td>\n",
       "      <td>0.935185</td>\n",
       "      <td>0.952830</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>0.064815</td>\n",
       "      <td>0.998633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Accuracy  Precision  \\\n",
       "Algorithms: all, with LogisticRegression            0.993784   0.983923   \n",
       "Algorithms: lr, rf, gb, with LogisticRegression     0.993243   0.974603   \n",
       "Algorithms: rf, gb, with LogisticRegression         0.989459   0.946708   \n",
       "Algorithms: lr, gb, with LogisticRegression         0.993514   0.980769   \n",
       "Algorithms: lr, rf, with LogisticRegression         0.991351   0.974026   \n",
       "Algorithms: all, with RandomForestClassifier        0.993243   0.974603   \n",
       "Algorithms: lr, rf, gb, with RandomForestClassi...  0.993243   0.980707   \n",
       "Algorithms: rf, gb, with RandomForestClassifier     0.990000   0.947040   \n",
       "Algorithms: lr, gb, with RandomForestClassifier     0.992973   0.974522   \n",
       "Algorithms: lr, rf, with RandomForestClassifier     0.990270   0.964516   \n",
       "Algorithms: all, with GradientBoostingClassifier    0.992703   0.968454   \n",
       "Algorithms: lr, rf, gb, with GradientBoostingCl...  0.993243   0.974603   \n",
       "Algorithms: rf, gb, with GradientBoostingClassi...  0.991081   0.953271   \n",
       "Algorithms: lr, gb, with GradientBoostingClassi...  0.993784   0.974763   \n",
       "Algorithms: lr, rf, with GradientBoostingClassi...  0.991892   0.971154   \n",
       "\n",
       "                                                      Recall  F1 Score  \\\n",
       "Algorithms: all, with LogisticRegression            0.944444  0.963780   \n",
       "Algorithms: lr, rf, gb, with LogisticRegression     0.947531  0.960876   \n",
       "Algorithms: rf, gb, with LogisticRegression         0.932099  0.939347   \n",
       "Algorithms: lr, gb, with LogisticRegression         0.944444  0.962264   \n",
       "Algorithms: lr, rf, with LogisticRegression         0.925926  0.949367   \n",
       "Algorithms: all, with RandomForestClassifier        0.947531  0.960876   \n",
       "Algorithms: lr, rf, gb, with RandomForestClassi...  0.941358  0.960630   \n",
       "Algorithms: rf, gb, with RandomForestClassifier     0.938272  0.942636   \n",
       "Algorithms: lr, gb, with RandomForestClassifier     0.944444  0.959248   \n",
       "Algorithms: lr, rf, with RandomForestClassifier     0.922840  0.943218   \n",
       "Algorithms: all, with GradientBoostingClassifier    0.947531  0.957878   \n",
       "Algorithms: lr, rf, gb, with GradientBoostingCl...  0.947531  0.960876   \n",
       "Algorithms: rf, gb, with GradientBoostingClassi...  0.944444  0.948837   \n",
       "Algorithms: lr, gb, with GradientBoostingClassi...  0.953704  0.964119   \n",
       "Algorithms: lr, rf, with GradientBoostingClassi...  0.935185  0.952830   \n",
       "\n",
       "                                                    False Positive Rate  \\\n",
       "Algorithms: all, with LogisticRegression                       0.001481   \n",
       "Algorithms: lr, rf, gb, with LogisticRegression                0.002370   \n",
       "Algorithms: rf, gb, with LogisticRegression                    0.005036   \n",
       "Algorithms: lr, gb, with LogisticRegression                    0.001777   \n",
       "Algorithms: lr, rf, with LogisticRegression                    0.002370   \n",
       "Algorithms: all, with RandomForestClassifier                   0.002370   \n",
       "Algorithms: lr, rf, gb, with RandomForestClassi...             0.001777   \n",
       "Algorithms: rf, gb, with RandomForestClassifier                0.005036   \n",
       "Algorithms: lr, gb, with RandomForestClassifier                0.002370   \n",
       "Algorithms: lr, rf, with RandomForestClassifier                0.003258   \n",
       "Algorithms: all, with GradientBoostingClassifier               0.002962   \n",
       "Algorithms: lr, rf, gb, with GradientBoostingCl...             0.002370   \n",
       "Algorithms: rf, gb, with GradientBoostingClassi...             0.004443   \n",
       "Algorithms: lr, gb, with GradientBoostingClassi...             0.002370   \n",
       "Algorithms: lr, rf, with GradientBoostingClassi...             0.002666   \n",
       "\n",
       "                                                    False Negative Rate  \\\n",
       "Algorithms: all, with LogisticRegression                       0.055556   \n",
       "Algorithms: lr, rf, gb, with LogisticRegression                0.052469   \n",
       "Algorithms: rf, gb, with LogisticRegression                    0.067901   \n",
       "Algorithms: lr, gb, with LogisticRegression                    0.055556   \n",
       "Algorithms: lr, rf, with LogisticRegression                    0.074074   \n",
       "Algorithms: all, with RandomForestClassifier                   0.052469   \n",
       "Algorithms: lr, rf, gb, with RandomForestClassi...             0.058642   \n",
       "Algorithms: rf, gb, with RandomForestClassifier                0.061728   \n",
       "Algorithms: lr, gb, with RandomForestClassifier                0.055556   \n",
       "Algorithms: lr, rf, with RandomForestClassifier                0.077160   \n",
       "Algorithms: all, with GradientBoostingClassifier               0.052469   \n",
       "Algorithms: lr, rf, gb, with GradientBoostingCl...             0.052469   \n",
       "Algorithms: rf, gb, with GradientBoostingClassi...             0.055556   \n",
       "Algorithms: lr, gb, with GradientBoostingClassi...             0.046296   \n",
       "Algorithms: lr, rf, with GradientBoostingClassi...             0.064815   \n",
       "\n",
       "                                                    Area Under ROC Curve  \n",
       "Algorithms: all, with LogisticRegression                        0.996701  \n",
       "Algorithms: lr, rf, gb, with LogisticRegression                 0.996843  \n",
       "Algorithms: rf, gb, with LogisticRegression                     0.996567  \n",
       "Algorithms: lr, gb, with LogisticRegression                     0.997376  \n",
       "Algorithms: lr, rf, with LogisticRegression                     0.995751  \n",
       "Algorithms: all, with RandomForestClassifier                    0.998764  \n",
       "Algorithms: lr, rf, gb, with RandomForestClassi...              0.998818  \n",
       "Algorithms: rf, gb, with RandomForestClassifier                 0.998558  \n",
       "Algorithms: lr, gb, with RandomForestClassifier                 0.998934  \n",
       "Algorithms: lr, rf, with RandomForestClassifier                 0.998321  \n",
       "Algorithms: all, with GradientBoostingClassifier                0.999003  \n",
       "Algorithms: lr, rf, gb, with GradientBoostingCl...              0.998923  \n",
       "Algorithms: rf, gb, with GradientBoostingClassi...              0.998514  \n",
       "Algorithms: lr, gb, with GradientBoostingClassi...              0.998875  \n",
       "Algorithms: lr, rf, with GradientBoostingClassi...              0.998633  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_stacking_imbalanced_multi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd442e7e",
   "metadata": {},
   "source": [
    "Of course, these models performed better on average than the stacking only of different feature sets. On the imbalanced dataset, Naive Bayes and Decision Tree did have more impact on the prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b89718ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stacking_imbalanced_best = pd.concat([results_stacking_imbalanced_best, results_stacking_imbalanced_multi.sort_values(by=['F1 Score'], ascending = [False]).head(13)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d88996f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stacking_imbalanced_full = pd.concat([results_stacking_imbalanced_full, results_stacking_imbalanced_multi])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bc5c50",
   "metadata": {},
   "source": [
    "### Appending all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "800c2b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stacking_imbalanced_append = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f780e5",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9a189f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18min 44s, sys: 4min 28s, total: 23min 12s\n",
      "Wall time: 16min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], exclude_models=[], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=[], append_features=True, result_row_name=\"Algorithms: all, with LogisticRegression (with appended features)\")\n",
    "results_stacking_imbalanced_append = pd.concat([results_stacking_imbalanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], exclude_models=['dt', 'nb'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb'], append_features=True)\n",
    "results_stacking_imbalanced_append = pd.concat([results_stacking_imbalanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], exclude_models=['dt', 'nb', 'lr'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'lr'], append_features=True)\n",
    "results_stacking_imbalanced_append = pd.concat([results_stacking_imbalanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], exclude_models=['dt', 'nb', 'rf'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'rf'], append_features=True)\n",
    "results_stacking_imbalanced_append = pd.concat([results_stacking_imbalanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], exclude_models=['dt', 'nb', 'gb'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb'], append_features=True)\n",
    "results_stacking_imbalanced_append = pd.concat([results_stacking_imbalanced_append, stacked_preds['results']])\n",
    "\n",
    "# Single level 0\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], exclude_models=['dt', 'nb', 'gb', 'rf'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb', 'rf'], append_features=True)\n",
    "results_stacking_imbalanced_append = pd.concat([results_stacking_imbalanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], exclude_models=['dt', 'nb', 'gb', 'lr'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb', 'lr'], append_features=True)\n",
    "results_stacking_imbalanced_append = pd.concat([results_stacking_imbalanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], exclude_models=['dt', 'nb', 'rf', 'lr'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'rf', 'lr'], append_features=True)\n",
    "results_stacking_imbalanced_append = pd.concat([results_stacking_imbalanced_append, stacked_preds['results']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ae87f7",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ad0fa9c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17min 19s, sys: 3min 16s, total: 20min 36s\n",
      "Wall time: 15min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=rf, exclude_models=[], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=[], append_features=True, result_row_name=\"Algorithms: all, with RandomForestClassifier (with appended features)\")\n",
    "results_stacking_imbalanced_append = pd.concat([results_stacking_imbalanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=rf, exclude_models=['dt', 'nb'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb'], append_features=True)\n",
    "results_stacking_imbalanced_append = pd.concat([results_stacking_imbalanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=rf, exclude_models=['dt', 'nb', 'lr'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'lr'], append_features=True)\n",
    "results_stacking_imbalanced_append = pd.concat([results_stacking_imbalanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=rf, exclude_models=['dt', 'nb', 'rf'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'rf'], append_features=True)\n",
    "results_stacking_imbalanced_append = pd.concat([results_stacking_imbalanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=rf, exclude_models=['dt', 'nb', 'gb'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb'], append_features=True)\n",
    "results_stacking_imbalanced_append = pd.concat([results_stacking_imbalanced_append, stacked_preds['results']])\n",
    "\n",
    "# Single level 0\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=rf, exclude_models=['dt', 'nb', 'gb', 'rf'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb', 'rf'], append_features=True)\n",
    "results_stacking_imbalanced_append = pd.concat([results_stacking_imbalanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=rf, exclude_models=['dt', 'nb', 'gb', 'lr'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb', 'lr'], append_features=True)\n",
    "results_stacking_imbalanced_append = pd.concat([results_stacking_imbalanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=rf, exclude_models=['dt', 'nb', 'rf', 'lr'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'rf', 'lr'], append_features=True)\n",
    "results_stacking_imbalanced_append = pd.concat([results_stacking_imbalanced_append, stacked_preds['results']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944bae83",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "72796493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23min 29s, sys: 2min 51s, total: 26min 21s\n",
      "Wall time: 22min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=gb, exclude_models=[], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=[], append_features=True, result_row_name=\"Algorithms: all, with GradientBoostingClassifier (with appended features)\")\n",
    "results_stacking_imbalanced_append = pd.concat([results_stacking_imbalanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=gb, exclude_models=['dt', 'nb'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb'], append_features=True)\n",
    "results_stacking_imbalanced_append = pd.concat([results_stacking_imbalanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=gb, exclude_models=['dt', 'nb', 'lr'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'lr'], append_features=True)\n",
    "results_stacking_imbalanced_append = pd.concat([results_stacking_imbalanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=gb, exclude_models=['dt', 'nb', 'rf'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'rf'], append_features=True)\n",
    "results_stacking_imbalanced_append = pd.concat([results_stacking_imbalanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=gb, exclude_models=['dt', 'nb', 'gb'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb'], append_features=True)\n",
    "results_stacking_imbalanced_append = pd.concat([results_stacking_imbalanced_append, stacked_preds['results']])\n",
    "\n",
    "# Single level 0\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=gb, exclude_models=['dt', 'nb', 'gb', 'rf'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb', 'rf'], append_features=True)\n",
    "results_stacking_imbalanced_append = pd.concat([results_stacking_imbalanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=gb, exclude_models=['dt', 'nb', 'gb', 'lr'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb', 'lr'], append_features=True)\n",
    "results_stacking_imbalanced_append = pd.concat([results_stacking_imbalanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=gb, exclude_models=['dt', 'nb', 'rf', 'lr'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'rf', 'lr'], append_features=True)\n",
    "results_stacking_imbalanced_append = pd.concat([results_stacking_imbalanced_append, stacked_preds['results']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8da36db6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>Area Under ROC Curve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Algorithms: all, with LogisticRegression (with appended features)</th>\n",
       "      <td>0.992703</td>\n",
       "      <td>0.974441</td>\n",
       "      <td>0.941358</td>\n",
       "      <td>0.957614</td>\n",
       "      <td>0.002370</td>\n",
       "      <td>0.058642</td>\n",
       "      <td>0.998264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, rf, gb, with LogisticRegression (with appended features)</th>\n",
       "      <td>0.993243</td>\n",
       "      <td>0.980707</td>\n",
       "      <td>0.941358</td>\n",
       "      <td>0.960630</td>\n",
       "      <td>0.001777</td>\n",
       "      <td>0.058642</td>\n",
       "      <td>0.994992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, gb, with LogisticRegression (with appended features)</th>\n",
       "      <td>0.992162</td>\n",
       "      <td>0.974277</td>\n",
       "      <td>0.935185</td>\n",
       "      <td>0.954331</td>\n",
       "      <td>0.002370</td>\n",
       "      <td>0.064815</td>\n",
       "      <td>0.993650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, gb, with LogisticRegression (with appended features)</th>\n",
       "      <td>0.992973</td>\n",
       "      <td>0.977564</td>\n",
       "      <td>0.941358</td>\n",
       "      <td>0.959119</td>\n",
       "      <td>0.002073</td>\n",
       "      <td>0.058642</td>\n",
       "      <td>0.994877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, rf, with LogisticRegression (with appended features)</th>\n",
       "      <td>0.992973</td>\n",
       "      <td>0.980645</td>\n",
       "      <td>0.938272</td>\n",
       "      <td>0.958991</td>\n",
       "      <td>0.001777</td>\n",
       "      <td>0.061728</td>\n",
       "      <td>0.995784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, with LogisticRegression (with appended features)</th>\n",
       "      <td>0.991622</td>\n",
       "      <td>0.971061</td>\n",
       "      <td>0.932099</td>\n",
       "      <td>0.951181</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>0.067901</td>\n",
       "      <td>0.994488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, with LogisticRegression (with appended features)</th>\n",
       "      <td>0.992703</td>\n",
       "      <td>0.980583</td>\n",
       "      <td>0.935185</td>\n",
       "      <td>0.957346</td>\n",
       "      <td>0.001777</td>\n",
       "      <td>0.064815</td>\n",
       "      <td>0.994433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: gb, with LogisticRegression (with appended features)</th>\n",
       "      <td>0.993514</td>\n",
       "      <td>0.983871</td>\n",
       "      <td>0.941358</td>\n",
       "      <td>0.962145</td>\n",
       "      <td>0.001481</td>\n",
       "      <td>0.058642</td>\n",
       "      <td>0.993473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: all, with RandomForestClassifier (with appended features)</th>\n",
       "      <td>0.991892</td>\n",
       "      <td>0.968153</td>\n",
       "      <td>0.938272</td>\n",
       "      <td>0.952978</td>\n",
       "      <td>0.002962</td>\n",
       "      <td>0.061728</td>\n",
       "      <td>0.997290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, rf, gb, with RandomForestClassifier (with appended features)</th>\n",
       "      <td>0.992703</td>\n",
       "      <td>0.983713</td>\n",
       "      <td>0.932099</td>\n",
       "      <td>0.957211</td>\n",
       "      <td>0.001481</td>\n",
       "      <td>0.067901</td>\n",
       "      <td>0.997017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, gb, with RandomForestClassifier (with appended features)</th>\n",
       "      <td>0.989730</td>\n",
       "      <td>0.955414</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.940439</td>\n",
       "      <td>0.004147</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.996141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, gb, with RandomForestClassifier (with appended features)</th>\n",
       "      <td>0.992162</td>\n",
       "      <td>0.983607</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.953895</td>\n",
       "      <td>0.001481</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.997766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, rf, with RandomForestClassifier (with appended features)</th>\n",
       "      <td>0.991892</td>\n",
       "      <td>0.986755</td>\n",
       "      <td>0.919753</td>\n",
       "      <td>0.952077</td>\n",
       "      <td>0.001185</td>\n",
       "      <td>0.080247</td>\n",
       "      <td>0.997452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, with RandomForestClassifier (with appended features)</th>\n",
       "      <td>0.988108</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.876543</td>\n",
       "      <td>0.928105</td>\n",
       "      <td>0.001185</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>0.996436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, with RandomForestClassifier (with appended features)</th>\n",
       "      <td>0.987297</td>\n",
       "      <td>0.966330</td>\n",
       "      <td>0.885802</td>\n",
       "      <td>0.924316</td>\n",
       "      <td>0.002962</td>\n",
       "      <td>0.114198</td>\n",
       "      <td>0.995155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: gb, with RandomForestClassifier (with appended features)</th>\n",
       "      <td>0.987838</td>\n",
       "      <td>0.957377</td>\n",
       "      <td>0.901235</td>\n",
       "      <td>0.928458</td>\n",
       "      <td>0.003851</td>\n",
       "      <td>0.098765</td>\n",
       "      <td>0.995964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: all, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.993784</td>\n",
       "      <td>0.980831</td>\n",
       "      <td>0.947531</td>\n",
       "      <td>0.963893</td>\n",
       "      <td>0.001777</td>\n",
       "      <td>0.052469</td>\n",
       "      <td>0.999175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, rf, gb, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.992432</td>\n",
       "      <td>0.965409</td>\n",
       "      <td>0.947531</td>\n",
       "      <td>0.956386</td>\n",
       "      <td>0.003258</td>\n",
       "      <td>0.052469</td>\n",
       "      <td>0.999120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, gb, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.991081</td>\n",
       "      <td>0.942249</td>\n",
       "      <td>0.956790</td>\n",
       "      <td>0.949464</td>\n",
       "      <td>0.005628</td>\n",
       "      <td>0.043210</td>\n",
       "      <td>0.998976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, gb, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.994054</td>\n",
       "      <td>0.977848</td>\n",
       "      <td>0.953704</td>\n",
       "      <td>0.965625</td>\n",
       "      <td>0.002073</td>\n",
       "      <td>0.046296</td>\n",
       "      <td>0.999021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, rf, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.993243</td>\n",
       "      <td>0.971609</td>\n",
       "      <td>0.950617</td>\n",
       "      <td>0.960998</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>0.049383</td>\n",
       "      <td>0.998888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.993514</td>\n",
       "      <td>0.983871</td>\n",
       "      <td>0.941358</td>\n",
       "      <td>0.962145</td>\n",
       "      <td>0.001481</td>\n",
       "      <td>0.058642</td>\n",
       "      <td>0.998843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.989730</td>\n",
       "      <td>0.941358</td>\n",
       "      <td>0.941358</td>\n",
       "      <td>0.941358</td>\n",
       "      <td>0.005628</td>\n",
       "      <td>0.058642</td>\n",
       "      <td>0.997884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: gb, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.991351</td>\n",
       "      <td>0.950617</td>\n",
       "      <td>0.950617</td>\n",
       "      <td>0.950617</td>\n",
       "      <td>0.004739</td>\n",
       "      <td>0.049383</td>\n",
       "      <td>0.998939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Accuracy  Precision  \\\n",
       "Algorithms: all, with LogisticRegression (with ...  0.992703   0.974441   \n",
       "Algorithms: lr, rf, gb, with LogisticRegression...  0.993243   0.980707   \n",
       "Algorithms: rf, gb, with LogisticRegression (wi...  0.992162   0.974277   \n",
       "Algorithms: lr, gb, with LogisticRegression (wi...  0.992973   0.977564   \n",
       "Algorithms: lr, rf, with LogisticRegression (wi...  0.992973   0.980645   \n",
       "Algorithms: lr, with LogisticRegression (with a...  0.991622   0.971061   \n",
       "Algorithms: rf, with LogisticRegression (with a...  0.992703   0.980583   \n",
       "Algorithms: gb, with LogisticRegression (with a...  0.993514   0.983871   \n",
       "Algorithms: all, with RandomForestClassifier (w...  0.991892   0.968153   \n",
       "Algorithms: lr, rf, gb, with RandomForestClassi...  0.992703   0.983713   \n",
       "Algorithms: rf, gb, with RandomForestClassifier...  0.989730   0.955414   \n",
       "Algorithms: lr, gb, with RandomForestClassifier...  0.992162   0.983607   \n",
       "Algorithms: lr, rf, with RandomForestClassifier...  0.991892   0.986755   \n",
       "Algorithms: lr, with RandomForestClassifier (wi...  0.988108   0.986111   \n",
       "Algorithms: rf, with RandomForestClassifier (wi...  0.987297   0.966330   \n",
       "Algorithms: gb, with RandomForestClassifier (wi...  0.987838   0.957377   \n",
       "Algorithms: all, with GradientBoostingClassifie...  0.993784   0.980831   \n",
       "Algorithms: lr, rf, gb, with GradientBoostingCl...  0.992432   0.965409   \n",
       "Algorithms: rf, gb, with GradientBoostingClassi...  0.991081   0.942249   \n",
       "Algorithms: lr, gb, with GradientBoostingClassi...  0.994054   0.977848   \n",
       "Algorithms: lr, rf, with GradientBoostingClassi...  0.993243   0.971609   \n",
       "Algorithms: lr, with GradientBoostingClassifier...  0.993514   0.983871   \n",
       "Algorithms: rf, with GradientBoostingClassifier...  0.989730   0.941358   \n",
       "Algorithms: gb, with GradientBoostingClassifier...  0.991351   0.950617   \n",
       "\n",
       "                                                      Recall  F1 Score  \\\n",
       "Algorithms: all, with LogisticRegression (with ...  0.941358  0.957614   \n",
       "Algorithms: lr, rf, gb, with LogisticRegression...  0.941358  0.960630   \n",
       "Algorithms: rf, gb, with LogisticRegression (wi...  0.935185  0.954331   \n",
       "Algorithms: lr, gb, with LogisticRegression (wi...  0.941358  0.959119   \n",
       "Algorithms: lr, rf, with LogisticRegression (wi...  0.938272  0.958991   \n",
       "Algorithms: lr, with LogisticRegression (with a...  0.932099  0.951181   \n",
       "Algorithms: rf, with LogisticRegression (with a...  0.935185  0.957346   \n",
       "Algorithms: gb, with LogisticRegression (with a...  0.941358  0.962145   \n",
       "Algorithms: all, with RandomForestClassifier (w...  0.938272  0.952978   \n",
       "Algorithms: lr, rf, gb, with RandomForestClassi...  0.932099  0.957211   \n",
       "Algorithms: rf, gb, with RandomForestClassifier...  0.925926  0.940439   \n",
       "Algorithms: lr, gb, with RandomForestClassifier...  0.925926  0.953895   \n",
       "Algorithms: lr, rf, with RandomForestClassifier...  0.919753  0.952077   \n",
       "Algorithms: lr, with RandomForestClassifier (wi...  0.876543  0.928105   \n",
       "Algorithms: rf, with RandomForestClassifier (wi...  0.885802  0.924316   \n",
       "Algorithms: gb, with RandomForestClassifier (wi...  0.901235  0.928458   \n",
       "Algorithms: all, with GradientBoostingClassifie...  0.947531  0.963893   \n",
       "Algorithms: lr, rf, gb, with GradientBoostingCl...  0.947531  0.956386   \n",
       "Algorithms: rf, gb, with GradientBoostingClassi...  0.956790  0.949464   \n",
       "Algorithms: lr, gb, with GradientBoostingClassi...  0.953704  0.965625   \n",
       "Algorithms: lr, rf, with GradientBoostingClassi...  0.950617  0.960998   \n",
       "Algorithms: lr, with GradientBoostingClassifier...  0.941358  0.962145   \n",
       "Algorithms: rf, with GradientBoostingClassifier...  0.941358  0.941358   \n",
       "Algorithms: gb, with GradientBoostingClassifier...  0.950617  0.950617   \n",
       "\n",
       "                                                    False Positive Rate  \\\n",
       "Algorithms: all, with LogisticRegression (with ...             0.002370   \n",
       "Algorithms: lr, rf, gb, with LogisticRegression...             0.001777   \n",
       "Algorithms: rf, gb, with LogisticRegression (wi...             0.002370   \n",
       "Algorithms: lr, gb, with LogisticRegression (wi...             0.002073   \n",
       "Algorithms: lr, rf, with LogisticRegression (wi...             0.001777   \n",
       "Algorithms: lr, with LogisticRegression (with a...             0.002666   \n",
       "Algorithms: rf, with LogisticRegression (with a...             0.001777   \n",
       "Algorithms: gb, with LogisticRegression (with a...             0.001481   \n",
       "Algorithms: all, with RandomForestClassifier (w...             0.002962   \n",
       "Algorithms: lr, rf, gb, with RandomForestClassi...             0.001481   \n",
       "Algorithms: rf, gb, with RandomForestClassifier...             0.004147   \n",
       "Algorithms: lr, gb, with RandomForestClassifier...             0.001481   \n",
       "Algorithms: lr, rf, with RandomForestClassifier...             0.001185   \n",
       "Algorithms: lr, with RandomForestClassifier (wi...             0.001185   \n",
       "Algorithms: rf, with RandomForestClassifier (wi...             0.002962   \n",
       "Algorithms: gb, with RandomForestClassifier (wi...             0.003851   \n",
       "Algorithms: all, with GradientBoostingClassifie...             0.001777   \n",
       "Algorithms: lr, rf, gb, with GradientBoostingCl...             0.003258   \n",
       "Algorithms: rf, gb, with GradientBoostingClassi...             0.005628   \n",
       "Algorithms: lr, gb, with GradientBoostingClassi...             0.002073   \n",
       "Algorithms: lr, rf, with GradientBoostingClassi...             0.002666   \n",
       "Algorithms: lr, with GradientBoostingClassifier...             0.001481   \n",
       "Algorithms: rf, with GradientBoostingClassifier...             0.005628   \n",
       "Algorithms: gb, with GradientBoostingClassifier...             0.004739   \n",
       "\n",
       "                                                    False Negative Rate  \\\n",
       "Algorithms: all, with LogisticRegression (with ...             0.058642   \n",
       "Algorithms: lr, rf, gb, with LogisticRegression...             0.058642   \n",
       "Algorithms: rf, gb, with LogisticRegression (wi...             0.064815   \n",
       "Algorithms: lr, gb, with LogisticRegression (wi...             0.058642   \n",
       "Algorithms: lr, rf, with LogisticRegression (wi...             0.061728   \n",
       "Algorithms: lr, with LogisticRegression (with a...             0.067901   \n",
       "Algorithms: rf, with LogisticRegression (with a...             0.064815   \n",
       "Algorithms: gb, with LogisticRegression (with a...             0.058642   \n",
       "Algorithms: all, with RandomForestClassifier (w...             0.061728   \n",
       "Algorithms: lr, rf, gb, with RandomForestClassi...             0.067901   \n",
       "Algorithms: rf, gb, with RandomForestClassifier...             0.074074   \n",
       "Algorithms: lr, gb, with RandomForestClassifier...             0.074074   \n",
       "Algorithms: lr, rf, with RandomForestClassifier...             0.080247   \n",
       "Algorithms: lr, with RandomForestClassifier (wi...             0.123457   \n",
       "Algorithms: rf, with RandomForestClassifier (wi...             0.114198   \n",
       "Algorithms: gb, with RandomForestClassifier (wi...             0.098765   \n",
       "Algorithms: all, with GradientBoostingClassifie...             0.052469   \n",
       "Algorithms: lr, rf, gb, with GradientBoostingCl...             0.052469   \n",
       "Algorithms: rf, gb, with GradientBoostingClassi...             0.043210   \n",
       "Algorithms: lr, gb, with GradientBoostingClassi...             0.046296   \n",
       "Algorithms: lr, rf, with GradientBoostingClassi...             0.049383   \n",
       "Algorithms: lr, with GradientBoostingClassifier...             0.058642   \n",
       "Algorithms: rf, with GradientBoostingClassifier...             0.058642   \n",
       "Algorithms: gb, with GradientBoostingClassifier...             0.049383   \n",
       "\n",
       "                                                    Area Under ROC Curve  \n",
       "Algorithms: all, with LogisticRegression (with ...              0.998264  \n",
       "Algorithms: lr, rf, gb, with LogisticRegression...              0.994992  \n",
       "Algorithms: rf, gb, with LogisticRegression (wi...              0.993650  \n",
       "Algorithms: lr, gb, with LogisticRegression (wi...              0.994877  \n",
       "Algorithms: lr, rf, with LogisticRegression (wi...              0.995784  \n",
       "Algorithms: lr, with LogisticRegression (with a...              0.994488  \n",
       "Algorithms: rf, with LogisticRegression (with a...              0.994433  \n",
       "Algorithms: gb, with LogisticRegression (with a...              0.993473  \n",
       "Algorithms: all, with RandomForestClassifier (w...              0.997290  \n",
       "Algorithms: lr, rf, gb, with RandomForestClassi...              0.997017  \n",
       "Algorithms: rf, gb, with RandomForestClassifier...              0.996141  \n",
       "Algorithms: lr, gb, with RandomForestClassifier...              0.997766  \n",
       "Algorithms: lr, rf, with RandomForestClassifier...              0.997452  \n",
       "Algorithms: lr, with RandomForestClassifier (wi...              0.996436  \n",
       "Algorithms: rf, with RandomForestClassifier (wi...              0.995155  \n",
       "Algorithms: gb, with RandomForestClassifier (wi...              0.995964  \n",
       "Algorithms: all, with GradientBoostingClassifie...              0.999175  \n",
       "Algorithms: lr, rf, gb, with GradientBoostingCl...              0.999120  \n",
       "Algorithms: rf, gb, with GradientBoostingClassi...              0.998976  \n",
       "Algorithms: lr, gb, with GradientBoostingClassi...              0.999021  \n",
       "Algorithms: lr, rf, with GradientBoostingClassi...              0.998888  \n",
       "Algorithms: lr, with GradientBoostingClassifier...              0.998843  \n",
       "Algorithms: rf, with GradientBoostingClassifier...              0.997884  \n",
       "Algorithms: gb, with GradientBoostingClassifier...              0.998939  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_stacking_imbalanced_append"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53342ec1",
   "metadata": {},
   "source": [
    "Adding the initial feature sets to the final classifier also mostly harms performance on the imbalanced dataset. The best performing model now only barely performed better than without the features. The algorithm that performed better was Gradient Boosting. Also, there were some single-classifier models in the top performing ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "380c0f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stacking_imbalanced_best = pd.concat([results_stacking_imbalanced_best, results_stacking_imbalanced_append.sort_values(by=['F1 Score'], ascending = [False]).head(12)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4161c43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stacking_imbalanced_full = pd.concat([results_stacking_imbalanced_full, results_stacking_imbalanced_append])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8ba91b",
   "metadata": {},
   "source": [
    "### Merged Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "097252fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature_sets_imbalanced_merged = [{'name': 'merge', 'features': style_content_train_imbalanced}]\n",
    "test_feature_sets_imbalanced_merged = [{'name': 'merge', 'features': style_content_test_imbalanced}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1650fcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_merged_imbalanced = {'model' : lr_style_content_imbalanced, 'scaler': lr_style_content_imbalanced_scaler}\n",
    "nb_merged_imbalanced = {'model' : nb_style_content_imbalanced, 'scaler': nb_style_content_imbalanced_scaler}\n",
    "\n",
    "merged_models_imbalanced = [{'name' : 'lr', 'features' : 'merge', 'model' : lr_merged_imbalanced},\n",
    "                          {'name' : 'dt', 'features' : 'merge', 'model' : dt_style_content_imbalanced},\n",
    "                          {'name' : 'rf', 'features' : 'merge', 'model' : rf_style_content_imbalanced},\n",
    "                          {'name' : 'gb', 'features' : 'merge', 'model' : gb_style_content_imbalanced},\n",
    "                          {'name' : 'nb', 'features' : 'merge', 'model' : nb_merged_imbalanced}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e26d815e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stacking_imbalanced_merged = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7384bf08",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "863e7864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22min 45s, sys: 4min 52s, total: 27min 37s\n",
      "Wall time: 19min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stacked_clf = ml.train_stacked_models(merged_models_imbalanced, train_feature_sets_imbalanced_merged, style_train_imbalanced['target'], exclude_models=['dt', 'nb'], append_features=False)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_imbalanced, test_feature_sets_imbalanced_merged, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb'], append_features=False, result_row_name=\"Algorithms: lr, rf, gb merged, with LogisticRegression\")\n",
    "results_stacking_imbalanced_merged = pd.concat([results_stacking_imbalanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_imbalanced, train_feature_sets_imbalanced_merged, style_train_imbalanced['target'], exclude_models=['dt', 'nb', 'lr'], append_features=False)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_imbalanced, test_feature_sets_imbalanced_merged, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'lr'], append_features=False, result_row_name=\"Algorithms: rf, gb merged, with LogisticRegression\")\n",
    "results_stacking_imbalanced_merged = pd.concat([results_stacking_imbalanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_imbalanced, train_feature_sets_imbalanced_merged, style_train_imbalanced['target'], exclude_models=['dt', 'nb', 'rf'], append_features=False)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_imbalanced, test_feature_sets_imbalanced_merged, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'rf'], append_features=False, result_row_name=\"Algorithms: lr, gb merged, with LogisticRegression\")\n",
    "results_stacking_imbalanced_merged = pd.concat([results_stacking_imbalanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_imbalanced, train_feature_sets_imbalanced_merged, style_train_imbalanced['target'], exclude_models=['dt', 'nb', 'gb'], append_features=False)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_imbalanced, test_feature_sets_imbalanced_merged, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb'], append_features=False, result_row_name=\"Algorithms: rf, lr merged, with LogisticRegression\")\n",
    "results_stacking_imbalanced_merged = pd.concat([results_stacking_imbalanced_merged, stacked_preds['results']])\n",
    "\n",
    "# Append features\n",
    "stacked_clf = ml.train_stacked_models(merged_models_imbalanced, train_feature_sets_imbalanced_merged, style_train_imbalanced['target'], exclude_models=['dt', 'nb'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_imbalanced, test_feature_sets_imbalanced_merged, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb'], append_features=True, result_row_name=\"Algorithms: lr, rf, gb merged, with LogisticRegression (with appended features)\")\n",
    "results_stacking_imbalanced_merged = pd.concat([results_stacking_imbalanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_imbalanced, train_feature_sets_imbalanced_merged, style_train_imbalanced['target'], exclude_models=['dt', 'nb', 'lr'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_imbalanced, test_feature_sets_imbalanced_merged, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'lr'], append_features=True, result_row_name=\"Algorithms: rf, gb merged, with LogisticRegression (with appended features)\")\n",
    "results_stacking_imbalanced_merged = pd.concat([results_stacking_imbalanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_imbalanced, train_feature_sets_imbalanced_merged, style_train_imbalanced['target'], exclude_models=['dt', 'nb', 'rf'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_imbalanced, test_feature_sets_imbalanced_merged, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'rf'], append_features=True, result_row_name=\"Algorithms: lr, gb merged, with LogisticRegression (with appended features)\")\n",
    "results_stacking_imbalanced_merged = pd.concat([results_stacking_imbalanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_imbalanced, train_feature_sets_imbalanced_merged, style_train_imbalanced['target'], exclude_models=['dt', 'nb', 'gb'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_imbalanced, test_feature_sets_imbalanced_merged, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb'], append_features=True, result_row_name=\"Algorithms: rf, lr merged, with LogisticRegression (with appended features)\")\n",
    "results_stacking_imbalanced_merged = pd.concat([results_stacking_imbalanced_merged, stacked_preds['results']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeaf03c2",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8834a342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22min 29s, sys: 4min 53s, total: 27min 22s\n",
      "Wall time: 19min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stacked_clf = ml.train_stacked_models(merged_models_imbalanced, train_feature_sets_imbalanced_merged, style_train_imbalanced['target'], final_classifier=rf, exclude_models=['dt', 'nb'], append_features=False)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_imbalanced, test_feature_sets_imbalanced_merged, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb'], append_features=False, result_row_name=\"Algorithms: lr, rf, gb merged, with RandomForestClassifier\")\n",
    "results_stacking_imbalanced_merged = pd.concat([results_stacking_imbalanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_imbalanced, train_feature_sets_imbalanced_merged, style_train_imbalanced['target'], final_classifier=rf, exclude_models=['dt', 'nb', 'lr'], append_features=False)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_imbalanced, test_feature_sets_imbalanced_merged, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'lr'], append_features=False, result_row_name=\"Algorithms: rf, gb merged, with RandomForestClassifier\")\n",
    "results_stacking_imbalanced_merged = pd.concat([results_stacking_imbalanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_imbalanced, train_feature_sets_imbalanced_merged, style_train_imbalanced['target'], final_classifier=rf, exclude_models=['dt', 'nb', 'rf'], append_features=False)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_imbalanced, test_feature_sets_imbalanced_merged, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'rf'], append_features=False, result_row_name=\"Algorithms: lr, gb merged, with RandomForestClassifier\")\n",
    "results_stacking_imbalanced_merged = pd.concat([results_stacking_imbalanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_imbalanced, train_feature_sets_imbalanced_merged, style_train_imbalanced['target'], final_classifier=rf, exclude_models=['dt', 'nb', 'gb'], append_features=False)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_imbalanced, test_feature_sets_imbalanced_merged, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb'], append_features=False, result_row_name=\"Algorithms: rf, lr merged, with RandomForestClassifier\")\n",
    "results_stacking_imbalanced_merged = pd.concat([results_stacking_imbalanced_merged, stacked_preds['results']])\n",
    "\n",
    "# Append features\n",
    "stacked_clf = ml.train_stacked_models(merged_models_imbalanced, train_feature_sets_imbalanced_merged, style_train_imbalanced['target'], final_classifier=rf, exclude_models=['dt', 'nb'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_imbalanced, test_feature_sets_imbalanced_merged, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb'], append_features=True, result_row_name=\"Algorithms: lr, rf, gb merged, with RandomForestClassifier (with appended features)\")\n",
    "results_stacking_imbalanced_merged = pd.concat([results_stacking_imbalanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_imbalanced, train_feature_sets_imbalanced_merged, style_train_imbalanced['target'], final_classifier=rf, exclude_models=['dt', 'nb', 'lr'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_imbalanced, test_feature_sets_imbalanced_merged, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'lr'], append_features=True, result_row_name=\"Algorithms: rf, gb merged, with RandomForestClassifier (with appended features)\")\n",
    "results_stacking_imbalanced_merged = pd.concat([results_stacking_imbalanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_imbalanced, train_feature_sets_imbalanced_merged, style_train_imbalanced['target'], final_classifier=rf, exclude_models=['dt', 'nb', 'rf'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_imbalanced, test_feature_sets_imbalanced_merged, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'rf'], append_features=True, result_row_name=\"Algorithms: lr, gb merged, with RandomForestClassifier (with appended features)\")\n",
    "results_stacking_imbalanced_merged = pd.concat([results_stacking_imbalanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_imbalanced, train_feature_sets_imbalanced_merged, style_train_imbalanced['target'], final_classifier=rf, exclude_models=['dt', 'nb', 'gb'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_imbalanced, test_feature_sets_imbalanced_merged, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb'], append_features=True, result_row_name=\"Algorithms: rf, lr merged, with RandomForestClassifier (with appended features)\")\n",
    "results_stacking_imbalanced_merged = pd.concat([results_stacking_imbalanced_merged, stacked_preds['results']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0e3fa2",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8c2e1bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26min 51s, sys: 6min 27s, total: 33min 18s\n",
      "Wall time: 22min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stacked_clf = ml.train_stacked_models(merged_models_imbalanced, train_feature_sets_imbalanced_merged, style_train_imbalanced['target'], final_classifier=gb, exclude_models=['dt', 'nb'], append_features=False)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_imbalanced, test_feature_sets_imbalanced_merged, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb'], append_features=False, result_row_name=\"Algorithms: lr, rf, gb merged, with GradientBoostingClassifier\")\n",
    "results_stacking_imbalanced_merged = pd.concat([results_stacking_imbalanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_imbalanced, train_feature_sets_imbalanced_merged, style_train_imbalanced['target'], final_classifier=gb, exclude_models=['dt', 'nb', 'lr'], append_features=False)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_imbalanced, test_feature_sets_imbalanced_merged, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'lr'], append_features=False, result_row_name=\"Algorithms: rf, gb merged, with GradientBoostingClassifier\")\n",
    "results_stacking_imbalanced_merged = pd.concat([results_stacking_imbalanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_imbalanced, train_feature_sets_imbalanced_merged, style_train_imbalanced['target'], final_classifier=gb, exclude_models=['dt', 'nb', 'rf'], append_features=False)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_imbalanced, test_feature_sets_imbalanced_merged, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'rf'], append_features=False, result_row_name=\"Algorithms: lr, gb merged, with GradientBoostingClassifier\")\n",
    "results_stacking_imbalanced_merged = pd.concat([results_stacking_imbalanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_imbalanced, train_feature_sets_imbalanced_merged, style_train_imbalanced['target'], final_classifier=gb, exclude_models=['dt', 'nb', 'gb'], append_features=False)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_imbalanced, test_feature_sets_imbalanced_merged, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb'], append_features=False, result_row_name=\"Algorithms: rf, lr merged, with GradientBoostingClassifier\")\n",
    "results_stacking_imbalanced_merged = pd.concat([results_stacking_imbalanced_merged, stacked_preds['results']])\n",
    "\n",
    "# Append features\n",
    "stacked_clf = ml.train_stacked_models(merged_models_imbalanced, train_feature_sets_imbalanced_merged, style_train_imbalanced['target'], final_classifier=gb, exclude_models=['dt', 'nb'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_imbalanced, test_feature_sets_imbalanced_merged, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb'], append_features=True, result_row_name=\"Algorithms: lr, rf, gb merged, with GradientBoostingClassifier (with appended features)\")\n",
    "results_stacking_imbalanced_merged = pd.concat([results_stacking_imbalanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_imbalanced, train_feature_sets_imbalanced_merged, style_train_imbalanced['target'], final_classifier=gb, exclude_models=['dt', 'nb', 'lr'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_imbalanced, test_feature_sets_imbalanced_merged, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'lr'], append_features=True, result_row_name=\"Algorithms: rf, gb merged, with GradientBoostingClassifier (with appended features)\")\n",
    "results_stacking_imbalanced_merged = pd.concat([results_stacking_imbalanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_imbalanced, train_feature_sets_imbalanced_merged, style_train_imbalanced['target'], final_classifier=gb, exclude_models=['dt', 'nb', 'rf'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_imbalanced, test_feature_sets_imbalanced_merged, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'rf'], append_features=True, result_row_name=\"Algorithms: lr, gb merged, with GradientBoostingClassifier (with appended features)\")\n",
    "results_stacking_imbalanced_merged = pd.concat([results_stacking_imbalanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_imbalanced, train_feature_sets_imbalanced_merged, style_train_imbalanced['target'], final_classifier=gb, exclude_models=['dt', 'nb', 'gb'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_imbalanced, test_feature_sets_imbalanced_merged, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb'], append_features=True, result_row_name=\"Algorithms: rf, lr merged, with GradientBoostingClassifier (with appended features)\")\n",
    "results_stacking_imbalanced_merged = pd.concat([results_stacking_imbalanced_merged, stacked_preds['results']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8f524cae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>Area Under ROC Curve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, rf, gb merged, with LogisticRegression</th>\n",
       "      <td>0.992703</td>\n",
       "      <td>0.974441</td>\n",
       "      <td>0.941358</td>\n",
       "      <td>0.957614</td>\n",
       "      <td>0.002370</td>\n",
       "      <td>0.058642</td>\n",
       "      <td>0.998603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, gb merged, with LogisticRegression</th>\n",
       "      <td>0.990811</td>\n",
       "      <td>0.964744</td>\n",
       "      <td>0.929012</td>\n",
       "      <td>0.946541</td>\n",
       "      <td>0.003258</td>\n",
       "      <td>0.070988</td>\n",
       "      <td>0.997282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, gb merged, with LogisticRegression</th>\n",
       "      <td>0.992162</td>\n",
       "      <td>0.968254</td>\n",
       "      <td>0.941358</td>\n",
       "      <td>0.954617</td>\n",
       "      <td>0.002962</td>\n",
       "      <td>0.058642</td>\n",
       "      <td>0.999003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, lr merged, with LogisticRegression</th>\n",
       "      <td>0.991892</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.929012</td>\n",
       "      <td>0.952532</td>\n",
       "      <td>0.002073</td>\n",
       "      <td>0.070988</td>\n",
       "      <td>0.997752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, rf, gb merged, with LogisticRegression (with appended features)</th>\n",
       "      <td>0.991081</td>\n",
       "      <td>0.964856</td>\n",
       "      <td>0.932099</td>\n",
       "      <td>0.948195</td>\n",
       "      <td>0.003258</td>\n",
       "      <td>0.067901</td>\n",
       "      <td>0.993531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, gb merged, with LogisticRegression (with appended features)</th>\n",
       "      <td>0.992703</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.992919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, gb merged, with LogisticRegression (with appended features)</th>\n",
       "      <td>0.990541</td>\n",
       "      <td>0.958730</td>\n",
       "      <td>0.932099</td>\n",
       "      <td>0.945227</td>\n",
       "      <td>0.003851</td>\n",
       "      <td>0.067901</td>\n",
       "      <td>0.993459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, lr merged, with LogisticRegression (with appended features)</th>\n",
       "      <td>0.989459</td>\n",
       "      <td>0.961165</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.938389</td>\n",
       "      <td>0.003555</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.993355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, rf, gb merged, with RandomForestClassifier</th>\n",
       "      <td>0.992432</td>\n",
       "      <td>0.968354</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.956250</td>\n",
       "      <td>0.002962</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.998952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, gb merged, with RandomForestClassifier</th>\n",
       "      <td>0.991081</td>\n",
       "      <td>0.950464</td>\n",
       "      <td>0.947531</td>\n",
       "      <td>0.948995</td>\n",
       "      <td>0.004739</td>\n",
       "      <td>0.052469</td>\n",
       "      <td>0.998049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, gb merged, with RandomForestClassifier</th>\n",
       "      <td>0.992973</td>\n",
       "      <td>0.974522</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.959248</td>\n",
       "      <td>0.002370</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.998957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, lr merged, with RandomForestClassifier</th>\n",
       "      <td>0.990541</td>\n",
       "      <td>0.980066</td>\n",
       "      <td>0.910494</td>\n",
       "      <td>0.944000</td>\n",
       "      <td>0.001777</td>\n",
       "      <td>0.089506</td>\n",
       "      <td>0.998119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, rf, gb merged, with RandomForestClassifier (with appended features)</th>\n",
       "      <td>0.992162</td>\n",
       "      <td>0.977346</td>\n",
       "      <td>0.932099</td>\n",
       "      <td>0.954186</td>\n",
       "      <td>0.002073</td>\n",
       "      <td>0.067901</td>\n",
       "      <td>0.998186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, gb merged, with RandomForestClassifier (with appended features)</th>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.970492</td>\n",
       "      <td>0.913580</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>0.086420</td>\n",
       "      <td>0.994579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, gb merged, with RandomForestClassifier (with appended features)</th>\n",
       "      <td>0.992162</td>\n",
       "      <td>0.986799</td>\n",
       "      <td>0.922840</td>\n",
       "      <td>0.953748</td>\n",
       "      <td>0.001185</td>\n",
       "      <td>0.077160</td>\n",
       "      <td>0.997266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, lr merged, with RandomForestClassifier (with appended features)</th>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.986441</td>\n",
       "      <td>0.898148</td>\n",
       "      <td>0.940226</td>\n",
       "      <td>0.001185</td>\n",
       "      <td>0.101852</td>\n",
       "      <td>0.996616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, rf, gb merged, with GradientBoostingClassifier</th>\n",
       "      <td>0.991892</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.953271</td>\n",
       "      <td>0.003555</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.998814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, gb merged, with GradientBoostingClassifier</th>\n",
       "      <td>0.990811</td>\n",
       "      <td>0.947531</td>\n",
       "      <td>0.947531</td>\n",
       "      <td>0.947531</td>\n",
       "      <td>0.005036</td>\n",
       "      <td>0.052469</td>\n",
       "      <td>0.997845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, gb merged, with GradientBoostingClassifier</th>\n",
       "      <td>0.991351</td>\n",
       "      <td>0.959119</td>\n",
       "      <td>0.941358</td>\n",
       "      <td>0.950156</td>\n",
       "      <td>0.003851</td>\n",
       "      <td>0.058642</td>\n",
       "      <td>0.998689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, lr merged, with GradientBoostingClassifier</th>\n",
       "      <td>0.990541</td>\n",
       "      <td>0.964630</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.944882</td>\n",
       "      <td>0.003258</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.996858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, rf, gb merged, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.992162</td>\n",
       "      <td>0.959502</td>\n",
       "      <td>0.950617</td>\n",
       "      <td>0.955039</td>\n",
       "      <td>0.003851</td>\n",
       "      <td>0.049383</td>\n",
       "      <td>0.998569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, gb merged, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.992162</td>\n",
       "      <td>0.962382</td>\n",
       "      <td>0.947531</td>\n",
       "      <td>0.954899</td>\n",
       "      <td>0.003555</td>\n",
       "      <td>0.052469</td>\n",
       "      <td>0.998358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, gb merged, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.991892</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.950617</td>\n",
       "      <td>0.953560</td>\n",
       "      <td>0.004147</td>\n",
       "      <td>0.049383</td>\n",
       "      <td>0.998556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, lr merged, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.992162</td>\n",
       "      <td>0.971246</td>\n",
       "      <td>0.938272</td>\n",
       "      <td>0.954474</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>0.061728</td>\n",
       "      <td>0.998236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Accuracy  Precision  \\\n",
       "Algorithms: lr, rf, gb merged, with LogisticReg...  0.992703   0.974441   \n",
       "Algorithms: rf, gb merged, with LogisticRegression  0.990811   0.964744   \n",
       "Algorithms: lr, gb merged, with LogisticRegression  0.992162   0.968254   \n",
       "Algorithms: rf, lr merged, with LogisticRegression  0.991892   0.977273   \n",
       "Algorithms: lr, rf, gb merged, with LogisticReg...  0.991081   0.964856   \n",
       "Algorithms: rf, gb merged, with LogisticRegress...  0.992703   0.971429   \n",
       "Algorithms: lr, gb merged, with LogisticRegress...  0.990541   0.958730   \n",
       "Algorithms: rf, lr merged, with LogisticRegress...  0.989459   0.961165   \n",
       "Algorithms: lr, rf, gb merged, with RandomFores...  0.992432   0.968354   \n",
       "Algorithms: rf, gb merged, with RandomForestCla...  0.991081   0.950464   \n",
       "Algorithms: lr, gb merged, with RandomForestCla...  0.992973   0.974522   \n",
       "Algorithms: rf, lr merged, with RandomForestCla...  0.990541   0.980066   \n",
       "Algorithms: lr, rf, gb merged, with RandomFores...  0.992162   0.977346   \n",
       "Algorithms: rf, gb merged, with RandomForestCla...  0.990000   0.970492   \n",
       "Algorithms: lr, gb merged, with RandomForestCla...  0.992162   0.986799   \n",
       "Algorithms: rf, lr merged, with RandomForestCla...  0.990000   0.986441   \n",
       "Algorithms: lr, rf, gb merged, with GradientBoo...  0.991892   0.962264   \n",
       "Algorithms: rf, gb merged, with GradientBoostin...  0.990811   0.947531   \n",
       "Algorithms: lr, gb merged, with GradientBoostin...  0.991351   0.959119   \n",
       "Algorithms: rf, lr merged, with GradientBoostin...  0.990541   0.964630   \n",
       "Algorithms: lr, rf, gb merged, with GradientBoo...  0.992162   0.959502   \n",
       "Algorithms: rf, gb merged, with GradientBoostin...  0.992162   0.962382   \n",
       "Algorithms: lr, gb merged, with GradientBoostin...  0.991892   0.956522   \n",
       "Algorithms: rf, lr merged, with GradientBoostin...  0.992162   0.971246   \n",
       "\n",
       "                                                      Recall  F1 Score  \\\n",
       "Algorithms: lr, rf, gb merged, with LogisticReg...  0.941358  0.957614   \n",
       "Algorithms: rf, gb merged, with LogisticRegression  0.929012  0.946541   \n",
       "Algorithms: lr, gb merged, with LogisticRegression  0.941358  0.954617   \n",
       "Algorithms: rf, lr merged, with LogisticRegression  0.929012  0.952532   \n",
       "Algorithms: lr, rf, gb merged, with LogisticReg...  0.932099  0.948195   \n",
       "Algorithms: rf, gb merged, with LogisticRegress...  0.944444  0.957746   \n",
       "Algorithms: lr, gb merged, with LogisticRegress...  0.932099  0.945227   \n",
       "Algorithms: rf, lr merged, with LogisticRegress...  0.916667  0.938389   \n",
       "Algorithms: lr, rf, gb merged, with RandomFores...  0.944444  0.956250   \n",
       "Algorithms: rf, gb merged, with RandomForestCla...  0.947531  0.948995   \n",
       "Algorithms: lr, gb merged, with RandomForestCla...  0.944444  0.959248   \n",
       "Algorithms: rf, lr merged, with RandomForestCla...  0.910494  0.944000   \n",
       "Algorithms: lr, rf, gb merged, with RandomFores...  0.932099  0.954186   \n",
       "Algorithms: rf, gb merged, with RandomForestCla...  0.913580  0.941176   \n",
       "Algorithms: lr, gb merged, with RandomForestCla...  0.922840  0.953748   \n",
       "Algorithms: rf, lr merged, with RandomForestCla...  0.898148  0.940226   \n",
       "Algorithms: lr, rf, gb merged, with GradientBoo...  0.944444  0.953271   \n",
       "Algorithms: rf, gb merged, with GradientBoostin...  0.947531  0.947531   \n",
       "Algorithms: lr, gb merged, with GradientBoostin...  0.941358  0.950156   \n",
       "Algorithms: rf, lr merged, with GradientBoostin...  0.925926  0.944882   \n",
       "Algorithms: lr, rf, gb merged, with GradientBoo...  0.950617  0.955039   \n",
       "Algorithms: rf, gb merged, with GradientBoostin...  0.947531  0.954899   \n",
       "Algorithms: lr, gb merged, with GradientBoostin...  0.950617  0.953560   \n",
       "Algorithms: rf, lr merged, with GradientBoostin...  0.938272  0.954474   \n",
       "\n",
       "                                                    False Positive Rate  \\\n",
       "Algorithms: lr, rf, gb merged, with LogisticReg...             0.002370   \n",
       "Algorithms: rf, gb merged, with LogisticRegression             0.003258   \n",
       "Algorithms: lr, gb merged, with LogisticRegression             0.002962   \n",
       "Algorithms: rf, lr merged, with LogisticRegression             0.002073   \n",
       "Algorithms: lr, rf, gb merged, with LogisticReg...             0.003258   \n",
       "Algorithms: rf, gb merged, with LogisticRegress...             0.002666   \n",
       "Algorithms: lr, gb merged, with LogisticRegress...             0.003851   \n",
       "Algorithms: rf, lr merged, with LogisticRegress...             0.003555   \n",
       "Algorithms: lr, rf, gb merged, with RandomFores...             0.002962   \n",
       "Algorithms: rf, gb merged, with RandomForestCla...             0.004739   \n",
       "Algorithms: lr, gb merged, with RandomForestCla...             0.002370   \n",
       "Algorithms: rf, lr merged, with RandomForestCla...             0.001777   \n",
       "Algorithms: lr, rf, gb merged, with RandomFores...             0.002073   \n",
       "Algorithms: rf, gb merged, with RandomForestCla...             0.002666   \n",
       "Algorithms: lr, gb merged, with RandomForestCla...             0.001185   \n",
       "Algorithms: rf, lr merged, with RandomForestCla...             0.001185   \n",
       "Algorithms: lr, rf, gb merged, with GradientBoo...             0.003555   \n",
       "Algorithms: rf, gb merged, with GradientBoostin...             0.005036   \n",
       "Algorithms: lr, gb merged, with GradientBoostin...             0.003851   \n",
       "Algorithms: rf, lr merged, with GradientBoostin...             0.003258   \n",
       "Algorithms: lr, rf, gb merged, with GradientBoo...             0.003851   \n",
       "Algorithms: rf, gb merged, with GradientBoostin...             0.003555   \n",
       "Algorithms: lr, gb merged, with GradientBoostin...             0.004147   \n",
       "Algorithms: rf, lr merged, with GradientBoostin...             0.002666   \n",
       "\n",
       "                                                    False Negative Rate  \\\n",
       "Algorithms: lr, rf, gb merged, with LogisticReg...             0.058642   \n",
       "Algorithms: rf, gb merged, with LogisticRegression             0.070988   \n",
       "Algorithms: lr, gb merged, with LogisticRegression             0.058642   \n",
       "Algorithms: rf, lr merged, with LogisticRegression             0.070988   \n",
       "Algorithms: lr, rf, gb merged, with LogisticReg...             0.067901   \n",
       "Algorithms: rf, gb merged, with LogisticRegress...             0.055556   \n",
       "Algorithms: lr, gb merged, with LogisticRegress...             0.067901   \n",
       "Algorithms: rf, lr merged, with LogisticRegress...             0.083333   \n",
       "Algorithms: lr, rf, gb merged, with RandomFores...             0.055556   \n",
       "Algorithms: rf, gb merged, with RandomForestCla...             0.052469   \n",
       "Algorithms: lr, gb merged, with RandomForestCla...             0.055556   \n",
       "Algorithms: rf, lr merged, with RandomForestCla...             0.089506   \n",
       "Algorithms: lr, rf, gb merged, with RandomFores...             0.067901   \n",
       "Algorithms: rf, gb merged, with RandomForestCla...             0.086420   \n",
       "Algorithms: lr, gb merged, with RandomForestCla...             0.077160   \n",
       "Algorithms: rf, lr merged, with RandomForestCla...             0.101852   \n",
       "Algorithms: lr, rf, gb merged, with GradientBoo...             0.055556   \n",
       "Algorithms: rf, gb merged, with GradientBoostin...             0.052469   \n",
       "Algorithms: lr, gb merged, with GradientBoostin...             0.058642   \n",
       "Algorithms: rf, lr merged, with GradientBoostin...             0.074074   \n",
       "Algorithms: lr, rf, gb merged, with GradientBoo...             0.049383   \n",
       "Algorithms: rf, gb merged, with GradientBoostin...             0.052469   \n",
       "Algorithms: lr, gb merged, with GradientBoostin...             0.049383   \n",
       "Algorithms: rf, lr merged, with GradientBoostin...             0.061728   \n",
       "\n",
       "                                                    Area Under ROC Curve  \n",
       "Algorithms: lr, rf, gb merged, with LogisticReg...              0.998603  \n",
       "Algorithms: rf, gb merged, with LogisticRegression              0.997282  \n",
       "Algorithms: lr, gb merged, with LogisticRegression              0.999003  \n",
       "Algorithms: rf, lr merged, with LogisticRegression              0.997752  \n",
       "Algorithms: lr, rf, gb merged, with LogisticReg...              0.993531  \n",
       "Algorithms: rf, gb merged, with LogisticRegress...              0.992919  \n",
       "Algorithms: lr, gb merged, with LogisticRegress...              0.993459  \n",
       "Algorithms: rf, lr merged, with LogisticRegress...              0.993355  \n",
       "Algorithms: lr, rf, gb merged, with RandomFores...              0.998952  \n",
       "Algorithms: rf, gb merged, with RandomForestCla...              0.998049  \n",
       "Algorithms: lr, gb merged, with RandomForestCla...              0.998957  \n",
       "Algorithms: rf, lr merged, with RandomForestCla...              0.998119  \n",
       "Algorithms: lr, rf, gb merged, with RandomFores...              0.998186  \n",
       "Algorithms: rf, gb merged, with RandomForestCla...              0.994579  \n",
       "Algorithms: lr, gb merged, with RandomForestCla...              0.997266  \n",
       "Algorithms: rf, lr merged, with RandomForestCla...              0.996616  \n",
       "Algorithms: lr, rf, gb merged, with GradientBoo...              0.998814  \n",
       "Algorithms: rf, gb merged, with GradientBoostin...              0.997845  \n",
       "Algorithms: lr, gb merged, with GradientBoostin...              0.998689  \n",
       "Algorithms: rf, lr merged, with GradientBoostin...              0.996858  \n",
       "Algorithms: lr, rf, gb merged, with GradientBoo...              0.998569  \n",
       "Algorithms: rf, gb merged, with GradientBoostin...              0.998358  \n",
       "Algorithms: lr, gb merged, with GradientBoostin...              0.998556  \n",
       "Algorithms: rf, lr merged, with GradientBoostin...              0.998236  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_stacking_imbalanced_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e05466",
   "metadata": {},
   "source": [
    "These models did not perform as well as the previous ones, but in general were better than the baseline with merged features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f6335811",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stacking_imbalanced_best = pd.concat([results_stacking_imbalanced_best, results_stacking_imbalanced_merged.sort_values(by=['F1 Score'], ascending = [False]).head(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a7405bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stacking_imbalanced_full = pd.concat([results_stacking_imbalanced_full, results_stacking_imbalanced_merged])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e69d51b1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>Area Under ROC Curve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, gb, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.994054</td>\n",
       "      <td>0.977848</td>\n",
       "      <td>0.953704</td>\n",
       "      <td>0.965625</td>\n",
       "      <td>0.002073</td>\n",
       "      <td>0.046296</td>\n",
       "      <td>0.999021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, gb, with GradientBoostingClassifier</th>\n",
       "      <td>0.993784</td>\n",
       "      <td>0.974763</td>\n",
       "      <td>0.953704</td>\n",
       "      <td>0.964119</td>\n",
       "      <td>0.002370</td>\n",
       "      <td>0.046296</td>\n",
       "      <td>0.998875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: all, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.993784</td>\n",
       "      <td>0.980831</td>\n",
       "      <td>0.947531</td>\n",
       "      <td>0.963893</td>\n",
       "      <td>0.001777</td>\n",
       "      <td>0.052469</td>\n",
       "      <td>0.999175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: all, with LogisticRegression</th>\n",
       "      <td>0.993784</td>\n",
       "      <td>0.983923</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.963780</td>\n",
       "      <td>0.001481</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.996701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, gb, with LogisticRegression</th>\n",
       "      <td>0.993514</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.001777</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.997376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: gb, with LogisticRegression (with appended features)</th>\n",
       "      <td>0.993514</td>\n",
       "      <td>0.983871</td>\n",
       "      <td>0.941358</td>\n",
       "      <td>0.962145</td>\n",
       "      <td>0.001481</td>\n",
       "      <td>0.058642</td>\n",
       "      <td>0.993473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.993514</td>\n",
       "      <td>0.983871</td>\n",
       "      <td>0.941358</td>\n",
       "      <td>0.962145</td>\n",
       "      <td>0.001481</td>\n",
       "      <td>0.058642</td>\n",
       "      <td>0.998843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, rf, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.993243</td>\n",
       "      <td>0.971609</td>\n",
       "      <td>0.950617</td>\n",
       "      <td>0.960998</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>0.049383</td>\n",
       "      <td>0.998888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, rf, gb, with LogisticRegression</th>\n",
       "      <td>0.993243</td>\n",
       "      <td>0.974603</td>\n",
       "      <td>0.947531</td>\n",
       "      <td>0.960876</td>\n",
       "      <td>0.002370</td>\n",
       "      <td>0.052469</td>\n",
       "      <td>0.996843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: all, with RandomForestClassifier</th>\n",
       "      <td>0.993243</td>\n",
       "      <td>0.974603</td>\n",
       "      <td>0.947531</td>\n",
       "      <td>0.960876</td>\n",
       "      <td>0.002370</td>\n",
       "      <td>0.052469</td>\n",
       "      <td>0.998764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, rf, gb, with GradientBoostingClassifier</th>\n",
       "      <td>0.993243</td>\n",
       "      <td>0.974603</td>\n",
       "      <td>0.947531</td>\n",
       "      <td>0.960876</td>\n",
       "      <td>0.002370</td>\n",
       "      <td>0.052469</td>\n",
       "      <td>0.998923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, rf, gb, with RandomForestClassifier</th>\n",
       "      <td>0.993243</td>\n",
       "      <td>0.980707</td>\n",
       "      <td>0.941358</td>\n",
       "      <td>0.960630</td>\n",
       "      <td>0.001777</td>\n",
       "      <td>0.058642</td>\n",
       "      <td>0.998818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, rf, gb, with LogisticRegression (with appended features)</th>\n",
       "      <td>0.993243</td>\n",
       "      <td>0.980707</td>\n",
       "      <td>0.941358</td>\n",
       "      <td>0.960630</td>\n",
       "      <td>0.001777</td>\n",
       "      <td>0.058642</td>\n",
       "      <td>0.994992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Accuracy  Precision  \\\n",
       "Algorithms: lr, gb, with GradientBoostingClassi...  0.994054   0.977848   \n",
       "Algorithms: lr, gb, with GradientBoostingClassi...  0.993784   0.974763   \n",
       "Algorithms: all, with GradientBoostingClassifie...  0.993784   0.980831   \n",
       "Algorithms: all, with LogisticRegression            0.993784   0.983923   \n",
       "Algorithms: lr, gb, with LogisticRegression         0.993514   0.980769   \n",
       "Algorithms: gb, with LogisticRegression (with a...  0.993514   0.983871   \n",
       "Algorithms: lr, with GradientBoostingClassifier...  0.993514   0.983871   \n",
       "Algorithms: lr, rf, with GradientBoostingClassi...  0.993243   0.971609   \n",
       "Algorithms: lr, rf, gb, with LogisticRegression     0.993243   0.974603   \n",
       "Algorithms: all, with RandomForestClassifier        0.993243   0.974603   \n",
       "Algorithms: lr, rf, gb, with GradientBoostingCl...  0.993243   0.974603   \n",
       "Algorithms: lr, rf, gb, with RandomForestClassi...  0.993243   0.980707   \n",
       "Algorithms: lr, rf, gb, with LogisticRegression...  0.993243   0.980707   \n",
       "\n",
       "                                                      Recall  F1 Score  \\\n",
       "Algorithms: lr, gb, with GradientBoostingClassi...  0.953704  0.965625   \n",
       "Algorithms: lr, gb, with GradientBoostingClassi...  0.953704  0.964119   \n",
       "Algorithms: all, with GradientBoostingClassifie...  0.947531  0.963893   \n",
       "Algorithms: all, with LogisticRegression            0.944444  0.963780   \n",
       "Algorithms: lr, gb, with LogisticRegression         0.944444  0.962264   \n",
       "Algorithms: gb, with LogisticRegression (with a...  0.941358  0.962145   \n",
       "Algorithms: lr, with GradientBoostingClassifier...  0.941358  0.962145   \n",
       "Algorithms: lr, rf, with GradientBoostingClassi...  0.950617  0.960998   \n",
       "Algorithms: lr, rf, gb, with LogisticRegression     0.947531  0.960876   \n",
       "Algorithms: all, with RandomForestClassifier        0.947531  0.960876   \n",
       "Algorithms: lr, rf, gb, with GradientBoostingCl...  0.947531  0.960876   \n",
       "Algorithms: lr, rf, gb, with RandomForestClassi...  0.941358  0.960630   \n",
       "Algorithms: lr, rf, gb, with LogisticRegression...  0.941358  0.960630   \n",
       "\n",
       "                                                    False Positive Rate  \\\n",
       "Algorithms: lr, gb, with GradientBoostingClassi...             0.002073   \n",
       "Algorithms: lr, gb, with GradientBoostingClassi...             0.002370   \n",
       "Algorithms: all, with GradientBoostingClassifie...             0.001777   \n",
       "Algorithms: all, with LogisticRegression                       0.001481   \n",
       "Algorithms: lr, gb, with LogisticRegression                    0.001777   \n",
       "Algorithms: gb, with LogisticRegression (with a...             0.001481   \n",
       "Algorithms: lr, with GradientBoostingClassifier...             0.001481   \n",
       "Algorithms: lr, rf, with GradientBoostingClassi...             0.002666   \n",
       "Algorithms: lr, rf, gb, with LogisticRegression                0.002370   \n",
       "Algorithms: all, with RandomForestClassifier                   0.002370   \n",
       "Algorithms: lr, rf, gb, with GradientBoostingCl...             0.002370   \n",
       "Algorithms: lr, rf, gb, with RandomForestClassi...             0.001777   \n",
       "Algorithms: lr, rf, gb, with LogisticRegression...             0.001777   \n",
       "\n",
       "                                                    False Negative Rate  \\\n",
       "Algorithms: lr, gb, with GradientBoostingClassi...             0.046296   \n",
       "Algorithms: lr, gb, with GradientBoostingClassi...             0.046296   \n",
       "Algorithms: all, with GradientBoostingClassifie...             0.052469   \n",
       "Algorithms: all, with LogisticRegression                       0.055556   \n",
       "Algorithms: lr, gb, with LogisticRegression                    0.055556   \n",
       "Algorithms: gb, with LogisticRegression (with a...             0.058642   \n",
       "Algorithms: lr, with GradientBoostingClassifier...             0.058642   \n",
       "Algorithms: lr, rf, with GradientBoostingClassi...             0.049383   \n",
       "Algorithms: lr, rf, gb, with LogisticRegression                0.052469   \n",
       "Algorithms: all, with RandomForestClassifier                   0.052469   \n",
       "Algorithms: lr, rf, gb, with GradientBoostingCl...             0.052469   \n",
       "Algorithms: lr, rf, gb, with RandomForestClassi...             0.058642   \n",
       "Algorithms: lr, rf, gb, with LogisticRegression...             0.058642   \n",
       "\n",
       "                                                    Area Under ROC Curve  \n",
       "Algorithms: lr, gb, with GradientBoostingClassi...              0.999021  \n",
       "Algorithms: lr, gb, with GradientBoostingClassi...              0.998875  \n",
       "Algorithms: all, with GradientBoostingClassifie...              0.999175  \n",
       "Algorithms: all, with LogisticRegression                        0.996701  \n",
       "Algorithms: lr, gb, with LogisticRegression                     0.997376  \n",
       "Algorithms: gb, with LogisticRegression (with a...              0.993473  \n",
       "Algorithms: lr, with GradientBoostingClassifier...              0.998843  \n",
       "Algorithms: lr, rf, with GradientBoostingClassi...              0.998888  \n",
       "Algorithms: lr, rf, gb, with LogisticRegression                 0.996843  \n",
       "Algorithms: all, with RandomForestClassifier                    0.998764  \n",
       "Algorithms: lr, rf, gb, with GradientBoostingCl...              0.998923  \n",
       "Algorithms: lr, rf, gb, with RandomForestClassi...              0.998818  \n",
       "Algorithms: lr, rf, gb, with LogisticRegression...              0.994992  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_stacking_imbalanced_best.sort_values(by=['F1 Score'], ascending = [False]).head(13)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

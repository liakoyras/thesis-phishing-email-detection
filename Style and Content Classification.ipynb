{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e41204e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = 250\n",
    "\n",
    "import machine_learning as ml\n",
    "from preprocessing import separate_features_target\n",
    "\n",
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "702a8888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path\n",
    "cwd = os.getcwd()\n",
    "csv_path = os.path.join(cwd, 'data/csv/')\n",
    "\n",
    "train = {\n",
    "    'stylometric' : ['style_train_balanced.csv','style_train_imbalanced.csv'],\n",
    "    'word2vec' : ['word2vec_train_balanced.csv','word2vec_train_imbalanced.csv']\n",
    "}\n",
    "test = {\n",
    "    'stylometric' : ['style_test_balanced.csv','style_test_imbalanced.csv'],\n",
    "    'word2vec' : ['word2vec_test_balanced.csv','word2vec_test_imbalanced.csv']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424810a5",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02737f46",
   "metadata": {},
   "source": [
    "Since Word2Vec features outperformed the TF-IDF features, only those will be used to test the combination with content features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ebf18e",
   "metadata": {},
   "source": [
    "### Balanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19750b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "style_train_balanced_complete = pd.read_csv(os.path.join(csv_path, train['stylometric'][0]), index_col=0, dtype={'email_class': 'bool', 'email_id': 'int16'})\n",
    "style_test_balanced_complete = pd.read_csv(os.path.join(csv_path, test['stylometric'][0]), index_col=0, dtype={'email_class': 'bool', 'email_id': 'int16'})\n",
    "\n",
    "word2vec_train_balanced_complete = pd.read_csv(os.path.join(csv_path, train['word2vec'][0]), index_col=0, dtype={'email_class': 'bool', 'email_id': 'int16'})\n",
    "word2vec_test_balanced_complete = pd.read_csv(os.path.join(csv_path, test['word2vec'][0]), index_col=0, dtype={'email_class': 'bool', 'email_id': 'int16'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "117c14ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "style_train_balanced = separate_features_target(style_train_balanced_complete)\n",
    "style_test_balanced = separate_features_target(style_test_balanced_complete)\n",
    "\n",
    "word2vec_train_balanced = separate_features_target(word2vec_train_balanced_complete)\n",
    "word2vec_test_balanced = separate_features_target(word2vec_test_balanced_complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28b1832",
   "metadata": {},
   "source": [
    "### Imbalanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f07057f",
   "metadata": {},
   "outputs": [],
   "source": [
    "style_train_imbalanced_complete = pd.read_csv(os.path.join(csv_path, train['stylometric'][1]), index_col=0, dtype={'email_class': 'bool', 'email_id': 'int16'})\n",
    "style_test_imbalanced_complete = pd.read_csv(os.path.join(csv_path, test['stylometric'][1]), index_col=0, dtype={'email_class': 'bool', 'email_id': 'int16'})\n",
    "\n",
    "word2vec_train_imbalanced_complete = pd.read_csv(os.path.join(csv_path, train['word2vec'][1]), index_col=0, dtype={'email_class': 'bool', 'email_id': 'int16'})\n",
    "word2vec_test_imbalanced_complete = pd.read_csv(os.path.join(csv_path, test['word2vec'][1]), index_col=0, dtype={'email_class': 'bool', 'email_id': 'int16'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f680514",
   "metadata": {},
   "outputs": [],
   "source": [
    "style_train_imbalanced = separate_features_target(style_train_imbalanced_complete)\n",
    "style_test_imbalanced = separate_features_target(style_test_imbalanced_complete)\n",
    "\n",
    "word2vec_train_imbalanced = separate_features_target(word2vec_train_imbalanced_complete)\n",
    "word2vec_test_imbalanced = separate_features_target(word2vec_test_imbalanced_complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfda150",
   "metadata": {},
   "source": [
    "# Merging Feature Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464fccfe",
   "metadata": {},
   "source": [
    "The simplest way of combining the information of the two different feature sets is to simply merge them into one set and then perform the predictions based on this concatenated set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6cdc4a",
   "metadata": {},
   "source": [
    "## Balanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68f32c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "style_content_train_balanced = pd.concat([word2vec_train_balanced['features'], style_train_balanced['features']], axis=1)\n",
    "style_content_test_balanced = pd.concat([word2vec_test_balanced['features'], style_test_balanced['features']], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df122e5",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2957d9ed",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "828667e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9944320712694877\n"
     ]
    }
   ],
   "source": [
    "lr_style_content_balanced = ml.train_logistic_regression(style_content_train_balanced, style_train_balanced['target'], show_train_accuracy=1)\n",
    "lr_style_content_balanced, lr_style_content_balanced_scaler = lr_style_content_balanced['model'], lr_style_content_balanced['scaler']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6b7cd3",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76d32c44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9862657757980697\n"
     ]
    }
   ],
   "source": [
    "dt_style_content_balanced = ml.train_decision_tree(style_content_train_balanced, style_train_balanced['target'], show_train_accuracy=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16daa374",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58232f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9844097995545658\n"
     ]
    }
   ],
   "source": [
    "rf_style_content_balanced = ml.train_random_forest(style_content_train_balanced, style_train_balanced['target'], show_train_accuracy=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322a604a",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edcc3d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9974016332590943\n"
     ]
    }
   ],
   "source": [
    "gb_style_content_balanced = ml.train_gradient_boost(style_content_train_balanced, style_train_balanced['target'], show_train_accuracy=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5118b57c",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6a120f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9510022271714922\n"
     ]
    }
   ],
   "source": [
    "nb_style_content_balanced = ml.train_naive_bayes(style_content_train_balanced, style_train_balanced['target'], show_train_accuracy=1, remove_negatives=True)\n",
    "nb_style_content_balanced, nb_style_content_balanced_scaler = nb_style_content_balanced['model'], nb_style_content_balanced['scaler']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafc39b7",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b043c4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [lr_style_content_balanced, dt_style_content_balanced, rf_style_content_balanced, gb_style_content_balanced, nb_style_content_balanced]\n",
    "names = ['Logistic Regression', 'Decision Tree', 'Random Forest', 'Gradient Boosting Tree', 'Naive Bayes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "893cc6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_style_content_balanced = ml.multi_model_results(models, names, style_content_test_balanced, style_test_balanced['target'], lr_style_content_balanced_scaler, nb_style_content_balanced_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bec06c19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>Area Under ROC Curve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.965875</td>\n",
       "      <td>0.955182</td>\n",
       "      <td>0.979885</td>\n",
       "      <td>0.967376</td>\n",
       "      <td>0.049080</td>\n",
       "      <td>0.020115</td>\n",
       "      <td>0.965403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.951039</td>\n",
       "      <td>0.951289</td>\n",
       "      <td>0.954023</td>\n",
       "      <td>0.952654</td>\n",
       "      <td>0.052147</td>\n",
       "      <td>0.045977</td>\n",
       "      <td>0.950938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.968843</td>\n",
       "      <td>0.957983</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.970213</td>\n",
       "      <td>0.046012</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.968373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting Tree</th>\n",
       "      <td>0.967359</td>\n",
       "      <td>0.960452</td>\n",
       "      <td>0.977011</td>\n",
       "      <td>0.968661</td>\n",
       "      <td>0.042945</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>0.967033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.936202</td>\n",
       "      <td>0.957958</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.936858</td>\n",
       "      <td>0.042945</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.936861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Accuracy  Precision    Recall  F1 Score  \\\n",
       "Logistic Regression     0.965875   0.955182  0.979885  0.967376   \n",
       "Decision Tree           0.951039   0.951289  0.954023  0.952654   \n",
       "Random Forest           0.968843   0.957983  0.982759  0.970213   \n",
       "Gradient Boosting Tree  0.967359   0.960452  0.977011  0.968661   \n",
       "Naive Bayes             0.936202   0.957958  0.916667  0.936858   \n",
       "\n",
       "                        False Positive Rate  False Negative Rate  \\\n",
       "Logistic Regression                0.049080             0.020115   \n",
       "Decision Tree                      0.052147             0.045977   \n",
       "Random Forest                      0.046012             0.017241   \n",
       "Gradient Boosting Tree             0.042945             0.022989   \n",
       "Naive Bayes                        0.042945             0.083333   \n",
       "\n",
       "                        Area Under ROC Curve  \n",
       "Logistic Regression                 0.965403  \n",
       "Decision Tree                       0.950938  \n",
       "Random Forest                       0.968373  \n",
       "Gradient Boosting Tree              0.967033  \n",
       "Naive Bayes                         0.936861  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_style_content_balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde64486",
   "metadata": {},
   "source": [
    "## Imbalanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3eee1e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "style_content_train_imbalanced = pd.concat([word2vec_train_imbalanced['features'], style_train_imbalanced['features']], axis=1)\n",
    "style_content_test_imbalanced = pd.concat([word2vec_test_imbalanced['features'], style_test_imbalanced['features']], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1fd2fd",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3615327d",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02d925c3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9927692931477227\n"
     ]
    }
   ],
   "source": [
    "lr_style_content_imbalanced = ml.train_logistic_regression(style_content_train_imbalanced, style_train_imbalanced['target'], show_train_accuracy=1)\n",
    "lr_style_content_imbalanced, lr_style_content_imbalanced_scaler = lr_style_content_imbalanced['model'], lr_style_content_imbalanced['scaler']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0c2c28",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1fb6866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9833085552101636\n"
     ]
    }
   ],
   "source": [
    "dt_style_content_imbalanced = ml.train_decision_tree(style_content_train_imbalanced, style_train_imbalanced['target'], show_train_accuracy=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400dbaf8",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e067945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9846600892012434\n"
     ]
    }
   ],
   "source": [
    "rf_style_content_imbalanced = ml.train_random_forest(style_content_train_imbalanced, style_train_imbalanced['target'], show_train_accuracy=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e41141",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7d65c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9947965941343425\n"
     ]
    }
   ],
   "source": [
    "gb_style_content_imbalanced = ml.train_gradient_boost(style_content_train_imbalanced, style_train_imbalanced['target'], show_train_accuracy=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9953740",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d16b266",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9080281119070145\n"
     ]
    }
   ],
   "source": [
    "nb_style_content_imbalanced = ml.train_naive_bayes(style_content_train_imbalanced, style_train_imbalanced['target'], show_train_accuracy=1, remove_negatives=True)\n",
    "nb_style_content_imbalanced, nb_style_content_imbalanced_scaler = nb_style_content_imbalanced['model'], nb_style_content_imbalanced['scaler']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c23e477",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "416794b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [lr_style_content_imbalanced, dt_style_content_imbalanced, rf_style_content_imbalanced, gb_style_content_imbalanced, nb_style_content_imbalanced]\n",
    "names = ['Logistic Regression', 'Decision Tree', 'Random Forest', 'Gradient Boosting Tree', 'Naive Bayes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a8046fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_style_content_imbalanced = ml.multi_model_results(models, names, style_content_test_imbalanced, style_test_imbalanced['target'], lr_style_content_imbalanced_scaler, nb_style_content_imbalanced_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa564bda",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>Area Under ROC Curve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.988108</td>\n",
       "      <td>0.940252</td>\n",
       "      <td>0.922840</td>\n",
       "      <td>0.931464</td>\n",
       "      <td>0.005628</td>\n",
       "      <td>0.077160</td>\n",
       "      <td>0.958606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.977838</td>\n",
       "      <td>0.903333</td>\n",
       "      <td>0.836420</td>\n",
       "      <td>0.868590</td>\n",
       "      <td>0.008590</td>\n",
       "      <td>0.163580</td>\n",
       "      <td>0.913915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.979459</td>\n",
       "      <td>0.955882</td>\n",
       "      <td>0.802469</td>\n",
       "      <td>0.872483</td>\n",
       "      <td>0.003555</td>\n",
       "      <td>0.197531</td>\n",
       "      <td>0.899457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting Tree</th>\n",
       "      <td>0.988649</td>\n",
       "      <td>0.946203</td>\n",
       "      <td>0.922840</td>\n",
       "      <td>0.934375</td>\n",
       "      <td>0.005036</td>\n",
       "      <td>0.077160</td>\n",
       "      <td>0.958902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.912703</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003086</td>\n",
       "      <td>0.006154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.996914</td>\n",
       "      <td>0.501543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Accuracy  Precision    Recall  F1 Score  \\\n",
       "Logistic Regression     0.988108   0.940252  0.922840  0.931464   \n",
       "Decision Tree           0.977838   0.903333  0.836420  0.868590   \n",
       "Random Forest           0.979459   0.955882  0.802469  0.872483   \n",
       "Gradient Boosting Tree  0.988649   0.946203  0.922840  0.934375   \n",
       "Naive Bayes             0.912703   1.000000  0.003086  0.006154   \n",
       "\n",
       "                        False Positive Rate  False Negative Rate  \\\n",
       "Logistic Regression                0.005628             0.077160   \n",
       "Decision Tree                      0.008590             0.163580   \n",
       "Random Forest                      0.003555             0.197531   \n",
       "Gradient Boosting Tree             0.005036             0.077160   \n",
       "Naive Bayes                        0.000000             0.996914   \n",
       "\n",
       "                        Area Under ROC Curve  \n",
       "Logistic Regression                 0.958606  \n",
       "Decision Tree                       0.913915  \n",
       "Random Forest                       0.899457  \n",
       "Gradient Boosting Tree              0.958902  \n",
       "Naive Bayes                         0.501543  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_style_content_imbalanced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e02783e",
   "metadata": {},
   "source": [
    "Comparing these with the content-only baseline, it is obvious that there is a at least a small improvement in the balanced dataset and a more significant improvement in the imbalanced dataset.<br>\n",
    "It seems that the extra features are helpful in order to achieve better accuracy on the bigger dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc39478e",
   "metadata": {},
   "source": [
    "Another interesting observation is that the false negative rate of the two best performing algorithms is the same. This means that they both did not detect the same number of phishing emails (25)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "18a0bd88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_dt_predictions = ml.results_by_id([lr_style_content_imbalanced, gb_style_content_imbalanced], ['lr', 'gb'], pd.concat([style_test_imbalanced_complete[['email_id', 'email_class']],  style_content_test_imbalanced], axis=1), style_test_imbalanced_complete['email_id'], lr_style_content_imbalanced_scaler)\n",
    "lr_dt_predictions[(lr_dt_predictions['True Class'] == True) & ((lr_dt_predictions['lr'] == False) & (lr_dt_predictions['gb'] == False))].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973b826c",
   "metadata": {},
   "source": [
    "15 of them were missclassified by both algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2023540",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9003f184",
   "metadata": {},
   "source": [
    "In machine learning, stacking refers to the proccess of using different learners (each one working best at learning a different part of the problem) called level 0 models as intermediate steps and then use their outputs to train another learner, called level 1 model. Thus, the final model is sometimes able to outperform the individual ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93d4a2a",
   "metadata": {},
   "source": [
    "On this specific case, the different initial classifiers will be trained on both of the feature sets, and thus the final classifier essentially will combine information from both of them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b47088",
   "metadata": {},
   "source": [
    "#### Final Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82282b0f",
   "metadata": {},
   "source": [
    "Only the three best classifiers will be used as a level 1 classifier, namely Logistic Regression (which is implemented by default), Random Forest and Gradient Boosting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3d9c76aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = ml.RandomForestClassifier(max_depth=5, n_estimators=20, random_state=ml.alg_random_state)\n",
    "gb = ml.GradientBoostingClassifier(loss='log_loss', max_depth=3, learning_rate=0.1, random_state=ml.alg_random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc58a2a5",
   "metadata": {},
   "source": [
    "## Balanced Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32941e90",
   "metadata": {},
   "source": [
    "#### Train Initial Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8dda48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature_sets_balanced = [{'name': 'style', 'features': style_train_balanced['features']}, {'name': 'word2vec', 'features': word2vec_train_balanced['features']}]\n",
    "test_feature_sets_balanced = [{'name': 'style', 'features': style_test_balanced['features']}, {'name': 'word2vec', 'features': word2vec_test_balanced['features']}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9a5da859",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stacking_models_balanced = ml.train_models(train_feature_sets_balanced, style_train_balanced['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da494e3",
   "metadata": {},
   "source": [
    "### Single-algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2be1dce",
   "metadata": {},
   "source": [
    "First, the stacking will be done only on the same algorithms with different feature sets, while also testing for different final_classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f28e1c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stacking_balanced_single = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca8b5b4",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "da32f89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], exclude_models=['dt', 'rf', 'gb', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'rf', 'gb', 'nb'])\n",
    "results_stacking_balanced_single = pd.concat([results_stacking_balanced_single, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], exclude_models=['lr', 'rf', 'gb', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['lr', 'rf', 'gb', 'nb'])\n",
    "results_stacking_balanced_single = pd.concat([results_stacking_balanced_single, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], exclude_models=['lr', 'dt', 'gb', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['lr', 'dt', 'gb', 'nb'])\n",
    "results_stacking_balanced_single = pd.concat([results_stacking_balanced_single, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], exclude_models=['lr', 'dt', 'rf', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['lr', 'dt', 'rf', 'nb'])\n",
    "results_stacking_balanced_single = pd.concat([results_stacking_balanced_single, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], exclude_models=['lr', 'dt', 'rf', 'gb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['lr', 'dt', 'rf', 'gb'])\n",
    "results_stacking_balanced_single = pd.concat([results_stacking_balanced_single, stacked_preds['results']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa440123",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ff9069f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=rf, exclude_models=['dt', 'rf', 'gb', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'rf', 'gb', 'nb'])\n",
    "results_stacking_balanced_single = pd.concat([results_stacking_balanced_single, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=rf, exclude_models=['lr', 'rf', 'gb', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['lr', 'rf', 'gb', 'nb'])\n",
    "results_stacking_balanced_single = pd.concat([results_stacking_balanced_single, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=rf, exclude_models=['lr', 'dt', 'gb', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['lr', 'dt', 'gb', 'nb'])\n",
    "results_stacking_balanced_single = pd.concat([results_stacking_balanced_single, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=rf, exclude_models=['lr', 'dt', 'rf', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['lr', 'dt', 'rf', 'nb'])\n",
    "results_stacking_balanced_single = pd.concat([results_stacking_balanced_single, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=rf, exclude_models=['lr', 'dt', 'rf', 'gb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['lr', 'dt', 'rf', 'gb'])\n",
    "results_stacking_balanced_single = pd.concat([results_stacking_balanced_single, stacked_preds['results']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d265000",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e5fa23d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=gb, exclude_models=['dt', 'rf', 'gb', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'rf', 'gb', 'nb'])\n",
    "results_stacking_balanced_single = pd.concat([results_stacking_balanced_single, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=gb, exclude_models=['lr', 'rf', 'gb', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['lr', 'rf', 'gb', 'nb'])\n",
    "results_stacking_balanced_single = pd.concat([results_stacking_balanced_single, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=gb, exclude_models=['lr', 'dt', 'gb', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['lr', 'dt', 'gb', 'nb'])\n",
    "results_stacking_balanced_single = pd.concat([results_stacking_balanced_single, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=gb, exclude_models=['lr', 'dt', 'rf', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['lr', 'dt', 'rf', 'nb'])\n",
    "results_stacking_balanced_single = pd.concat([results_stacking_balanced_single, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=gb, exclude_models=['lr', 'dt', 'rf', 'gb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['lr', 'dt', 'rf', 'gb'])\n",
    "results_stacking_balanced_single = pd.concat([results_stacking_balanced_single, stacked_preds['results']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b5a4e25e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>Area Under ROC Curve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, with LogisticRegression</th>\n",
       "      <td>0.965875</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.977011</td>\n",
       "      <td>0.967283</td>\n",
       "      <td>0.046012</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>0.965500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: dt, with LogisticRegression</th>\n",
       "      <td>0.956973</td>\n",
       "      <td>0.954416</td>\n",
       "      <td>0.962644</td>\n",
       "      <td>0.958512</td>\n",
       "      <td>0.049080</td>\n",
       "      <td>0.037356</td>\n",
       "      <td>0.956782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, with LogisticRegression</th>\n",
       "      <td>0.970326</td>\n",
       "      <td>0.960674</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.971591</td>\n",
       "      <td>0.042945</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.969907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: gb, with LogisticRegression</th>\n",
       "      <td>0.974777</td>\n",
       "      <td>0.963585</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.975887</td>\n",
       "      <td>0.039877</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.974314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: nb, with LogisticRegression</th>\n",
       "      <td>0.940653</td>\n",
       "      <td>0.950292</td>\n",
       "      <td>0.933908</td>\n",
       "      <td>0.942029</td>\n",
       "      <td>0.052147</td>\n",
       "      <td>0.066092</td>\n",
       "      <td>0.940880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, with RandomForestClassifier</th>\n",
       "      <td>0.968843</td>\n",
       "      <td>0.960563</td>\n",
       "      <td>0.979885</td>\n",
       "      <td>0.970128</td>\n",
       "      <td>0.042945</td>\n",
       "      <td>0.020115</td>\n",
       "      <td>0.968470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: dt, with RandomForestClassifier</th>\n",
       "      <td>0.962908</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.977011</td>\n",
       "      <td>0.964539</td>\n",
       "      <td>0.052147</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>0.962432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, with RandomForestClassifier</th>\n",
       "      <td>0.968843</td>\n",
       "      <td>0.960563</td>\n",
       "      <td>0.979885</td>\n",
       "      <td>0.970128</td>\n",
       "      <td>0.042945</td>\n",
       "      <td>0.020115</td>\n",
       "      <td>0.968470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: gb, with RandomForestClassifier</th>\n",
       "      <td>0.976261</td>\n",
       "      <td>0.963687</td>\n",
       "      <td>0.991379</td>\n",
       "      <td>0.977337</td>\n",
       "      <td>0.039877</td>\n",
       "      <td>0.008621</td>\n",
       "      <td>0.975751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: nb, with RandomForestClassifier</th>\n",
       "      <td>0.940653</td>\n",
       "      <td>0.952941</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.941860</td>\n",
       "      <td>0.049080</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.940977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, with GradientBoostingClassifier</th>\n",
       "      <td>0.962908</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.977011</td>\n",
       "      <td>0.964539</td>\n",
       "      <td>0.052147</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>0.962432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: dt, with GradientBoostingClassifier</th>\n",
       "      <td>0.961424</td>\n",
       "      <td>0.954802</td>\n",
       "      <td>0.971264</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.049080</td>\n",
       "      <td>0.028736</td>\n",
       "      <td>0.961092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, with GradientBoostingClassifier</th>\n",
       "      <td>0.962908</td>\n",
       "      <td>0.957507</td>\n",
       "      <td>0.971264</td>\n",
       "      <td>0.964337</td>\n",
       "      <td>0.046012</td>\n",
       "      <td>0.028736</td>\n",
       "      <td>0.962626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: gb, with GradientBoostingClassifier</th>\n",
       "      <td>0.974777</td>\n",
       "      <td>0.966197</td>\n",
       "      <td>0.985632</td>\n",
       "      <td>0.975818</td>\n",
       "      <td>0.036810</td>\n",
       "      <td>0.014368</td>\n",
       "      <td>0.974411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: nb, with GradientBoostingClassifier</th>\n",
       "      <td>0.943620</td>\n",
       "      <td>0.945402</td>\n",
       "      <td>0.945402</td>\n",
       "      <td>0.945402</td>\n",
       "      <td>0.058282</td>\n",
       "      <td>0.054598</td>\n",
       "      <td>0.943560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Accuracy  Precision  \\\n",
       "Algorithms: lr, with LogisticRegression          0.965875   0.957746   \n",
       "Algorithms: dt, with LogisticRegression          0.956973   0.954416   \n",
       "Algorithms: rf, with LogisticRegression          0.970326   0.960674   \n",
       "Algorithms: gb, with LogisticRegression          0.974777   0.963585   \n",
       "Algorithms: nb, with LogisticRegression          0.940653   0.950292   \n",
       "Algorithms: lr, with RandomForestClassifier      0.968843   0.960563   \n",
       "Algorithms: dt, with RandomForestClassifier      0.962908   0.952381   \n",
       "Algorithms: rf, with RandomForestClassifier      0.968843   0.960563   \n",
       "Algorithms: gb, with RandomForestClassifier      0.976261   0.963687   \n",
       "Algorithms: nb, with RandomForestClassifier      0.940653   0.952941   \n",
       "Algorithms: lr, with GradientBoostingClassifier  0.962908   0.952381   \n",
       "Algorithms: dt, with GradientBoostingClassifier  0.961424   0.954802   \n",
       "Algorithms: rf, with GradientBoostingClassifier  0.962908   0.957507   \n",
       "Algorithms: gb, with GradientBoostingClassifier  0.974777   0.966197   \n",
       "Algorithms: nb, with GradientBoostingClassifier  0.943620   0.945402   \n",
       "\n",
       "                                                   Recall  F1 Score  \\\n",
       "Algorithms: lr, with LogisticRegression          0.977011  0.967283   \n",
       "Algorithms: dt, with LogisticRegression          0.962644  0.958512   \n",
       "Algorithms: rf, with LogisticRegression          0.982759  0.971591   \n",
       "Algorithms: gb, with LogisticRegression          0.988506  0.975887   \n",
       "Algorithms: nb, with LogisticRegression          0.933908  0.942029   \n",
       "Algorithms: lr, with RandomForestClassifier      0.979885  0.970128   \n",
       "Algorithms: dt, with RandomForestClassifier      0.977011  0.964539   \n",
       "Algorithms: rf, with RandomForestClassifier      0.979885  0.970128   \n",
       "Algorithms: gb, with RandomForestClassifier      0.991379  0.977337   \n",
       "Algorithms: nb, with RandomForestClassifier      0.931034  0.941860   \n",
       "Algorithms: lr, with GradientBoostingClassifier  0.977011  0.964539   \n",
       "Algorithms: dt, with GradientBoostingClassifier  0.971264  0.962963   \n",
       "Algorithms: rf, with GradientBoostingClassifier  0.971264  0.964337   \n",
       "Algorithms: gb, with GradientBoostingClassifier  0.985632  0.975818   \n",
       "Algorithms: nb, with GradientBoostingClassifier  0.945402  0.945402   \n",
       "\n",
       "                                                 False Positive Rate  \\\n",
       "Algorithms: lr, with LogisticRegression                     0.046012   \n",
       "Algorithms: dt, with LogisticRegression                     0.049080   \n",
       "Algorithms: rf, with LogisticRegression                     0.042945   \n",
       "Algorithms: gb, with LogisticRegression                     0.039877   \n",
       "Algorithms: nb, with LogisticRegression                     0.052147   \n",
       "Algorithms: lr, with RandomForestClassifier                 0.042945   \n",
       "Algorithms: dt, with RandomForestClassifier                 0.052147   \n",
       "Algorithms: rf, with RandomForestClassifier                 0.042945   \n",
       "Algorithms: gb, with RandomForestClassifier                 0.039877   \n",
       "Algorithms: nb, with RandomForestClassifier                 0.049080   \n",
       "Algorithms: lr, with GradientBoostingClassifier             0.052147   \n",
       "Algorithms: dt, with GradientBoostingClassifier             0.049080   \n",
       "Algorithms: rf, with GradientBoostingClassifier             0.046012   \n",
       "Algorithms: gb, with GradientBoostingClassifier             0.036810   \n",
       "Algorithms: nb, with GradientBoostingClassifier             0.058282   \n",
       "\n",
       "                                                 False Negative Rate  \\\n",
       "Algorithms: lr, with LogisticRegression                     0.022989   \n",
       "Algorithms: dt, with LogisticRegression                     0.037356   \n",
       "Algorithms: rf, with LogisticRegression                     0.017241   \n",
       "Algorithms: gb, with LogisticRegression                     0.011494   \n",
       "Algorithms: nb, with LogisticRegression                     0.066092   \n",
       "Algorithms: lr, with RandomForestClassifier                 0.020115   \n",
       "Algorithms: dt, with RandomForestClassifier                 0.022989   \n",
       "Algorithms: rf, with RandomForestClassifier                 0.020115   \n",
       "Algorithms: gb, with RandomForestClassifier                 0.008621   \n",
       "Algorithms: nb, with RandomForestClassifier                 0.068966   \n",
       "Algorithms: lr, with GradientBoostingClassifier             0.022989   \n",
       "Algorithms: dt, with GradientBoostingClassifier             0.028736   \n",
       "Algorithms: rf, with GradientBoostingClassifier             0.028736   \n",
       "Algorithms: gb, with GradientBoostingClassifier             0.014368   \n",
       "Algorithms: nb, with GradientBoostingClassifier             0.054598   \n",
       "\n",
       "                                                 Area Under ROC Curve  \n",
       "Algorithms: lr, with LogisticRegression                      0.965500  \n",
       "Algorithms: dt, with LogisticRegression                      0.956782  \n",
       "Algorithms: rf, with LogisticRegression                      0.969907  \n",
       "Algorithms: gb, with LogisticRegression                      0.974314  \n",
       "Algorithms: nb, with LogisticRegression                      0.940880  \n",
       "Algorithms: lr, with RandomForestClassifier                  0.968470  \n",
       "Algorithms: dt, with RandomForestClassifier                  0.962432  \n",
       "Algorithms: rf, with RandomForestClassifier                  0.968470  \n",
       "Algorithms: gb, with RandomForestClassifier                  0.975751  \n",
       "Algorithms: nb, with RandomForestClassifier                  0.940977  \n",
       "Algorithms: lr, with GradientBoostingClassifier              0.962432  \n",
       "Algorithms: dt, with GradientBoostingClassifier              0.961092  \n",
       "Algorithms: rf, with GradientBoostingClassifier              0.962626  \n",
       "Algorithms: gb, with GradientBoostingClassifier              0.974411  \n",
       "Algorithms: nb, with GradientBoostingClassifier              0.943560  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_stacking_balanced_single"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1f7ca0",
   "metadata": {},
   "source": [
    "It is apparent that the results are better than the baseline models, and at some cases (when Random Forest of Gradient Boosting is used in one of the steps) even better than predicting with the merged feature sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645cc568",
   "metadata": {},
   "source": [
    "The 6 best performing models will be kept to compare with other stacking configurations and the complete single-algorithm results dataset will be archived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0452feca",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stacking_balanced_full = results_stacking_balanced_single.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1b978634",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stacking_balanced_best = results_stacking_balanced_single.sort_values(by=['F1 Score'], ascending = [False]).head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c225b01",
   "metadata": {},
   "source": [
    "### Multi-algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e2dd8c",
   "metadata": {},
   "source": [
    "Of course, it is possible to also use the outputs of more than one classifier, on both feature sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7c646926",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stacking_balanced_multi = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6992754c",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8f058e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], exclude_models=[])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=[], result_row_name=\"Algorithms: all, with LogisticRegression\")\n",
    "results_stacking_balanced_multi = pd.concat([results_stacking_balanced_multi, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], exclude_models=['dt', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb'])\n",
    "results_stacking_balanced_multi = pd.concat([results_stacking_balanced_multi, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], exclude_models=['dt', 'nb', 'lr'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'lr'])\n",
    "results_stacking_balanced_multi = pd.concat([results_stacking_balanced_multi, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], exclude_models=['dt', 'nb', 'rf'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'rf'])\n",
    "results_stacking_balanced_multi = pd.concat([results_stacking_balanced_multi, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], exclude_models=['dt', 'nb', 'gb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb'])\n",
    "results_stacking_balanced_multi = pd.concat([results_stacking_balanced_multi, stacked_preds['results']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15252f18",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4d1ac0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=rf, exclude_models=[])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=[], result_row_name=\"Algorithms: all, with RandomForestClassifier\")\n",
    "results_stacking_balanced_multi = pd.concat([results_stacking_balanced_multi, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=rf, exclude_models=['dt', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb'])\n",
    "results_stacking_balanced_multi = pd.concat([results_stacking_balanced_multi, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=rf, exclude_models=['dt', 'nb', 'lr'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'lr'])\n",
    "results_stacking_balanced_multi = pd.concat([results_stacking_balanced_multi, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=rf, exclude_models=['dt', 'nb', 'rf'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'rf'])\n",
    "results_stacking_balanced_multi = pd.concat([results_stacking_balanced_multi, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=rf, exclude_models=['dt', 'nb', 'gb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb'])\n",
    "results_stacking_balanced_multi = pd.concat([results_stacking_balanced_multi, stacked_preds['results']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583405a9",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c6e30e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=gb, exclude_models=[])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=[], result_row_name=\"Algorithms: all, with GradientBoostingClassifier\")\n",
    "results_stacking_balanced_multi = pd.concat([results_stacking_balanced_multi, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=gb, exclude_models=['dt', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb'])\n",
    "results_stacking_balanced_multi = pd.concat([results_stacking_balanced_multi, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=gb, exclude_models=['dt', 'nb', 'lr'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'lr'])\n",
    "results_stacking_balanced_multi = pd.concat([results_stacking_balanced_multi, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=gb, exclude_models=['dt', 'nb', 'rf'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'rf'])\n",
    "results_stacking_balanced_multi = pd.concat([results_stacking_balanced_multi, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=gb, exclude_models=['dt', 'nb', 'gb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb'])\n",
    "results_stacking_balanced_multi = pd.concat([results_stacking_balanced_multi, stacked_preds['results']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "49b34a9c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>Area Under ROC Curve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Algorithms: all, with LogisticRegression</th>\n",
       "      <td>0.976261</td>\n",
       "      <td>0.966292</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.036810</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.975848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: gb, lr, rf, with LogisticRegression</th>\n",
       "      <td>0.976261</td>\n",
       "      <td>0.966292</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.036810</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.975848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: gb, rf, with LogisticRegression</th>\n",
       "      <td>0.974777</td>\n",
       "      <td>0.963585</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.975887</td>\n",
       "      <td>0.039877</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.974314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: gb, lr, with LogisticRegression</th>\n",
       "      <td>0.976261</td>\n",
       "      <td>0.968927</td>\n",
       "      <td>0.985632</td>\n",
       "      <td>0.977208</td>\n",
       "      <td>0.033742</td>\n",
       "      <td>0.014368</td>\n",
       "      <td>0.975945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, rf, with LogisticRegression</th>\n",
       "      <td>0.974777</td>\n",
       "      <td>0.963585</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.975887</td>\n",
       "      <td>0.039877</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.974314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: all, with RandomForestClassifier</th>\n",
       "      <td>0.974777</td>\n",
       "      <td>0.963585</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.975887</td>\n",
       "      <td>0.039877</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.974314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: gb, lr, rf, with RandomForestClassifier</th>\n",
       "      <td>0.977745</td>\n",
       "      <td>0.966387</td>\n",
       "      <td>0.991379</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>0.036810</td>\n",
       "      <td>0.008621</td>\n",
       "      <td>0.977285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: gb, rf, with RandomForestClassifier</th>\n",
       "      <td>0.974777</td>\n",
       "      <td>0.963585</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.975887</td>\n",
       "      <td>0.039877</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.974314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: gb, lr, with RandomForestClassifier</th>\n",
       "      <td>0.976261</td>\n",
       "      <td>0.963687</td>\n",
       "      <td>0.991379</td>\n",
       "      <td>0.977337</td>\n",
       "      <td>0.039877</td>\n",
       "      <td>0.008621</td>\n",
       "      <td>0.975751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, rf, with RandomForestClassifier</th>\n",
       "      <td>0.973294</td>\n",
       "      <td>0.966102</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.036810</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.972974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: all, with GradientBoostingClassifier</th>\n",
       "      <td>0.977745</td>\n",
       "      <td>0.966387</td>\n",
       "      <td>0.991379</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>0.036810</td>\n",
       "      <td>0.008621</td>\n",
       "      <td>0.977285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: gb, lr, rf, with GradientBoostingClassifier</th>\n",
       "      <td>0.977745</td>\n",
       "      <td>0.966387</td>\n",
       "      <td>0.991379</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>0.036810</td>\n",
       "      <td>0.008621</td>\n",
       "      <td>0.977285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: gb, rf, with GradientBoostingClassifier</th>\n",
       "      <td>0.971810</td>\n",
       "      <td>0.963380</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.039877</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.971441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: gb, lr, with GradientBoostingClassifier</th>\n",
       "      <td>0.979228</td>\n",
       "      <td>0.969101</td>\n",
       "      <td>0.991379</td>\n",
       "      <td>0.980114</td>\n",
       "      <td>0.033742</td>\n",
       "      <td>0.008621</td>\n",
       "      <td>0.978818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, rf, with GradientBoostingClassifier</th>\n",
       "      <td>0.974777</td>\n",
       "      <td>0.963585</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.975887</td>\n",
       "      <td>0.039877</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.974314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Accuracy  Precision  \\\n",
       "Algorithms: all, with LogisticRegression            0.976261   0.966292   \n",
       "Algorithms: gb, lr, rf, with LogisticRegression     0.976261   0.966292   \n",
       "Algorithms: gb, rf, with LogisticRegression         0.974777   0.963585   \n",
       "Algorithms: gb, lr, with LogisticRegression         0.976261   0.968927   \n",
       "Algorithms: lr, rf, with LogisticRegression         0.974777   0.963585   \n",
       "Algorithms: all, with RandomForestClassifier        0.974777   0.963585   \n",
       "Algorithms: gb, lr, rf, with RandomForestClassi...  0.977745   0.966387   \n",
       "Algorithms: gb, rf, with RandomForestClassifier     0.974777   0.963585   \n",
       "Algorithms: gb, lr, with RandomForestClassifier     0.976261   0.963687   \n",
       "Algorithms: lr, rf, with RandomForestClassifier     0.973294   0.966102   \n",
       "Algorithms: all, with GradientBoostingClassifier    0.977745   0.966387   \n",
       "Algorithms: gb, lr, rf, with GradientBoostingCl...  0.977745   0.966387   \n",
       "Algorithms: gb, rf, with GradientBoostingClassi...  0.971810   0.963380   \n",
       "Algorithms: gb, lr, with GradientBoostingClassi...  0.979228   0.969101   \n",
       "Algorithms: lr, rf, with GradientBoostingClassi...  0.974777   0.963585   \n",
       "\n",
       "                                                      Recall  F1 Score  \\\n",
       "Algorithms: all, with LogisticRegression            0.988506  0.977273   \n",
       "Algorithms: gb, lr, rf, with LogisticRegression     0.988506  0.977273   \n",
       "Algorithms: gb, rf, with LogisticRegression         0.988506  0.975887   \n",
       "Algorithms: gb, lr, with LogisticRegression         0.985632  0.977208   \n",
       "Algorithms: lr, rf, with LogisticRegression         0.988506  0.975887   \n",
       "Algorithms: all, with RandomForestClassifier        0.988506  0.975887   \n",
       "Algorithms: gb, lr, rf, with RandomForestClassi...  0.991379  0.978723   \n",
       "Algorithms: gb, rf, with RandomForestClassifier     0.988506  0.975887   \n",
       "Algorithms: gb, lr, with RandomForestClassifier     0.991379  0.977337   \n",
       "Algorithms: lr, rf, with RandomForestClassifier     0.982759  0.974359   \n",
       "Algorithms: all, with GradientBoostingClassifier    0.991379  0.978723   \n",
       "Algorithms: gb, lr, rf, with GradientBoostingCl...  0.991379  0.978723   \n",
       "Algorithms: gb, rf, with GradientBoostingClassi...  0.982759  0.972973   \n",
       "Algorithms: gb, lr, with GradientBoostingClassi...  0.991379  0.980114   \n",
       "Algorithms: lr, rf, with GradientBoostingClassi...  0.988506  0.975887   \n",
       "\n",
       "                                                    False Positive Rate  \\\n",
       "Algorithms: all, with LogisticRegression                       0.036810   \n",
       "Algorithms: gb, lr, rf, with LogisticRegression                0.036810   \n",
       "Algorithms: gb, rf, with LogisticRegression                    0.039877   \n",
       "Algorithms: gb, lr, with LogisticRegression                    0.033742   \n",
       "Algorithms: lr, rf, with LogisticRegression                    0.039877   \n",
       "Algorithms: all, with RandomForestClassifier                   0.039877   \n",
       "Algorithms: gb, lr, rf, with RandomForestClassi...             0.036810   \n",
       "Algorithms: gb, rf, with RandomForestClassifier                0.039877   \n",
       "Algorithms: gb, lr, with RandomForestClassifier                0.039877   \n",
       "Algorithms: lr, rf, with RandomForestClassifier                0.036810   \n",
       "Algorithms: all, with GradientBoostingClassifier               0.036810   \n",
       "Algorithms: gb, lr, rf, with GradientBoostingCl...             0.036810   \n",
       "Algorithms: gb, rf, with GradientBoostingClassi...             0.039877   \n",
       "Algorithms: gb, lr, with GradientBoostingClassi...             0.033742   \n",
       "Algorithms: lr, rf, with GradientBoostingClassi...             0.039877   \n",
       "\n",
       "                                                    False Negative Rate  \\\n",
       "Algorithms: all, with LogisticRegression                       0.011494   \n",
       "Algorithms: gb, lr, rf, with LogisticRegression                0.011494   \n",
       "Algorithms: gb, rf, with LogisticRegression                    0.011494   \n",
       "Algorithms: gb, lr, with LogisticRegression                    0.014368   \n",
       "Algorithms: lr, rf, with LogisticRegression                    0.011494   \n",
       "Algorithms: all, with RandomForestClassifier                   0.011494   \n",
       "Algorithms: gb, lr, rf, with RandomForestClassi...             0.008621   \n",
       "Algorithms: gb, rf, with RandomForestClassifier                0.011494   \n",
       "Algorithms: gb, lr, with RandomForestClassifier                0.008621   \n",
       "Algorithms: lr, rf, with RandomForestClassifier                0.017241   \n",
       "Algorithms: all, with GradientBoostingClassifier               0.008621   \n",
       "Algorithms: gb, lr, rf, with GradientBoostingCl...             0.008621   \n",
       "Algorithms: gb, rf, with GradientBoostingClassi...             0.017241   \n",
       "Algorithms: gb, lr, with GradientBoostingClassi...             0.008621   \n",
       "Algorithms: lr, rf, with GradientBoostingClassi...             0.011494   \n",
       "\n",
       "                                                    Area Under ROC Curve  \n",
       "Algorithms: all, with LogisticRegression                        0.975848  \n",
       "Algorithms: gb, lr, rf, with LogisticRegression                 0.975848  \n",
       "Algorithms: gb, rf, with LogisticRegression                     0.974314  \n",
       "Algorithms: gb, lr, with LogisticRegression                     0.975945  \n",
       "Algorithms: lr, rf, with LogisticRegression                     0.974314  \n",
       "Algorithms: all, with RandomForestClassifier                    0.974314  \n",
       "Algorithms: gb, lr, rf, with RandomForestClassi...              0.977285  \n",
       "Algorithms: gb, rf, with RandomForestClassifier                 0.974314  \n",
       "Algorithms: gb, lr, with RandomForestClassifier                 0.975751  \n",
       "Algorithms: lr, rf, with RandomForestClassifier                 0.972974  \n",
       "Algorithms: all, with GradientBoostingClassifier                0.977285  \n",
       "Algorithms: gb, lr, rf, with GradientBoostingCl...              0.977285  \n",
       "Algorithms: gb, rf, with GradientBoostingClassi...              0.971441  \n",
       "Algorithms: gb, lr, with GradientBoostingClassi...              0.978818  \n",
       "Algorithms: lr, rf, with GradientBoostingClassi...              0.974314  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_stacking_balanced_multi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7323132e",
   "metadata": {},
   "source": [
    "As expected, using more than one classifier consistently improves the classification accuracy. The best level 1 classifier seems to be Gradient Boosting, and Logistic Regression gives better results when used as a level 0 classifier. However, all combinations performed quite well.\n",
    "\n",
    "On the other hand, Naive Bayes and Decision Tree classifiers do not affect the result at all or even reduce the accuracy when used with the Random Forest Classifier, so from now on they will be excluded in order to reduce the execution time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7015943",
   "metadata": {},
   "source": [
    "The top 8 models will be added to the best models dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5e84d349",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stacking_balanced_best = pd.concat([results_stacking_balanced_best, results_stacking_balanced_multi.sort_values(by=['F1 Score'], ascending = [False]).head(8)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8e49ade4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stacking_balanced_full = pd.concat([results_stacking_balanced_full, results_stacking_balanced_multi])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75685ca",
   "metadata": {},
   "source": [
    "### Appending all features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0532041",
   "metadata": {},
   "source": [
    "Another variation of stacking includes appending the predictions to the other feature sets and then train the final classifier with all the features.<br>\n",
    "Since using both feature sets has been proven to improve accuracy on the baselines, the predictions will be appended to the merged feature set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e5a71b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stacking_balanced_append = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385d09bf",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7e49c357",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], exclude_models=['dt', 'nb', 'lr'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'lr'], append_features=True)\n",
    "results_stacking_balanced_append = pd.concat([results_stacking_balanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], exclude_models=['dt', 'nb', 'rf'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'rf'], append_features=True)\n",
    "results_stacking_balanced_append = pd.concat([results_stacking_balanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], exclude_models=['dt', 'nb', 'gb'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb'], append_features=True)\n",
    "results_stacking_balanced_append = pd.concat([results_stacking_balanced_append, stacked_preds['results']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133808d6",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0b41df61",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=rf, exclude_models=['dt', 'nb', 'lr'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'lr'], append_features=True)\n",
    "results_stacking_balanced_append = pd.concat([results_stacking_balanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=rf, exclude_models=['dt', 'nb', 'rf'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'rf'], append_features=True)\n",
    "results_stacking_balanced_append = pd.concat([results_stacking_balanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=rf, exclude_models=['dt', 'nb', 'gb'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb'], append_features=True)\n",
    "results_stacking_balanced_append = pd.concat([results_stacking_balanced_append, stacked_preds['results']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a197324",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "129ffbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=gb, exclude_models=['dt', 'nb', 'lr'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'lr'], append_features=True)\n",
    "results_stacking_balanced_append = pd.concat([results_stacking_balanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=gb, exclude_models=['dt', 'nb', 'rf'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'rf'], append_features=True)\n",
    "results_stacking_balanced_append = pd.concat([results_stacking_balanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=gb, exclude_models=['dt', 'nb', 'gb'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb'], append_features=True)\n",
    "results_stacking_balanced_append = pd.concat([results_stacking_balanced_append, stacked_preds['results']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1af982df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>Area Under ROC Curve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Algorithms: gb, rf, with LogisticRegression (with appended features)</th>\n",
       "      <td>0.956973</td>\n",
       "      <td>0.951841</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.958631</td>\n",
       "      <td>0.052147</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.956685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: gb, lr, with LogisticRegression (with appended features)</th>\n",
       "      <td>0.951039</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.956897</td>\n",
       "      <td>0.952790</td>\n",
       "      <td>0.055215</td>\n",
       "      <td>0.043103</td>\n",
       "      <td>0.950841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, rf, with LogisticRegression (with appended features)</th>\n",
       "      <td>0.958457</td>\n",
       "      <td>0.946927</td>\n",
       "      <td>0.974138</td>\n",
       "      <td>0.960340</td>\n",
       "      <td>0.058282</td>\n",
       "      <td>0.025862</td>\n",
       "      <td>0.957928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: gb, rf, with RandomForestClassifier (with appended features)</th>\n",
       "      <td>0.968843</td>\n",
       "      <td>0.963173</td>\n",
       "      <td>0.977011</td>\n",
       "      <td>0.970043</td>\n",
       "      <td>0.039877</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>0.968567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: gb, lr, with RandomForestClassifier (with appended features)</th>\n",
       "      <td>0.968843</td>\n",
       "      <td>0.963173</td>\n",
       "      <td>0.977011</td>\n",
       "      <td>0.970043</td>\n",
       "      <td>0.039877</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>0.968567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, rf, with RandomForestClassifier (with appended features)</th>\n",
       "      <td>0.973294</td>\n",
       "      <td>0.966102</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.036810</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.972974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: gb, rf, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.974777</td>\n",
       "      <td>0.961003</td>\n",
       "      <td>0.991379</td>\n",
       "      <td>0.975955</td>\n",
       "      <td>0.042945</td>\n",
       "      <td>0.008621</td>\n",
       "      <td>0.974217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: gb, lr, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.980712</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>0.991379</td>\n",
       "      <td>0.981508</td>\n",
       "      <td>0.030675</td>\n",
       "      <td>0.008621</td>\n",
       "      <td>0.980352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, rf, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.979228</td>\n",
       "      <td>0.971751</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.980057</td>\n",
       "      <td>0.030675</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.978915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Accuracy  Precision  \\\n",
       "Algorithms: gb, rf, with LogisticRegression (wi...  0.956973   0.951841   \n",
       "Algorithms: gb, lr, with LogisticRegression (wi...  0.951039   0.948718   \n",
       "Algorithms: lr, rf, with LogisticRegression (wi...  0.958457   0.946927   \n",
       "Algorithms: gb, rf, with RandomForestClassifier...  0.968843   0.963173   \n",
       "Algorithms: gb, lr, with RandomForestClassifier...  0.968843   0.963173   \n",
       "Algorithms: lr, rf, with RandomForestClassifier...  0.973294   0.966102   \n",
       "Algorithms: gb, rf, with GradientBoostingClassi...  0.974777   0.961003   \n",
       "Algorithms: gb, lr, with GradientBoostingClassi...  0.980712   0.971831   \n",
       "Algorithms: lr, rf, with GradientBoostingClassi...  0.979228   0.971751   \n",
       "\n",
       "                                                      Recall  F1 Score  \\\n",
       "Algorithms: gb, rf, with LogisticRegression (wi...  0.965517  0.958631   \n",
       "Algorithms: gb, lr, with LogisticRegression (wi...  0.956897  0.952790   \n",
       "Algorithms: lr, rf, with LogisticRegression (wi...  0.974138  0.960340   \n",
       "Algorithms: gb, rf, with RandomForestClassifier...  0.977011  0.970043   \n",
       "Algorithms: gb, lr, with RandomForestClassifier...  0.977011  0.970043   \n",
       "Algorithms: lr, rf, with RandomForestClassifier...  0.982759  0.974359   \n",
       "Algorithms: gb, rf, with GradientBoostingClassi...  0.991379  0.975955   \n",
       "Algorithms: gb, lr, with GradientBoostingClassi...  0.991379  0.981508   \n",
       "Algorithms: lr, rf, with GradientBoostingClassi...  0.988506  0.980057   \n",
       "\n",
       "                                                    False Positive Rate  \\\n",
       "Algorithms: gb, rf, with LogisticRegression (wi...             0.052147   \n",
       "Algorithms: gb, lr, with LogisticRegression (wi...             0.055215   \n",
       "Algorithms: lr, rf, with LogisticRegression (wi...             0.058282   \n",
       "Algorithms: gb, rf, with RandomForestClassifier...             0.039877   \n",
       "Algorithms: gb, lr, with RandomForestClassifier...             0.039877   \n",
       "Algorithms: lr, rf, with RandomForestClassifier...             0.036810   \n",
       "Algorithms: gb, rf, with GradientBoostingClassi...             0.042945   \n",
       "Algorithms: gb, lr, with GradientBoostingClassi...             0.030675   \n",
       "Algorithms: lr, rf, with GradientBoostingClassi...             0.030675   \n",
       "\n",
       "                                                    False Negative Rate  \\\n",
       "Algorithms: gb, rf, with LogisticRegression (wi...             0.034483   \n",
       "Algorithms: gb, lr, with LogisticRegression (wi...             0.043103   \n",
       "Algorithms: lr, rf, with LogisticRegression (wi...             0.025862   \n",
       "Algorithms: gb, rf, with RandomForestClassifier...             0.022989   \n",
       "Algorithms: gb, lr, with RandomForestClassifier...             0.022989   \n",
       "Algorithms: lr, rf, with RandomForestClassifier...             0.017241   \n",
       "Algorithms: gb, rf, with GradientBoostingClassi...             0.008621   \n",
       "Algorithms: gb, lr, with GradientBoostingClassi...             0.008621   \n",
       "Algorithms: lr, rf, with GradientBoostingClassi...             0.011494   \n",
       "\n",
       "                                                    Area Under ROC Curve  \n",
       "Algorithms: gb, rf, with LogisticRegression (wi...              0.956685  \n",
       "Algorithms: gb, lr, with LogisticRegression (wi...              0.950841  \n",
       "Algorithms: lr, rf, with LogisticRegression (wi...              0.957928  \n",
       "Algorithms: gb, rf, with RandomForestClassifier...              0.968567  \n",
       "Algorithms: gb, lr, with RandomForestClassifier...              0.968567  \n",
       "Algorithms: lr, rf, with RandomForestClassifier...              0.972974  \n",
       "Algorithms: gb, rf, with GradientBoostingClassi...              0.974217  \n",
       "Algorithms: gb, lr, with GradientBoostingClassi...              0.980352  \n",
       "Algorithms: lr, rf, with GradientBoostingClassi...              0.978915  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_stacking_balanced_append"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346de830",
   "metadata": {},
   "source": [
    "Adding the initial feature sets to the final classifier seems to mostly harm performance on the balanced dataset. This is most likely due to overfitting, since the level 1 classifier becomes extremely specialized at recognizing the emails provided in the training set and fails to generalize for the test set.\n",
    "\n",
    "However, when using Gradient Boosting as the final classifier, it manages to outperform the model without the appended features. This is no surprise, since Boosting methods in general are somewhat more resistant to overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85a7a21",
   "metadata": {},
   "source": [
    "The top 6 of these models will be added to the best result dataset, simply for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a9f9898c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stacking_balanced_best = pd.concat([results_stacking_balanced_best, results_stacking_balanced_append.sort_values(by=['F1 Score'], ascending = [False]).head(6)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f9848a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stacking_balanced_full = pd.concat([results_stacking_balanced_full, results_stacking_balanced_append])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ef667e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>Area Under ROC Curve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Algorithms: gb, lr, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.980712</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>0.991379</td>\n",
       "      <td>0.981508</td>\n",
       "      <td>0.030675</td>\n",
       "      <td>0.008621</td>\n",
       "      <td>0.980352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: gb, lr, with GradientBoostingClassifier</th>\n",
       "      <td>0.979228</td>\n",
       "      <td>0.969101</td>\n",
       "      <td>0.991379</td>\n",
       "      <td>0.980114</td>\n",
       "      <td>0.033742</td>\n",
       "      <td>0.008621</td>\n",
       "      <td>0.978818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, rf, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.979228</td>\n",
       "      <td>0.971751</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.980057</td>\n",
       "      <td>0.030675</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.978915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: gb, lr, rf, with RandomForestClassifier</th>\n",
       "      <td>0.977745</td>\n",
       "      <td>0.966387</td>\n",
       "      <td>0.991379</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>0.036810</td>\n",
       "      <td>0.008621</td>\n",
       "      <td>0.977285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: gb, lr, rf, with GradientBoostingClassifier</th>\n",
       "      <td>0.977745</td>\n",
       "      <td>0.966387</td>\n",
       "      <td>0.991379</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>0.036810</td>\n",
       "      <td>0.008621</td>\n",
       "      <td>0.977285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Accuracy  Precision  \\\n",
       "Algorithms: gb, lr, with GradientBoostingClassi...  0.980712   0.971831   \n",
       "Algorithms: gb, lr, with GradientBoostingClassi...  0.979228   0.969101   \n",
       "Algorithms: lr, rf, with GradientBoostingClassi...  0.979228   0.971751   \n",
       "Algorithms: gb, lr, rf, with RandomForestClassi...  0.977745   0.966387   \n",
       "Algorithms: gb, lr, rf, with GradientBoostingCl...  0.977745   0.966387   \n",
       "\n",
       "                                                      Recall  F1 Score  \\\n",
       "Algorithms: gb, lr, with GradientBoostingClassi...  0.991379  0.981508   \n",
       "Algorithms: gb, lr, with GradientBoostingClassi...  0.991379  0.980114   \n",
       "Algorithms: lr, rf, with GradientBoostingClassi...  0.988506  0.980057   \n",
       "Algorithms: gb, lr, rf, with RandomForestClassi...  0.991379  0.978723   \n",
       "Algorithms: gb, lr, rf, with GradientBoostingCl...  0.991379  0.978723   \n",
       "\n",
       "                                                    False Positive Rate  \\\n",
       "Algorithms: gb, lr, with GradientBoostingClassi...             0.030675   \n",
       "Algorithms: gb, lr, with GradientBoostingClassi...             0.033742   \n",
       "Algorithms: lr, rf, with GradientBoostingClassi...             0.030675   \n",
       "Algorithms: gb, lr, rf, with RandomForestClassi...             0.036810   \n",
       "Algorithms: gb, lr, rf, with GradientBoostingCl...             0.036810   \n",
       "\n",
       "                                                    False Negative Rate  \\\n",
       "Algorithms: gb, lr, with GradientBoostingClassi...             0.008621   \n",
       "Algorithms: gb, lr, with GradientBoostingClassi...             0.008621   \n",
       "Algorithms: lr, rf, with GradientBoostingClassi...             0.011494   \n",
       "Algorithms: gb, lr, rf, with RandomForestClassi...             0.008621   \n",
       "Algorithms: gb, lr, rf, with GradientBoostingCl...             0.008621   \n",
       "\n",
       "                                                    Area Under ROC Curve  \n",
       "Algorithms: gb, lr, with GradientBoostingClassi...              0.980352  \n",
       "Algorithms: gb, lr, with GradientBoostingClassi...              0.978818  \n",
       "Algorithms: lr, rf, with GradientBoostingClassi...              0.978915  \n",
       "Algorithms: gb, lr, rf, with RandomForestClassi...              0.977285  \n",
       "Algorithms: gb, lr, rf, with GradientBoostingCl...              0.977285  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_stacking_balanced_best.sort_values(by=['F1 Score'], ascending = [False]).head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

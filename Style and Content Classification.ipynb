{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e41204e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = 250\n",
    "\n",
    "import machine_learning as ml\n",
    "from preprocessing import separate_features_target\n",
    "\n",
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "702a8888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path\n",
    "cwd = os.getcwd()\n",
    "csv_path = os.path.join(cwd, 'data/csv/')\n",
    "\n",
    "train = {\n",
    "    'stylometric' : ['style_train_balanced.csv','style_train_imbalanced.csv'],\n",
    "    'word2vec' : ['word2vec_train_balanced.csv','word2vec_train_imbalanced.csv']\n",
    "}\n",
    "test = {\n",
    "    'stylometric' : ['style_test_balanced.csv','style_test_imbalanced.csv'],\n",
    "    'word2vec' : ['word2vec_test_balanced.csv','word2vec_test_imbalanced.csv']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424810a5",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02737f46",
   "metadata": {},
   "source": [
    "Since Word2Vec features outperformed the TF-IDF features, only those will be used to test the combination with content features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ebf18e",
   "metadata": {},
   "source": [
    "### Balanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19750b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "style_train_balanced_complete = pd.read_csv(os.path.join(csv_path, train['stylometric'][0]), index_col=0, dtype={'email_class': 'bool', 'email_id': 'int16'})\n",
    "style_test_balanced_complete = pd.read_csv(os.path.join(csv_path, test['stylometric'][0]), index_col=0, dtype={'email_class': 'bool', 'email_id': 'int16'})\n",
    "\n",
    "word2vec_train_balanced_complete = pd.read_csv(os.path.join(csv_path, train['word2vec'][0]), index_col=0, dtype={'email_class': 'bool', 'email_id': 'int16'})\n",
    "word2vec_test_balanced_complete = pd.read_csv(os.path.join(csv_path, test['word2vec'][0]), index_col=0, dtype={'email_class': 'bool', 'email_id': 'int16'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "117c14ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "style_train_balanced = separate_features_target(style_train_balanced_complete)\n",
    "style_test_balanced = separate_features_target(style_test_balanced_complete)\n",
    "\n",
    "word2vec_train_balanced = separate_features_target(word2vec_train_balanced_complete)\n",
    "word2vec_test_balanced = separate_features_target(word2vec_test_balanced_complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28b1832",
   "metadata": {},
   "source": [
    "### Imbalanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f07057f",
   "metadata": {},
   "outputs": [],
   "source": [
    "style_train_imbalanced_complete = pd.read_csv(os.path.join(csv_path, train['stylometric'][1]), index_col=0, dtype={'email_class': 'bool', 'email_id': 'int16'})\n",
    "style_test_imbalanced_complete = pd.read_csv(os.path.join(csv_path, test['stylometric'][1]), index_col=0, dtype={'email_class': 'bool', 'email_id': 'int16'})\n",
    "\n",
    "word2vec_train_imbalanced_complete = pd.read_csv(os.path.join(csv_path, train['word2vec'][1]), index_col=0, dtype={'email_class': 'bool', 'email_id': 'int16'})\n",
    "word2vec_test_imbalanced_complete = pd.read_csv(os.path.join(csv_path, test['word2vec'][1]), index_col=0, dtype={'email_class': 'bool', 'email_id': 'int16'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f680514",
   "metadata": {},
   "outputs": [],
   "source": [
    "style_train_imbalanced = separate_features_target(style_train_imbalanced_complete)\n",
    "style_test_imbalanced = separate_features_target(style_test_imbalanced_complete)\n",
    "\n",
    "word2vec_train_imbalanced = separate_features_target(word2vec_train_imbalanced_complete)\n",
    "word2vec_test_imbalanced = separate_features_target(word2vec_test_imbalanced_complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfda150",
   "metadata": {},
   "source": [
    "# Merging Feature Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464fccfe",
   "metadata": {},
   "source": [
    "The simplest way of combining the information of the two different feature sets is to simply merge them into one set and then perform the predictions based on this concatenated set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6cdc4a",
   "metadata": {},
   "source": [
    "## Balanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68f32c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "style_content_train_balanced = pd.concat([word2vec_train_balanced['features'], style_train_balanced['features']], axis=1)\n",
    "style_content_test_balanced = pd.concat([word2vec_test_balanced['features'], style_test_balanced['features']], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df122e5",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2957d9ed",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "828667e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9944320712694877\n"
     ]
    }
   ],
   "source": [
    "lr_style_content_balanced = ml.train_logistic_regression(style_content_train_balanced, style_train_balanced['target'], show_train_accuracy=1)\n",
    "lr_style_content_balanced, lr_style_content_balanced_scaler = lr_style_content_balanced['model'], lr_style_content_balanced['scaler']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6b7cd3",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76d32c44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9862657757980697\n"
     ]
    }
   ],
   "source": [
    "dt_style_content_balanced = ml.train_decision_tree(style_content_train_balanced, style_train_balanced['target'], show_train_accuracy=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16daa374",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58232f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9844097995545658\n"
     ]
    }
   ],
   "source": [
    "rf_style_content_balanced = ml.train_random_forest(style_content_train_balanced, style_train_balanced['target'], show_train_accuracy=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322a604a",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edcc3d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9974016332590943\n"
     ]
    }
   ],
   "source": [
    "gb_style_content_balanced = ml.train_gradient_boost(style_content_train_balanced, style_train_balanced['target'], show_train_accuracy=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5118b57c",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6a120f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9510022271714922\n"
     ]
    }
   ],
   "source": [
    "nb_style_content_balanced = ml.train_naive_bayes(style_content_train_balanced, style_train_balanced['target'], show_train_accuracy=1, remove_negatives=True)\n",
    "nb_style_content_balanced, nb_style_content_balanced_scaler = nb_style_content_balanced['model'], nb_style_content_balanced['scaler']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafc39b7",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b043c4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [lr_style_content_balanced, dt_style_content_balanced, rf_style_content_balanced, gb_style_content_balanced, nb_style_content_balanced]\n",
    "names = ['Logistic Regression', 'Decision Tree', 'Random Forest', 'Gradient Boosting Tree', 'Naive Bayes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "893cc6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_style_content_balanced = ml.multi_model_results(models, names, style_content_test_balanced, style_test_balanced['target'], lr_style_content_balanced_scaler, nb_style_content_balanced_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bec06c19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>Area Under ROC Curve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.965875</td>\n",
       "      <td>0.955182</td>\n",
       "      <td>0.979885</td>\n",
       "      <td>0.967376</td>\n",
       "      <td>0.049080</td>\n",
       "      <td>0.020115</td>\n",
       "      <td>0.991600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.951039</td>\n",
       "      <td>0.951289</td>\n",
       "      <td>0.954023</td>\n",
       "      <td>0.952654</td>\n",
       "      <td>0.052147</td>\n",
       "      <td>0.045977</td>\n",
       "      <td>0.958920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.968843</td>\n",
       "      <td>0.957983</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.970213</td>\n",
       "      <td>0.046012</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.993936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting Tree</th>\n",
       "      <td>0.967359</td>\n",
       "      <td>0.960452</td>\n",
       "      <td>0.977011</td>\n",
       "      <td>0.968661</td>\n",
       "      <td>0.042945</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>0.995901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.936202</td>\n",
       "      <td>0.957958</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.936858</td>\n",
       "      <td>0.042945</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.978871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Accuracy  Precision    Recall  F1 Score  \\\n",
       "Logistic Regression     0.965875   0.955182  0.979885  0.967376   \n",
       "Decision Tree           0.951039   0.951289  0.954023  0.952654   \n",
       "Random Forest           0.968843   0.957983  0.982759  0.970213   \n",
       "Gradient Boosting Tree  0.967359   0.960452  0.977011  0.968661   \n",
       "Naive Bayes             0.936202   0.957958  0.916667  0.936858   \n",
       "\n",
       "                        False Positive Rate  False Negative Rate  \\\n",
       "Logistic Regression                0.049080             0.020115   \n",
       "Decision Tree                      0.052147             0.045977   \n",
       "Random Forest                      0.046012             0.017241   \n",
       "Gradient Boosting Tree             0.042945             0.022989   \n",
       "Naive Bayes                        0.042945             0.083333   \n",
       "\n",
       "                        Area Under ROC Curve  \n",
       "Logistic Regression                 0.991600  \n",
       "Decision Tree                       0.958920  \n",
       "Random Forest                       0.993936  \n",
       "Gradient Boosting Tree              0.995901  \n",
       "Naive Bayes                         0.978871  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_style_content_balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde64486",
   "metadata": {},
   "source": [
    "## Imbalanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3eee1e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "style_content_train_imbalanced = pd.concat([word2vec_train_imbalanced['features'], style_train_imbalanced['features']], axis=1)\n",
    "style_content_test_imbalanced = pd.concat([word2vec_test_imbalanced['features'], style_test_imbalanced['features']], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1fd2fd",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3615327d",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02d925c3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9927692931477227\n"
     ]
    }
   ],
   "source": [
    "lr_style_content_imbalanced = ml.train_logistic_regression(style_content_train_imbalanced, style_train_imbalanced['target'], show_train_accuracy=1)\n",
    "lr_style_content_imbalanced, lr_style_content_imbalanced_scaler = lr_style_content_imbalanced['model'], lr_style_content_imbalanced['scaler']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0c2c28",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1fb6866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9833085552101636\n"
     ]
    }
   ],
   "source": [
    "dt_style_content_imbalanced = ml.train_decision_tree(style_content_train_imbalanced, style_train_imbalanced['target'], show_train_accuracy=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400dbaf8",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e067945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9846600892012434\n"
     ]
    }
   ],
   "source": [
    "rf_style_content_imbalanced = ml.train_random_forest(style_content_train_imbalanced, style_train_imbalanced['target'], show_train_accuracy=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e41141",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7d65c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9947965941343425\n"
     ]
    }
   ],
   "source": [
    "gb_style_content_imbalanced = ml.train_gradient_boost(style_content_train_imbalanced, style_train_imbalanced['target'], show_train_accuracy=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9953740",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d16b266",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9080281119070145\n"
     ]
    }
   ],
   "source": [
    "nb_style_content_imbalanced = ml.train_naive_bayes(style_content_train_imbalanced, style_train_imbalanced['target'], show_train_accuracy=1, remove_negatives=True)\n",
    "nb_style_content_imbalanced, nb_style_content_imbalanced_scaler = nb_style_content_imbalanced['model'], nb_style_content_imbalanced['scaler']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c23e477",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "416794b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [lr_style_content_imbalanced, dt_style_content_imbalanced, rf_style_content_imbalanced, gb_style_content_imbalanced, nb_style_content_imbalanced]\n",
    "names = ['Logistic Regression', 'Decision Tree', 'Random Forest', 'Gradient Boosting Tree', 'Naive Bayes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a8046fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_style_content_imbalanced = ml.multi_model_results(models, names, style_content_test_imbalanced, style_test_imbalanced['target'], lr_style_content_imbalanced_scaler, nb_style_content_imbalanced_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa564bda",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>Area Under ROC Curve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.988108</td>\n",
       "      <td>0.940252</td>\n",
       "      <td>0.922840</td>\n",
       "      <td>0.931464</td>\n",
       "      <td>0.005628</td>\n",
       "      <td>0.077160</td>\n",
       "      <td>0.993472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.977838</td>\n",
       "      <td>0.903333</td>\n",
       "      <td>0.836420</td>\n",
       "      <td>0.868590</td>\n",
       "      <td>0.008590</td>\n",
       "      <td>0.163580</td>\n",
       "      <td>0.973080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.979459</td>\n",
       "      <td>0.955882</td>\n",
       "      <td>0.802469</td>\n",
       "      <td>0.872483</td>\n",
       "      <td>0.003555</td>\n",
       "      <td>0.197531</td>\n",
       "      <td>0.993330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting Tree</th>\n",
       "      <td>0.988649</td>\n",
       "      <td>0.946203</td>\n",
       "      <td>0.922840</td>\n",
       "      <td>0.934375</td>\n",
       "      <td>0.005036</td>\n",
       "      <td>0.077160</td>\n",
       "      <td>0.997138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.912703</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003086</td>\n",
       "      <td>0.006154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.996914</td>\n",
       "      <td>0.984712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Accuracy  Precision    Recall  F1 Score  \\\n",
       "Logistic Regression     0.988108   0.940252  0.922840  0.931464   \n",
       "Decision Tree           0.977838   0.903333  0.836420  0.868590   \n",
       "Random Forest           0.979459   0.955882  0.802469  0.872483   \n",
       "Gradient Boosting Tree  0.988649   0.946203  0.922840  0.934375   \n",
       "Naive Bayes             0.912703   1.000000  0.003086  0.006154   \n",
       "\n",
       "                        False Positive Rate  False Negative Rate  \\\n",
       "Logistic Regression                0.005628             0.077160   \n",
       "Decision Tree                      0.008590             0.163580   \n",
       "Random Forest                      0.003555             0.197531   \n",
       "Gradient Boosting Tree             0.005036             0.077160   \n",
       "Naive Bayes                        0.000000             0.996914   \n",
       "\n",
       "                        Area Under ROC Curve  \n",
       "Logistic Regression                 0.993472  \n",
       "Decision Tree                       0.973080  \n",
       "Random Forest                       0.993330  \n",
       "Gradient Boosting Tree              0.997138  \n",
       "Naive Bayes                         0.984712  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_style_content_imbalanced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e02783e",
   "metadata": {},
   "source": [
    "Comparing these with the content-only baseline, it is obvious that there is a at least a small improvement in the balanced dataset and a more significant improvement in the imbalanced dataset.<br>\n",
    "It seems that the extra features are helpful in order to achieve better accuracy on the bigger dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc39478e",
   "metadata": {},
   "source": [
    "Another interesting observation is that the false negative rate of the two best performing algorithms is the same. This means that they both did not detect the same number of phishing emails (25)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "18a0bd88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_dt_predictions = ml.results_by_id([lr_style_content_imbalanced, gb_style_content_imbalanced], ['lr', 'gb'], pd.concat([style_test_imbalanced_complete[['email_id', 'email_class']],  style_content_test_imbalanced], axis=1), style_test_imbalanced_complete['email_id'], lr_style_content_imbalanced_scaler)\n",
    "lr_dt_predictions[(lr_dt_predictions['True Class'] == True) & ((lr_dt_predictions['lr'] == False) & (lr_dt_predictions['gb'] == False))].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973b826c",
   "metadata": {},
   "source": [
    "15 of them were missclassified by both algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2023540",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9003f184",
   "metadata": {},
   "source": [
    "In machine learning, stacking refers to the proccess of using different learners (each one working best at learning a different part of the problem) called level 0 models as intermediate steps and then use their outputs to train another learner, called level 1 model. Thus, the final model is sometimes able to outperform the individual ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93d4a2a",
   "metadata": {},
   "source": [
    "On this specific case, the different initial classifiers will be trained on both of the feature sets, and thus the final classifier essentially will combine information from both of them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea81e25c",
   "metadata": {},
   "source": [
    "#### Final Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338c2ddf",
   "metadata": {},
   "source": [
    "Only the three best classifiers will be used as a level 1 classifier, namely Logistic Regression (which is implemented by default), Random Forest and Gradient Boosting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c22e5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = ml.RandomForestClassifier(max_depth=5, n_estimators=20, random_state=ml.alg_random_state)\n",
    "gb = ml.GradientBoostingClassifier(loss='log_loss', max_depth=3, learning_rate=0.1, random_state=ml.alg_random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc58a2a5",
   "metadata": {},
   "source": [
    "## Balanced Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32941e90",
   "metadata": {},
   "source": [
    "#### Train Initial Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8dda48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature_sets_balanced = [{'name': 'style', 'features': style_train_balanced['features']}, {'name': 'word2vec', 'features': word2vec_train_balanced['features']}]\n",
    "test_feature_sets_balanced = [{'name': 'style', 'features': style_test_balanced['features']}, {'name': 'word2vec', 'features': word2vec_test_balanced['features']}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9a5da859",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stacking_models_balanced = ml.train_models(train_feature_sets_balanced, style_train_balanced['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da494e3",
   "metadata": {},
   "source": [
    "### Single-algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2be1dce",
   "metadata": {},
   "source": [
    "First, the stacking will be done only on the same algorithms with different feature sets, while also testing for different final_classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f28e1c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stacking_balanced_single = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca8b5b4",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "da32f89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], exclude_models=['dt', 'rf', 'gb', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'rf', 'gb', 'nb'])\n",
    "results_stacking_balanced_single = pd.concat([results_stacking_balanced_single, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], exclude_models=['lr', 'rf', 'gb', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['lr', 'rf', 'gb', 'nb'])\n",
    "results_stacking_balanced_single = pd.concat([results_stacking_balanced_single, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], exclude_models=['lr', 'dt', 'gb', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['lr', 'dt', 'gb', 'nb'])\n",
    "results_stacking_balanced_single = pd.concat([results_stacking_balanced_single, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], exclude_models=['lr', 'dt', 'rf', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['lr', 'dt', 'rf', 'nb'])\n",
    "results_stacking_balanced_single = pd.concat([results_stacking_balanced_single, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], exclude_models=['lr', 'dt', 'rf', 'gb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['lr', 'dt', 'rf', 'gb'])\n",
    "results_stacking_balanced_single = pd.concat([results_stacking_balanced_single, stacked_preds['results']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa440123",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ff9069f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=rf, exclude_models=['dt', 'rf', 'gb', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'rf', 'gb', 'nb'])\n",
    "results_stacking_balanced_single = pd.concat([results_stacking_balanced_single, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=rf, exclude_models=['lr', 'rf', 'gb', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['lr', 'rf', 'gb', 'nb'])\n",
    "results_stacking_balanced_single = pd.concat([results_stacking_balanced_single, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=rf, exclude_models=['lr', 'dt', 'gb', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['lr', 'dt', 'gb', 'nb'])\n",
    "results_stacking_balanced_single = pd.concat([results_stacking_balanced_single, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=rf, exclude_models=['lr', 'dt', 'rf', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['lr', 'dt', 'rf', 'nb'])\n",
    "results_stacking_balanced_single = pd.concat([results_stacking_balanced_single, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=rf, exclude_models=['lr', 'dt', 'rf', 'gb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['lr', 'dt', 'rf', 'gb'])\n",
    "results_stacking_balanced_single = pd.concat([results_stacking_balanced_single, stacked_preds['results']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d265000",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e5fa23d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=gb, exclude_models=['dt', 'rf', 'gb', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'rf', 'gb', 'nb'])\n",
    "results_stacking_balanced_single = pd.concat([results_stacking_balanced_single, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=gb, exclude_models=['lr', 'rf', 'gb', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['lr', 'rf', 'gb', 'nb'])\n",
    "results_stacking_balanced_single = pd.concat([results_stacking_balanced_single, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=gb, exclude_models=['lr', 'dt', 'gb', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['lr', 'dt', 'gb', 'nb'])\n",
    "results_stacking_balanced_single = pd.concat([results_stacking_balanced_single, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=gb, exclude_models=['lr', 'dt', 'rf', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['lr', 'dt', 'rf', 'nb'])\n",
    "results_stacking_balanced_single = pd.concat([results_stacking_balanced_single, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=gb, exclude_models=['lr', 'dt', 'rf', 'gb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['lr', 'dt', 'rf', 'gb'])\n",
    "results_stacking_balanced_single = pd.concat([results_stacking_balanced_single, stacked_preds['results']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b5a4e25e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>Area Under ROC Curve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, with LogisticRegression</th>\n",
       "      <td>0.965875</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.977011</td>\n",
       "      <td>0.967283</td>\n",
       "      <td>0.046012</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>0.993557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: dt, with LogisticRegression</th>\n",
       "      <td>0.956973</td>\n",
       "      <td>0.954416</td>\n",
       "      <td>0.962644</td>\n",
       "      <td>0.958512</td>\n",
       "      <td>0.049080</td>\n",
       "      <td>0.037356</td>\n",
       "      <td>0.982252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, with LogisticRegression</th>\n",
       "      <td>0.970326</td>\n",
       "      <td>0.960674</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.971591</td>\n",
       "      <td>0.042945</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.992102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: gb, with LogisticRegression</th>\n",
       "      <td>0.974777</td>\n",
       "      <td>0.963585</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.975887</td>\n",
       "      <td>0.039877</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.995751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: nb, with LogisticRegression</th>\n",
       "      <td>0.940653</td>\n",
       "      <td>0.950292</td>\n",
       "      <td>0.933908</td>\n",
       "      <td>0.942029</td>\n",
       "      <td>0.052147</td>\n",
       "      <td>0.066092</td>\n",
       "      <td>0.980026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, with RandomForestClassifier</th>\n",
       "      <td>0.968843</td>\n",
       "      <td>0.960563</td>\n",
       "      <td>0.979885</td>\n",
       "      <td>0.970128</td>\n",
       "      <td>0.042945</td>\n",
       "      <td>0.020115</td>\n",
       "      <td>0.995099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: dt, with RandomForestClassifier</th>\n",
       "      <td>0.962908</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.977011</td>\n",
       "      <td>0.964539</td>\n",
       "      <td>0.052147</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>0.985328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, with RandomForestClassifier</th>\n",
       "      <td>0.968843</td>\n",
       "      <td>0.960563</td>\n",
       "      <td>0.979885</td>\n",
       "      <td>0.970128</td>\n",
       "      <td>0.042945</td>\n",
       "      <td>0.020115</td>\n",
       "      <td>0.992450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: gb, with RandomForestClassifier</th>\n",
       "      <td>0.976261</td>\n",
       "      <td>0.963687</td>\n",
       "      <td>0.991379</td>\n",
       "      <td>0.977337</td>\n",
       "      <td>0.039877</td>\n",
       "      <td>0.008621</td>\n",
       "      <td>0.995707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: nb, with RandomForestClassifier</th>\n",
       "      <td>0.940653</td>\n",
       "      <td>0.952941</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.941860</td>\n",
       "      <td>0.049080</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.985654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, with GradientBoostingClassifier</th>\n",
       "      <td>0.962908</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.977011</td>\n",
       "      <td>0.964539</td>\n",
       "      <td>0.052147</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>0.993094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: dt, with GradientBoostingClassifier</th>\n",
       "      <td>0.961424</td>\n",
       "      <td>0.954802</td>\n",
       "      <td>0.971264</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.049080</td>\n",
       "      <td>0.028736</td>\n",
       "      <td>0.988210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, with GradientBoostingClassifier</th>\n",
       "      <td>0.962908</td>\n",
       "      <td>0.957507</td>\n",
       "      <td>0.971264</td>\n",
       "      <td>0.964337</td>\n",
       "      <td>0.046012</td>\n",
       "      <td>0.028736</td>\n",
       "      <td>0.991635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: gb, with GradientBoostingClassifier</th>\n",
       "      <td>0.974777</td>\n",
       "      <td>0.966197</td>\n",
       "      <td>0.985632</td>\n",
       "      <td>0.975818</td>\n",
       "      <td>0.036810</td>\n",
       "      <td>0.014368</td>\n",
       "      <td>0.995641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: nb, with GradientBoostingClassifier</th>\n",
       "      <td>0.943620</td>\n",
       "      <td>0.945402</td>\n",
       "      <td>0.945402</td>\n",
       "      <td>0.945402</td>\n",
       "      <td>0.058282</td>\n",
       "      <td>0.054598</td>\n",
       "      <td>0.985474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Accuracy  Precision  \\\n",
       "Algorithms: lr, with LogisticRegression          0.965875   0.957746   \n",
       "Algorithms: dt, with LogisticRegression          0.956973   0.954416   \n",
       "Algorithms: rf, with LogisticRegression          0.970326   0.960674   \n",
       "Algorithms: gb, with LogisticRegression          0.974777   0.963585   \n",
       "Algorithms: nb, with LogisticRegression          0.940653   0.950292   \n",
       "Algorithms: lr, with RandomForestClassifier      0.968843   0.960563   \n",
       "Algorithms: dt, with RandomForestClassifier      0.962908   0.952381   \n",
       "Algorithms: rf, with RandomForestClassifier      0.968843   0.960563   \n",
       "Algorithms: gb, with RandomForestClassifier      0.976261   0.963687   \n",
       "Algorithms: nb, with RandomForestClassifier      0.940653   0.952941   \n",
       "Algorithms: lr, with GradientBoostingClassifier  0.962908   0.952381   \n",
       "Algorithms: dt, with GradientBoostingClassifier  0.961424   0.954802   \n",
       "Algorithms: rf, with GradientBoostingClassifier  0.962908   0.957507   \n",
       "Algorithms: gb, with GradientBoostingClassifier  0.974777   0.966197   \n",
       "Algorithms: nb, with GradientBoostingClassifier  0.943620   0.945402   \n",
       "\n",
       "                                                   Recall  F1 Score  \\\n",
       "Algorithms: lr, with LogisticRegression          0.977011  0.967283   \n",
       "Algorithms: dt, with LogisticRegression          0.962644  0.958512   \n",
       "Algorithms: rf, with LogisticRegression          0.982759  0.971591   \n",
       "Algorithms: gb, with LogisticRegression          0.988506  0.975887   \n",
       "Algorithms: nb, with LogisticRegression          0.933908  0.942029   \n",
       "Algorithms: lr, with RandomForestClassifier      0.979885  0.970128   \n",
       "Algorithms: dt, with RandomForestClassifier      0.977011  0.964539   \n",
       "Algorithms: rf, with RandomForestClassifier      0.979885  0.970128   \n",
       "Algorithms: gb, with RandomForestClassifier      0.991379  0.977337   \n",
       "Algorithms: nb, with RandomForestClassifier      0.931034  0.941860   \n",
       "Algorithms: lr, with GradientBoostingClassifier  0.977011  0.964539   \n",
       "Algorithms: dt, with GradientBoostingClassifier  0.971264  0.962963   \n",
       "Algorithms: rf, with GradientBoostingClassifier  0.971264  0.964337   \n",
       "Algorithms: gb, with GradientBoostingClassifier  0.985632  0.975818   \n",
       "Algorithms: nb, with GradientBoostingClassifier  0.945402  0.945402   \n",
       "\n",
       "                                                 False Positive Rate  \\\n",
       "Algorithms: lr, with LogisticRegression                     0.046012   \n",
       "Algorithms: dt, with LogisticRegression                     0.049080   \n",
       "Algorithms: rf, with LogisticRegression                     0.042945   \n",
       "Algorithms: gb, with LogisticRegression                     0.039877   \n",
       "Algorithms: nb, with LogisticRegression                     0.052147   \n",
       "Algorithms: lr, with RandomForestClassifier                 0.042945   \n",
       "Algorithms: dt, with RandomForestClassifier                 0.052147   \n",
       "Algorithms: rf, with RandomForestClassifier                 0.042945   \n",
       "Algorithms: gb, with RandomForestClassifier                 0.039877   \n",
       "Algorithms: nb, with RandomForestClassifier                 0.049080   \n",
       "Algorithms: lr, with GradientBoostingClassifier             0.052147   \n",
       "Algorithms: dt, with GradientBoostingClassifier             0.049080   \n",
       "Algorithms: rf, with GradientBoostingClassifier             0.046012   \n",
       "Algorithms: gb, with GradientBoostingClassifier             0.036810   \n",
       "Algorithms: nb, with GradientBoostingClassifier             0.058282   \n",
       "\n",
       "                                                 False Negative Rate  \\\n",
       "Algorithms: lr, with LogisticRegression                     0.022989   \n",
       "Algorithms: dt, with LogisticRegression                     0.037356   \n",
       "Algorithms: rf, with LogisticRegression                     0.017241   \n",
       "Algorithms: gb, with LogisticRegression                     0.011494   \n",
       "Algorithms: nb, with LogisticRegression                     0.066092   \n",
       "Algorithms: lr, with RandomForestClassifier                 0.020115   \n",
       "Algorithms: dt, with RandomForestClassifier                 0.022989   \n",
       "Algorithms: rf, with RandomForestClassifier                 0.020115   \n",
       "Algorithms: gb, with RandomForestClassifier                 0.008621   \n",
       "Algorithms: nb, with RandomForestClassifier                 0.068966   \n",
       "Algorithms: lr, with GradientBoostingClassifier             0.022989   \n",
       "Algorithms: dt, with GradientBoostingClassifier             0.028736   \n",
       "Algorithms: rf, with GradientBoostingClassifier             0.028736   \n",
       "Algorithms: gb, with GradientBoostingClassifier             0.014368   \n",
       "Algorithms: nb, with GradientBoostingClassifier             0.054598   \n",
       "\n",
       "                                                 Area Under ROC Curve  \n",
       "Algorithms: lr, with LogisticRegression                      0.993557  \n",
       "Algorithms: dt, with LogisticRegression                      0.982252  \n",
       "Algorithms: rf, with LogisticRegression                      0.992102  \n",
       "Algorithms: gb, with LogisticRegression                      0.995751  \n",
       "Algorithms: nb, with LogisticRegression                      0.980026  \n",
       "Algorithms: lr, with RandomForestClassifier                  0.995099  \n",
       "Algorithms: dt, with RandomForestClassifier                  0.985328  \n",
       "Algorithms: rf, with RandomForestClassifier                  0.992450  \n",
       "Algorithms: gb, with RandomForestClassifier                  0.995707  \n",
       "Algorithms: nb, with RandomForestClassifier                  0.985654  \n",
       "Algorithms: lr, with GradientBoostingClassifier              0.993094  \n",
       "Algorithms: dt, with GradientBoostingClassifier              0.988210  \n",
       "Algorithms: rf, with GradientBoostingClassifier              0.991635  \n",
       "Algorithms: gb, with GradientBoostingClassifier              0.995641  \n",
       "Algorithms: nb, with GradientBoostingClassifier              0.985474  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_stacking_balanced_single"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1f7ca0",
   "metadata": {},
   "source": [
    "It is apparent that the results are better than the baseline models, and at some cases (when Random Forest of Gradient Boosting is used in at least one of the steps) even better than predicting with the merged feature sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645cc568",
   "metadata": {},
   "source": [
    "The 6 best performing models will be kept to compare with other stacking configurations and the complete single-algorithm results dataset will be archived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0452feca",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stacking_balanced_full = results_stacking_balanced_single.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1b978634",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stacking_balanced_best = results_stacking_balanced_single.sort_values(by=['F1 Score'], ascending = [False]).head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c225b01",
   "metadata": {},
   "source": [
    "### Multi-algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e2dd8c",
   "metadata": {},
   "source": [
    "Of course, it is possible to also use the outputs of more than one classifier, on both feature sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7c646926",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stacking_balanced_multi = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6992754c",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8f058e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], exclude_models=[])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=[], result_row_name=\"Algorithms: all, with LogisticRegression\")\n",
    "results_stacking_balanced_multi = pd.concat([results_stacking_balanced_multi, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], exclude_models=['dt', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb'])\n",
    "results_stacking_balanced_multi = pd.concat([results_stacking_balanced_multi, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], exclude_models=['dt', 'nb', 'lr'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'lr'])\n",
    "results_stacking_balanced_multi = pd.concat([results_stacking_balanced_multi, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], exclude_models=['dt', 'nb', 'rf'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'rf'])\n",
    "results_stacking_balanced_multi = pd.concat([results_stacking_balanced_multi, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], exclude_models=['dt', 'nb', 'gb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb'])\n",
    "results_stacking_balanced_multi = pd.concat([results_stacking_balanced_multi, stacked_preds['results']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15252f18",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4d1ac0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=rf, exclude_models=[])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=[], result_row_name=\"Algorithms: all, with RandomForestClassifier\")\n",
    "results_stacking_balanced_multi = pd.concat([results_stacking_balanced_multi, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=rf, exclude_models=['dt', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb'])\n",
    "results_stacking_balanced_multi = pd.concat([results_stacking_balanced_multi, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=rf, exclude_models=['dt', 'nb', 'lr'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'lr'])\n",
    "results_stacking_balanced_multi = pd.concat([results_stacking_balanced_multi, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=rf, exclude_models=['dt', 'nb', 'rf'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'rf'])\n",
    "results_stacking_balanced_multi = pd.concat([results_stacking_balanced_multi, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=rf, exclude_models=['dt', 'nb', 'gb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb'])\n",
    "results_stacking_balanced_multi = pd.concat([results_stacking_balanced_multi, stacked_preds['results']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583405a9",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c6e30e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=gb, exclude_models=[])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=[], result_row_name=\"Algorithms: all, with GradientBoostingClassifier\")\n",
    "results_stacking_balanced_multi = pd.concat([results_stacking_balanced_multi, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=gb, exclude_models=['dt', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb'])\n",
    "results_stacking_balanced_multi = pd.concat([results_stacking_balanced_multi, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=gb, exclude_models=['dt', 'nb', 'lr'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'lr'])\n",
    "results_stacking_balanced_multi = pd.concat([results_stacking_balanced_multi, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=gb, exclude_models=['dt', 'nb', 'rf'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'rf'])\n",
    "results_stacking_balanced_multi = pd.concat([results_stacking_balanced_multi, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=gb, exclude_models=['dt', 'nb', 'gb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb'])\n",
    "results_stacking_balanced_multi = pd.concat([results_stacking_balanced_multi, stacked_preds['results']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "49b34a9c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>Area Under ROC Curve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Algorithms: all, with LogisticRegression</th>\n",
       "      <td>0.976261</td>\n",
       "      <td>0.966292</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.036810</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.995954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, lr, gb, with LogisticRegression</th>\n",
       "      <td>0.976261</td>\n",
       "      <td>0.966292</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.036810</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.995989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, gb, with LogisticRegression</th>\n",
       "      <td>0.974777</td>\n",
       "      <td>0.963585</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.975887</td>\n",
       "      <td>0.039877</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.994870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, gb, with LogisticRegression</th>\n",
       "      <td>0.976261</td>\n",
       "      <td>0.968927</td>\n",
       "      <td>0.985632</td>\n",
       "      <td>0.977208</td>\n",
       "      <td>0.033742</td>\n",
       "      <td>0.014368</td>\n",
       "      <td>0.996430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, lr, with LogisticRegression</th>\n",
       "      <td>0.974777</td>\n",
       "      <td>0.963585</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.975887</td>\n",
       "      <td>0.039877</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.995037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: all, with RandomForestClassifier</th>\n",
       "      <td>0.974777</td>\n",
       "      <td>0.963585</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.975887</td>\n",
       "      <td>0.039877</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.995209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, lr, gb, with RandomForestClassifier</th>\n",
       "      <td>0.977745</td>\n",
       "      <td>0.966387</td>\n",
       "      <td>0.991379</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>0.036810</td>\n",
       "      <td>0.008621</td>\n",
       "      <td>0.996130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, gb, with RandomForestClassifier</th>\n",
       "      <td>0.974777</td>\n",
       "      <td>0.963585</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.975887</td>\n",
       "      <td>0.039877</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.993565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, gb, with RandomForestClassifier</th>\n",
       "      <td>0.976261</td>\n",
       "      <td>0.963687</td>\n",
       "      <td>0.991379</td>\n",
       "      <td>0.977337</td>\n",
       "      <td>0.039877</td>\n",
       "      <td>0.008621</td>\n",
       "      <td>0.996598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, lr, with RandomForestClassifier</th>\n",
       "      <td>0.973294</td>\n",
       "      <td>0.966102</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.036810</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.995632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: all, with GradientBoostingClassifier</th>\n",
       "      <td>0.977745</td>\n",
       "      <td>0.966387</td>\n",
       "      <td>0.991379</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>0.036810</td>\n",
       "      <td>0.008621</td>\n",
       "      <td>0.995646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, lr, gb, with GradientBoostingClassifier</th>\n",
       "      <td>0.977745</td>\n",
       "      <td>0.966387</td>\n",
       "      <td>0.991379</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>0.036810</td>\n",
       "      <td>0.008621</td>\n",
       "      <td>0.996130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, gb, with GradientBoostingClassifier</th>\n",
       "      <td>0.971810</td>\n",
       "      <td>0.963380</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.039877</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.995848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, gb, with GradientBoostingClassifier</th>\n",
       "      <td>0.979228</td>\n",
       "      <td>0.969101</td>\n",
       "      <td>0.991379</td>\n",
       "      <td>0.980114</td>\n",
       "      <td>0.033742</td>\n",
       "      <td>0.008621</td>\n",
       "      <td>0.996307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, lr, with GradientBoostingClassifier</th>\n",
       "      <td>0.974777</td>\n",
       "      <td>0.963585</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.975887</td>\n",
       "      <td>0.039877</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.995566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Accuracy  Precision  \\\n",
       "Algorithms: all, with LogisticRegression            0.976261   0.966292   \n",
       "Algorithms: rf, lr, gb, with LogisticRegression     0.976261   0.966292   \n",
       "Algorithms: rf, gb, with LogisticRegression         0.974777   0.963585   \n",
       "Algorithms: lr, gb, with LogisticRegression         0.976261   0.968927   \n",
       "Algorithms: rf, lr, with LogisticRegression         0.974777   0.963585   \n",
       "Algorithms: all, with RandomForestClassifier        0.974777   0.963585   \n",
       "Algorithms: rf, lr, gb, with RandomForestClassi...  0.977745   0.966387   \n",
       "Algorithms: rf, gb, with RandomForestClassifier     0.974777   0.963585   \n",
       "Algorithms: lr, gb, with RandomForestClassifier     0.976261   0.963687   \n",
       "Algorithms: rf, lr, with RandomForestClassifier     0.973294   0.966102   \n",
       "Algorithms: all, with GradientBoostingClassifier    0.977745   0.966387   \n",
       "Algorithms: rf, lr, gb, with GradientBoostingCl...  0.977745   0.966387   \n",
       "Algorithms: rf, gb, with GradientBoostingClassi...  0.971810   0.963380   \n",
       "Algorithms: lr, gb, with GradientBoostingClassi...  0.979228   0.969101   \n",
       "Algorithms: rf, lr, with GradientBoostingClassi...  0.974777   0.963585   \n",
       "\n",
       "                                                      Recall  F1 Score  \\\n",
       "Algorithms: all, with LogisticRegression            0.988506  0.977273   \n",
       "Algorithms: rf, lr, gb, with LogisticRegression     0.988506  0.977273   \n",
       "Algorithms: rf, gb, with LogisticRegression         0.988506  0.975887   \n",
       "Algorithms: lr, gb, with LogisticRegression         0.985632  0.977208   \n",
       "Algorithms: rf, lr, with LogisticRegression         0.988506  0.975887   \n",
       "Algorithms: all, with RandomForestClassifier        0.988506  0.975887   \n",
       "Algorithms: rf, lr, gb, with RandomForestClassi...  0.991379  0.978723   \n",
       "Algorithms: rf, gb, with RandomForestClassifier     0.988506  0.975887   \n",
       "Algorithms: lr, gb, with RandomForestClassifier     0.991379  0.977337   \n",
       "Algorithms: rf, lr, with RandomForestClassifier     0.982759  0.974359   \n",
       "Algorithms: all, with GradientBoostingClassifier    0.991379  0.978723   \n",
       "Algorithms: rf, lr, gb, with GradientBoostingCl...  0.991379  0.978723   \n",
       "Algorithms: rf, gb, with GradientBoostingClassi...  0.982759  0.972973   \n",
       "Algorithms: lr, gb, with GradientBoostingClassi...  0.991379  0.980114   \n",
       "Algorithms: rf, lr, with GradientBoostingClassi...  0.988506  0.975887   \n",
       "\n",
       "                                                    False Positive Rate  \\\n",
       "Algorithms: all, with LogisticRegression                       0.036810   \n",
       "Algorithms: rf, lr, gb, with LogisticRegression                0.036810   \n",
       "Algorithms: rf, gb, with LogisticRegression                    0.039877   \n",
       "Algorithms: lr, gb, with LogisticRegression                    0.033742   \n",
       "Algorithms: rf, lr, with LogisticRegression                    0.039877   \n",
       "Algorithms: all, with RandomForestClassifier                   0.039877   \n",
       "Algorithms: rf, lr, gb, with RandomForestClassi...             0.036810   \n",
       "Algorithms: rf, gb, with RandomForestClassifier                0.039877   \n",
       "Algorithms: lr, gb, with RandomForestClassifier                0.039877   \n",
       "Algorithms: rf, lr, with RandomForestClassifier                0.036810   \n",
       "Algorithms: all, with GradientBoostingClassifier               0.036810   \n",
       "Algorithms: rf, lr, gb, with GradientBoostingCl...             0.036810   \n",
       "Algorithms: rf, gb, with GradientBoostingClassi...             0.039877   \n",
       "Algorithms: lr, gb, with GradientBoostingClassi...             0.033742   \n",
       "Algorithms: rf, lr, with GradientBoostingClassi...             0.039877   \n",
       "\n",
       "                                                    False Negative Rate  \\\n",
       "Algorithms: all, with LogisticRegression                       0.011494   \n",
       "Algorithms: rf, lr, gb, with LogisticRegression                0.011494   \n",
       "Algorithms: rf, gb, with LogisticRegression                    0.011494   \n",
       "Algorithms: lr, gb, with LogisticRegression                    0.014368   \n",
       "Algorithms: rf, lr, with LogisticRegression                    0.011494   \n",
       "Algorithms: all, with RandomForestClassifier                   0.011494   \n",
       "Algorithms: rf, lr, gb, with RandomForestClassi...             0.008621   \n",
       "Algorithms: rf, gb, with RandomForestClassifier                0.011494   \n",
       "Algorithms: lr, gb, with RandomForestClassifier                0.008621   \n",
       "Algorithms: rf, lr, with RandomForestClassifier                0.017241   \n",
       "Algorithms: all, with GradientBoostingClassifier               0.008621   \n",
       "Algorithms: rf, lr, gb, with GradientBoostingCl...             0.008621   \n",
       "Algorithms: rf, gb, with GradientBoostingClassi...             0.017241   \n",
       "Algorithms: lr, gb, with GradientBoostingClassi...             0.008621   \n",
       "Algorithms: rf, lr, with GradientBoostingClassi...             0.011494   \n",
       "\n",
       "                                                    Area Under ROC Curve  \n",
       "Algorithms: all, with LogisticRegression                        0.995954  \n",
       "Algorithms: rf, lr, gb, with LogisticRegression                 0.995989  \n",
       "Algorithms: rf, gb, with LogisticRegression                     0.994870  \n",
       "Algorithms: lr, gb, with LogisticRegression                     0.996430  \n",
       "Algorithms: rf, lr, with LogisticRegression                     0.995037  \n",
       "Algorithms: all, with RandomForestClassifier                    0.995209  \n",
       "Algorithms: rf, lr, gb, with RandomForestClassi...              0.996130  \n",
       "Algorithms: rf, gb, with RandomForestClassifier                 0.993565  \n",
       "Algorithms: lr, gb, with RandomForestClassifier                 0.996598  \n",
       "Algorithms: rf, lr, with RandomForestClassifier                 0.995632  \n",
       "Algorithms: all, with GradientBoostingClassifier                0.995646  \n",
       "Algorithms: rf, lr, gb, with GradientBoostingCl...              0.996130  \n",
       "Algorithms: rf, gb, with GradientBoostingClassi...              0.995848  \n",
       "Algorithms: lr, gb, with GradientBoostingClassi...              0.996307  \n",
       "Algorithms: rf, lr, with GradientBoostingClassi...              0.995566  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_stacking_balanced_multi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4da4f4d",
   "metadata": {},
   "source": [
    "As expected, using more than one classifier consistently improves the classification accuracy. The best level 1 classifier seems to be Gradient Boosting, and Logistic Regression gives better results when used as a level 0 classifier. However, all combinations performed quite well.\n",
    "\n",
    "On the other hand, Naive Bayes and Decision Tree classifiers do not affect the result at all or even reduce the accuracy when used with the Random Forest Classifier, so from now on they will be excluded in order to reduce the execution time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b21358",
   "metadata": {},
   "source": [
    "The top 8 models will be added to the best model results dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "83adf932",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stacking_balanced_best = pd.concat([results_stacking_balanced_best, results_stacking_balanced_multi.sort_values(by=['F1 Score'], ascending = [False]).head(8)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8e49ade4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stacking_balanced_full = pd.concat([results_stacking_balanced_full, results_stacking_balanced_multi])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28750c26",
   "metadata": {},
   "source": [
    "### Appending all features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c16a89",
   "metadata": {},
   "source": [
    "Another variation of stacking includes appending the predictions to the other feature sets and then train the final classifier with all the features.<br>\n",
    "Since using both feature sets has been proven to improve accuracy on the baselines, the predictions will be appended to the merged feature set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "46e9a9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stacking_balanced_append = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d413228",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "db748200",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], exclude_models=[], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=[], append_features=True, result_row_name=\"Algorithms: all, with LogisticRegression (with appended features)\")\n",
    "results_stacking_balanced_append = pd.concat([results_stacking_balanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], exclude_models=['dt', 'nb'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb'], append_features=True)\n",
    "results_stacking_balanced_append = pd.concat([results_stacking_balanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], exclude_models=['dt', 'nb', 'lr'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'lr'], append_features=True)\n",
    "results_stacking_balanced_append = pd.concat([results_stacking_balanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], exclude_models=['dt', 'nb', 'rf'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'rf'], append_features=True)\n",
    "results_stacking_balanced_append = pd.concat([results_stacking_balanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], exclude_models=['dt', 'nb', 'gb'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb'], append_features=True)\n",
    "results_stacking_balanced_append = pd.concat([results_stacking_balanced_append, stacked_preds['results']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0882cf89",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e8085c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=rf, exclude_models=[], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=[], append_features=True, result_row_name=\"Algorithms: all, with RandomForestClassifier (with appended features)\")\n",
    "results_stacking_balanced_append = pd.concat([results_stacking_balanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=rf, exclude_models=['dt', 'nb'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb'], append_features=True)\n",
    "results_stacking_balanced_append = pd.concat([results_stacking_balanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=rf, exclude_models=['dt', 'nb', 'lr'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'lr'], append_features=True)\n",
    "results_stacking_balanced_append = pd.concat([results_stacking_balanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=rf, exclude_models=['dt', 'nb', 'rf'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'rf'], append_features=True)\n",
    "results_stacking_balanced_append = pd.concat([results_stacking_balanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=rf, exclude_models=['dt', 'nb', 'gb'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb'], append_features=True)\n",
    "results_stacking_balanced_append = pd.concat([results_stacking_balanced_append, stacked_preds['results']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbef30e",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0553dc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=gb, exclude_models=[], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=[], append_features=True, result_row_name=\"Algorithms: all, with GradientBoostingClassifier (with appended features)\")\n",
    "results_stacking_balanced_append = pd.concat([results_stacking_balanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=gb, exclude_models=['dt', 'nb'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb'], append_features=True)\n",
    "results_stacking_balanced_append = pd.concat([results_stacking_balanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=gb, exclude_models=['dt', 'nb', 'lr'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'lr'], append_features=True)\n",
    "results_stacking_balanced_append = pd.concat([results_stacking_balanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=gb, exclude_models=['dt', 'nb', 'rf'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'rf'], append_features=True)\n",
    "results_stacking_balanced_append = pd.concat([results_stacking_balanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_balanced, train_feature_sets_balanced, style_train_balanced['target'], final_classifier=gb, exclude_models=['dt', 'nb', 'gb'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_balanced, test_feature_sets_balanced, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb'], append_features=True)\n",
    "results_stacking_balanced_append = pd.concat([results_stacking_balanced_append, stacked_preds['results']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dc780ce8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>Area Under ROC Curve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Algorithms: all, with LogisticRegression (with appended features)</th>\n",
       "      <td>0.959941</td>\n",
       "      <td>0.949580</td>\n",
       "      <td>0.974138</td>\n",
       "      <td>0.961702</td>\n",
       "      <td>0.055215</td>\n",
       "      <td>0.025862</td>\n",
       "      <td>0.976024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, lr, gb, with LogisticRegression (with appended features)</th>\n",
       "      <td>0.958457</td>\n",
       "      <td>0.949438</td>\n",
       "      <td>0.971264</td>\n",
       "      <td>0.960227</td>\n",
       "      <td>0.055215</td>\n",
       "      <td>0.028736</td>\n",
       "      <td>0.975125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, gb, with LogisticRegression (with appended features)</th>\n",
       "      <td>0.956973</td>\n",
       "      <td>0.951841</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.958631</td>\n",
       "      <td>0.052147</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.974006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, gb, with LogisticRegression (with appended features)</th>\n",
       "      <td>0.951039</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.956897</td>\n",
       "      <td>0.952790</td>\n",
       "      <td>0.055215</td>\n",
       "      <td>0.043103</td>\n",
       "      <td>0.978730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, lr, with LogisticRegression (with appended features)</th>\n",
       "      <td>0.958457</td>\n",
       "      <td>0.946927</td>\n",
       "      <td>0.974138</td>\n",
       "      <td>0.960340</td>\n",
       "      <td>0.058282</td>\n",
       "      <td>0.025862</td>\n",
       "      <td>0.971864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: all, with RandomForestClassifier (with appended features)</th>\n",
       "      <td>0.970326</td>\n",
       "      <td>0.960674</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.971591</td>\n",
       "      <td>0.042945</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.995857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, lr, gb, with RandomForestClassifier (with appended features)</th>\n",
       "      <td>0.974777</td>\n",
       "      <td>0.966197</td>\n",
       "      <td>0.985632</td>\n",
       "      <td>0.975818</td>\n",
       "      <td>0.036810</td>\n",
       "      <td>0.014368</td>\n",
       "      <td>0.995884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, gb, with RandomForestClassifier (with appended features)</th>\n",
       "      <td>0.968843</td>\n",
       "      <td>0.963173</td>\n",
       "      <td>0.977011</td>\n",
       "      <td>0.970043</td>\n",
       "      <td>0.039877</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>0.994575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, gb, with RandomForestClassifier (with appended features)</th>\n",
       "      <td>0.968843</td>\n",
       "      <td>0.963173</td>\n",
       "      <td>0.977011</td>\n",
       "      <td>0.970043</td>\n",
       "      <td>0.039877</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>0.994548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, lr, with RandomForestClassifier (with appended features)</th>\n",
       "      <td>0.973294</td>\n",
       "      <td>0.966102</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.036810</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.995249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: all, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.979228</td>\n",
       "      <td>0.969101</td>\n",
       "      <td>0.991379</td>\n",
       "      <td>0.980114</td>\n",
       "      <td>0.033742</td>\n",
       "      <td>0.008621</td>\n",
       "      <td>0.996201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, lr, gb, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.980712</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>0.991379</td>\n",
       "      <td>0.981508</td>\n",
       "      <td>0.030675</td>\n",
       "      <td>0.008621</td>\n",
       "      <td>0.996598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, gb, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.974777</td>\n",
       "      <td>0.961003</td>\n",
       "      <td>0.991379</td>\n",
       "      <td>0.975955</td>\n",
       "      <td>0.042945</td>\n",
       "      <td>0.008621</td>\n",
       "      <td>0.995989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, gb, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.980712</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>0.991379</td>\n",
       "      <td>0.981508</td>\n",
       "      <td>0.030675</td>\n",
       "      <td>0.008621</td>\n",
       "      <td>0.996783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, lr, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.979228</td>\n",
       "      <td>0.971751</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.980057</td>\n",
       "      <td>0.030675</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.996342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Accuracy  Precision  \\\n",
       "Algorithms: all, with LogisticRegression (with ...  0.959941   0.949580   \n",
       "Algorithms: rf, lr, gb, with LogisticRegression...  0.958457   0.949438   \n",
       "Algorithms: rf, gb, with LogisticRegression (wi...  0.956973   0.951841   \n",
       "Algorithms: lr, gb, with LogisticRegression (wi...  0.951039   0.948718   \n",
       "Algorithms: rf, lr, with LogisticRegression (wi...  0.958457   0.946927   \n",
       "Algorithms: all, with RandomForestClassifier (w...  0.970326   0.960674   \n",
       "Algorithms: rf, lr, gb, with RandomForestClassi...  0.974777   0.966197   \n",
       "Algorithms: rf, gb, with RandomForestClassifier...  0.968843   0.963173   \n",
       "Algorithms: lr, gb, with RandomForestClassifier...  0.968843   0.963173   \n",
       "Algorithms: rf, lr, with RandomForestClassifier...  0.973294   0.966102   \n",
       "Algorithms: all, with GradientBoostingClassifie...  0.979228   0.969101   \n",
       "Algorithms: rf, lr, gb, with GradientBoostingCl...  0.980712   0.971831   \n",
       "Algorithms: rf, gb, with GradientBoostingClassi...  0.974777   0.961003   \n",
       "Algorithms: lr, gb, with GradientBoostingClassi...  0.980712   0.971831   \n",
       "Algorithms: rf, lr, with GradientBoostingClassi...  0.979228   0.971751   \n",
       "\n",
       "                                                      Recall  F1 Score  \\\n",
       "Algorithms: all, with LogisticRegression (with ...  0.974138  0.961702   \n",
       "Algorithms: rf, lr, gb, with LogisticRegression...  0.971264  0.960227   \n",
       "Algorithms: rf, gb, with LogisticRegression (wi...  0.965517  0.958631   \n",
       "Algorithms: lr, gb, with LogisticRegression (wi...  0.956897  0.952790   \n",
       "Algorithms: rf, lr, with LogisticRegression (wi...  0.974138  0.960340   \n",
       "Algorithms: all, with RandomForestClassifier (w...  0.982759  0.971591   \n",
       "Algorithms: rf, lr, gb, with RandomForestClassi...  0.985632  0.975818   \n",
       "Algorithms: rf, gb, with RandomForestClassifier...  0.977011  0.970043   \n",
       "Algorithms: lr, gb, with RandomForestClassifier...  0.977011  0.970043   \n",
       "Algorithms: rf, lr, with RandomForestClassifier...  0.982759  0.974359   \n",
       "Algorithms: all, with GradientBoostingClassifie...  0.991379  0.980114   \n",
       "Algorithms: rf, lr, gb, with GradientBoostingCl...  0.991379  0.981508   \n",
       "Algorithms: rf, gb, with GradientBoostingClassi...  0.991379  0.975955   \n",
       "Algorithms: lr, gb, with GradientBoostingClassi...  0.991379  0.981508   \n",
       "Algorithms: rf, lr, with GradientBoostingClassi...  0.988506  0.980057   \n",
       "\n",
       "                                                    False Positive Rate  \\\n",
       "Algorithms: all, with LogisticRegression (with ...             0.055215   \n",
       "Algorithms: rf, lr, gb, with LogisticRegression...             0.055215   \n",
       "Algorithms: rf, gb, with LogisticRegression (wi...             0.052147   \n",
       "Algorithms: lr, gb, with LogisticRegression (wi...             0.055215   \n",
       "Algorithms: rf, lr, with LogisticRegression (wi...             0.058282   \n",
       "Algorithms: all, with RandomForestClassifier (w...             0.042945   \n",
       "Algorithms: rf, lr, gb, with RandomForestClassi...             0.036810   \n",
       "Algorithms: rf, gb, with RandomForestClassifier...             0.039877   \n",
       "Algorithms: lr, gb, with RandomForestClassifier...             0.039877   \n",
       "Algorithms: rf, lr, with RandomForestClassifier...             0.036810   \n",
       "Algorithms: all, with GradientBoostingClassifie...             0.033742   \n",
       "Algorithms: rf, lr, gb, with GradientBoostingCl...             0.030675   \n",
       "Algorithms: rf, gb, with GradientBoostingClassi...             0.042945   \n",
       "Algorithms: lr, gb, with GradientBoostingClassi...             0.030675   \n",
       "Algorithms: rf, lr, with GradientBoostingClassi...             0.030675   \n",
       "\n",
       "                                                    False Negative Rate  \\\n",
       "Algorithms: all, with LogisticRegression (with ...             0.025862   \n",
       "Algorithms: rf, lr, gb, with LogisticRegression...             0.028736   \n",
       "Algorithms: rf, gb, with LogisticRegression (wi...             0.034483   \n",
       "Algorithms: lr, gb, with LogisticRegression (wi...             0.043103   \n",
       "Algorithms: rf, lr, with LogisticRegression (wi...             0.025862   \n",
       "Algorithms: all, with RandomForestClassifier (w...             0.017241   \n",
       "Algorithms: rf, lr, gb, with RandomForestClassi...             0.014368   \n",
       "Algorithms: rf, gb, with RandomForestClassifier...             0.022989   \n",
       "Algorithms: lr, gb, with RandomForestClassifier...             0.022989   \n",
       "Algorithms: rf, lr, with RandomForestClassifier...             0.017241   \n",
       "Algorithms: all, with GradientBoostingClassifie...             0.008621   \n",
       "Algorithms: rf, lr, gb, with GradientBoostingCl...             0.008621   \n",
       "Algorithms: rf, gb, with GradientBoostingClassi...             0.008621   \n",
       "Algorithms: lr, gb, with GradientBoostingClassi...             0.008621   \n",
       "Algorithms: rf, lr, with GradientBoostingClassi...             0.011494   \n",
       "\n",
       "                                                    Area Under ROC Curve  \n",
       "Algorithms: all, with LogisticRegression (with ...              0.976024  \n",
       "Algorithms: rf, lr, gb, with LogisticRegression...              0.975125  \n",
       "Algorithms: rf, gb, with LogisticRegression (wi...              0.974006  \n",
       "Algorithms: lr, gb, with LogisticRegression (wi...              0.978730  \n",
       "Algorithms: rf, lr, with LogisticRegression (wi...              0.971864  \n",
       "Algorithms: all, with RandomForestClassifier (w...              0.995857  \n",
       "Algorithms: rf, lr, gb, with RandomForestClassi...              0.995884  \n",
       "Algorithms: rf, gb, with RandomForestClassifier...              0.994575  \n",
       "Algorithms: lr, gb, with RandomForestClassifier...              0.994548  \n",
       "Algorithms: rf, lr, with RandomForestClassifier...              0.995249  \n",
       "Algorithms: all, with GradientBoostingClassifie...              0.996201  \n",
       "Algorithms: rf, lr, gb, with GradientBoostingCl...              0.996598  \n",
       "Algorithms: rf, gb, with GradientBoostingClassi...              0.995989  \n",
       "Algorithms: lr, gb, with GradientBoostingClassi...              0.996783  \n",
       "Algorithms: rf, lr, with GradientBoostingClassi...              0.996342  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_stacking_balanced_append"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dec3450",
   "metadata": {},
   "source": [
    "Adding the initial feature sets to the final classifier seems to mostly harm performance on the balanced dataset. This is most likely due to overfitting, since the level 1 classifier becomes extremely specialized at recognizing the emails provided in the training set and fails to generalize for the test set.\n",
    "\n",
    "However, when using Gradient Boosting as the final classifier, it manages at some cases to outperform the model without the appended features. This is no surprise, since Boosting methods in general are somewhat more resistant to overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e7f3f1",
   "metadata": {},
   "source": [
    "The top 6 of these models will be added to the best result dataset, for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eb3c8314",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stacking_balanced_best = pd.concat([results_stacking_balanced_best, results_stacking_balanced_append.sort_values(by=['F1 Score'], ascending = [False]).head(6)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cc366408",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stacking_balanced_full = pd.concat([results_stacking_balanced_full, results_stacking_balanced_append])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708c9fe3",
   "metadata": {},
   "source": [
    "### Merged Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842d8dac",
   "metadata": {},
   "source": [
    "Finally, for the sake of completeness, try stacking the level 0 classifiers that were trained with the merged dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "09253e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature_sets_balanced_merged = [{'name': 'merge', 'features': style_content_train_balanced}]\n",
    "test_feature_sets_balanced_merged = [{'name': 'merge', 'features': style_content_test_balanced}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0c764d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_merged_balanced = {'model' : lr_style_content_balanced, 'scaler': lr_style_content_balanced_scaler}\n",
    "nb_merged_balanced = {'model' : nb_style_content_balanced, 'scaler': nb_style_content_balanced_scaler}\n",
    "\n",
    "merged_models_balanced = [{'name' : 'lr', 'features' : 'merge', 'model' : lr_merged_balanced},\n",
    "                          {'name' : 'dt', 'features' : 'merge', 'model' : dt_style_content_balanced},\n",
    "                          {'name' : 'rf', 'features' : 'merge', 'model' : rf_style_content_balanced},\n",
    "                          {'name' : 'gb', 'features' : 'merge', 'model' : gb_style_content_balanced},\n",
    "                          {'name' : 'nb', 'features' : 'merge', 'model' : nb_merged_balanced}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e86b752c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stacking_balanced_merged = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2afbfb",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "556ed9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_clf = ml.train_stacked_models(merged_models_balanced, train_feature_sets_balanced_merged, style_train_balanced['target'], exclude_models=['dt', 'nb'], append_features=False)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_balanced, test_feature_sets_balanced_merged, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb'], append_features=False, result_row_name=\"Algorithms: lr, rf, gb merged, with LogisticRegression\")\n",
    "results_stacking_balanced_merged = pd.concat([results_stacking_balanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_balanced, train_feature_sets_balanced_merged, style_train_balanced['target'], exclude_models=['dt', 'nb', 'lr'], append_features=False)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_balanced, test_feature_sets_balanced_merged, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'lr'], append_features=False, result_row_name=\"Algorithms: rf, gb merged, with LogisticRegression\")\n",
    "results_stacking_balanced_merged = pd.concat([results_stacking_balanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_balanced, train_feature_sets_balanced_merged, style_train_balanced['target'], exclude_models=['dt', 'nb', 'rf'], append_features=False)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_balanced, test_feature_sets_balanced_merged, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'rf'], append_features=False, result_row_name=\"Algorithms: lr, gb merged, with LogisticRegression\")\n",
    "results_stacking_balanced_merged = pd.concat([results_stacking_balanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_balanced, train_feature_sets_balanced_merged, style_train_balanced['target'], exclude_models=['dt', 'nb', 'gb'], append_features=False)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_balanced, test_feature_sets_balanced_merged, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb'], append_features=False, result_row_name=\"Algorithms: rf, lr merged, with LogisticRegression\")\n",
    "results_stacking_balanced_merged = pd.concat([results_stacking_balanced_merged, stacked_preds['results']])\n",
    "\n",
    "# Append features\n",
    "stacked_clf = ml.train_stacked_models(merged_models_balanced, train_feature_sets_balanced_merged, style_train_balanced['target'], exclude_models=['dt', 'nb'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_balanced, test_feature_sets_balanced_merged, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb'], append_features=True, result_row_name=\"Algorithms: lr, rf, gb merged, with LogisticRegression (with appended features)\")\n",
    "results_stacking_balanced_merged = pd.concat([results_stacking_balanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_balanced, train_feature_sets_balanced_merged, style_train_balanced['target'], exclude_models=['dt', 'nb', 'lr'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_balanced, test_feature_sets_balanced_merged, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'lr'], append_features=True, result_row_name=\"Algorithms: rf, gb merged, with LogisticRegression (with appended features)\")\n",
    "results_stacking_balanced_merged = pd.concat([results_stacking_balanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_balanced, train_feature_sets_balanced_merged, style_train_balanced['target'], exclude_models=['dt', 'nb', 'rf'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_balanced, test_feature_sets_balanced_merged, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'rf'], append_features=True, result_row_name=\"Algorithms: lr, gb merged, with LogisticRegression (with appended features)\")\n",
    "results_stacking_balanced_merged = pd.concat([results_stacking_balanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_balanced, train_feature_sets_balanced_merged, style_train_balanced['target'], exclude_models=['dt', 'nb', 'gb'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_balanced, test_feature_sets_balanced_merged, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb'], append_features=True, result_row_name=\"Algorithms: rf, lr merged, with LogisticRegression (with appended features)\")\n",
    "results_stacking_balanced_merged = pd.concat([results_stacking_balanced_merged, stacked_preds['results']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c4f4bf",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b772f8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_clf = ml.train_stacked_models(merged_models_balanced, train_feature_sets_balanced_merged, style_train_balanced['target'], final_classifier=rf, exclude_models=['dt', 'nb'], append_features=False)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_balanced, test_feature_sets_balanced_merged, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb'], append_features=False, result_row_name=\"Algorithms: lr, rf, gb merged, with RandomForestClassifier\")\n",
    "results_stacking_balanced_merged = pd.concat([results_stacking_balanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_balanced, train_feature_sets_balanced_merged, style_train_balanced['target'], final_classifier=rf, exclude_models=['dt', 'nb', 'lr'], append_features=False)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_balanced, test_feature_sets_balanced_merged, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'lr'], append_features=False, result_row_name=\"Algorithms: rf, gb merged, with RandomForestClassifier\")\n",
    "results_stacking_balanced_merged = pd.concat([results_stacking_balanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_balanced, train_feature_sets_balanced_merged, style_train_balanced['target'], final_classifier=rf, exclude_models=['dt', 'nb', 'rf'], append_features=False)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_balanced, test_feature_sets_balanced_merged, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'rf'], append_features=False, result_row_name=\"Algorithms: lr, gb merged, with RandomForestClassifier\")\n",
    "results_stacking_balanced_merged = pd.concat([results_stacking_balanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_balanced, train_feature_sets_balanced_merged, style_train_balanced['target'], final_classifier=rf, exclude_models=['dt', 'nb', 'gb'], append_features=False)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_balanced, test_feature_sets_balanced_merged, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb'], append_features=False, result_row_name=\"Algorithms: rf, lr merged, with RandomForestClassifier\")\n",
    "results_stacking_balanced_merged = pd.concat([results_stacking_balanced_merged, stacked_preds['results']])\n",
    "\n",
    "# Append features\n",
    "stacked_clf = ml.train_stacked_models(merged_models_balanced, train_feature_sets_balanced_merged, style_train_balanced['target'], final_classifier=rf, exclude_models=['dt', 'nb'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_balanced, test_feature_sets_balanced_merged, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb'], append_features=True, result_row_name=\"Algorithms: lr, rf, gb merged, with RandomForestClassifier (with appended features)\")\n",
    "results_stacking_balanced_merged = pd.concat([results_stacking_balanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_balanced, train_feature_sets_balanced_merged, style_train_balanced['target'], final_classifier=rf, exclude_models=['dt', 'nb', 'lr'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_balanced, test_feature_sets_balanced_merged, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'lr'], append_features=True, result_row_name=\"Algorithms: rf, gb merged, with RandomForestClassifier (with appended features)\")\n",
    "results_stacking_balanced_merged = pd.concat([results_stacking_balanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_balanced, train_feature_sets_balanced_merged, style_train_balanced['target'], final_classifier=rf, exclude_models=['dt', 'nb', 'rf'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_balanced, test_feature_sets_balanced_merged, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'rf'], append_features=True, result_row_name=\"Algorithms: lr, gb merged, with RandomForestClassifier (with appended features)\")\n",
    "results_stacking_balanced_merged = pd.concat([results_stacking_balanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_balanced, train_feature_sets_balanced_merged, style_train_balanced['target'], final_classifier=rf, exclude_models=['dt', 'nb', 'gb'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_balanced, test_feature_sets_balanced_merged, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb'], append_features=True, result_row_name=\"Algorithms: rf, lr merged, with RandomForestClassifier (with appended features)\")\n",
    "results_stacking_balanced_merged = pd.concat([results_stacking_balanced_merged, stacked_preds['results']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11ebbf7",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5a689a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_clf = ml.train_stacked_models(merged_models_balanced, train_feature_sets_balanced_merged, style_train_balanced['target'], final_classifier=gb, exclude_models=['dt', 'nb'], append_features=False)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_balanced, test_feature_sets_balanced_merged, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb'], append_features=False, result_row_name=\"Algorithms: lr, rf, gb merged, with GradientBoostingClassifier\")\n",
    "results_stacking_balanced_merged = pd.concat([results_stacking_balanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_balanced, train_feature_sets_balanced_merged, style_train_balanced['target'], final_classifier=gb, exclude_models=['dt', 'nb', 'lr'], append_features=False)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_balanced, test_feature_sets_balanced_merged, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'lr'], append_features=False, result_row_name=\"Algorithms: rf, gb merged, with GradientBoostingClassifier\")\n",
    "results_stacking_balanced_merged = pd.concat([results_stacking_balanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_balanced, train_feature_sets_balanced_merged, style_train_balanced['target'], final_classifier=gb, exclude_models=['dt', 'nb', 'rf'], append_features=False)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_balanced, test_feature_sets_balanced_merged, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'rf'], append_features=False, result_row_name=\"Algorithms: lr, gb merged, with GradientBoostingClassifier\")\n",
    "results_stacking_balanced_merged = pd.concat([results_stacking_balanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_balanced, train_feature_sets_balanced_merged, style_train_balanced['target'], final_classifier=gb, exclude_models=['dt', 'nb', 'gb'], append_features=False)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_balanced, test_feature_sets_balanced_merged, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb'], append_features=False, result_row_name=\"Algorithms: rf, lr merged, with GradientBoostingClassifier\")\n",
    "results_stacking_balanced_merged = pd.concat([results_stacking_balanced_merged, stacked_preds['results']])\n",
    "\n",
    "# Append features\n",
    "stacked_clf = ml.train_stacked_models(merged_models_balanced, train_feature_sets_balanced_merged, style_train_balanced['target'], final_classifier=gb, exclude_models=['dt', 'nb'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_balanced, test_feature_sets_balanced_merged, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb'], append_features=True, result_row_name=\"Algorithms: lr, rf, gb merged, with GradientBoostingClassifier (with appended features)\")\n",
    "results_stacking_balanced_merged = pd.concat([results_stacking_balanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_balanced, train_feature_sets_balanced_merged, style_train_balanced['target'], final_classifier=gb, exclude_models=['dt', 'nb', 'lr'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_balanced, test_feature_sets_balanced_merged, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'lr'], append_features=True, result_row_name=\"Algorithms: rf, gb merged, with GradientBoostingClassifier (with appended features)\")\n",
    "results_stacking_balanced_merged = pd.concat([results_stacking_balanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_balanced, train_feature_sets_balanced_merged, style_train_balanced['target'], final_classifier=gb, exclude_models=['dt', 'nb', 'rf'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_balanced, test_feature_sets_balanced_merged, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'rf'], append_features=True, result_row_name=\"Algorithms: lr, gb merged, with GradientBoostingClassifier (with appended features)\")\n",
    "results_stacking_balanced_merged = pd.concat([results_stacking_balanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_balanced, train_feature_sets_balanced_merged, style_train_balanced['target'], final_classifier=gb, exclude_models=['dt', 'nb', 'gb'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_balanced, test_feature_sets_balanced_merged, style_test_balanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb'], append_features=True, result_row_name=\"Algorithms: rf, lr merged, with GradientBoostingClassifier (with appended features)\")\n",
    "results_stacking_balanced_merged = pd.concat([results_stacking_balanced_merged, stacked_preds['results']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9ca845f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>Area Under ROC Curve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, rf, gb merged, with LogisticRegression</th>\n",
       "      <td>0.974777</td>\n",
       "      <td>0.966197</td>\n",
       "      <td>0.985632</td>\n",
       "      <td>0.975818</td>\n",
       "      <td>0.036810</td>\n",
       "      <td>0.014368</td>\n",
       "      <td>0.996747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, gb merged, with LogisticRegression</th>\n",
       "      <td>0.971810</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>0.985632</td>\n",
       "      <td>0.973050</td>\n",
       "      <td>0.042945</td>\n",
       "      <td>0.014368</td>\n",
       "      <td>0.995355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, gb merged, with LogisticRegression</th>\n",
       "      <td>0.973294</td>\n",
       "      <td>0.966102</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.036810</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.997144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, lr merged, with LogisticRegression</th>\n",
       "      <td>0.971810</td>\n",
       "      <td>0.963380</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.039877</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.996421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, rf, gb merged, with LogisticRegression (with appended features)</th>\n",
       "      <td>0.955490</td>\n",
       "      <td>0.946629</td>\n",
       "      <td>0.968391</td>\n",
       "      <td>0.957386</td>\n",
       "      <td>0.058282</td>\n",
       "      <td>0.031609</td>\n",
       "      <td>0.975848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, gb merged, with LogisticRegression (with appended features)</th>\n",
       "      <td>0.955490</td>\n",
       "      <td>0.946629</td>\n",
       "      <td>0.968391</td>\n",
       "      <td>0.957386</td>\n",
       "      <td>0.058282</td>\n",
       "      <td>0.031609</td>\n",
       "      <td>0.974076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, gb merged, with LogisticRegression (with appended features)</th>\n",
       "      <td>0.958457</td>\n",
       "      <td>0.951977</td>\n",
       "      <td>0.968391</td>\n",
       "      <td>0.960114</td>\n",
       "      <td>0.052147</td>\n",
       "      <td>0.031609</td>\n",
       "      <td>0.973186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, lr merged, with LogisticRegression (with appended features)</th>\n",
       "      <td>0.951039</td>\n",
       "      <td>0.943662</td>\n",
       "      <td>0.962644</td>\n",
       "      <td>0.953058</td>\n",
       "      <td>0.061350</td>\n",
       "      <td>0.037356</td>\n",
       "      <td>0.973891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, rf, gb merged, with RandomForestClassifier</th>\n",
       "      <td>0.965875</td>\n",
       "      <td>0.947658</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.967651</td>\n",
       "      <td>0.058282</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.995394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, gb merged, with RandomForestClassifier</th>\n",
       "      <td>0.965875</td>\n",
       "      <td>0.960340</td>\n",
       "      <td>0.974138</td>\n",
       "      <td>0.967190</td>\n",
       "      <td>0.042945</td>\n",
       "      <td>0.025862</td>\n",
       "      <td>0.996245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, gb merged, with RandomForestClassifier</th>\n",
       "      <td>0.959941</td>\n",
       "      <td>0.937330</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.962238</td>\n",
       "      <td>0.070552</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.994980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, lr merged, with RandomForestClassifier</th>\n",
       "      <td>0.952522</td>\n",
       "      <td>0.929348</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.955307</td>\n",
       "      <td>0.079755</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.990524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, rf, gb merged, with RandomForestClassifier (with appended features)</th>\n",
       "      <td>0.973294</td>\n",
       "      <td>0.963483</td>\n",
       "      <td>0.985632</td>\n",
       "      <td>0.974432</td>\n",
       "      <td>0.039877</td>\n",
       "      <td>0.014368</td>\n",
       "      <td>0.995535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, gb merged, with RandomForestClassifier (with appended features)</th>\n",
       "      <td>0.964392</td>\n",
       "      <td>0.960227</td>\n",
       "      <td>0.971264</td>\n",
       "      <td>0.965714</td>\n",
       "      <td>0.042945</td>\n",
       "      <td>0.028736</td>\n",
       "      <td>0.995610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, gb merged, with RandomForestClassifier (with appended features)</th>\n",
       "      <td>0.970326</td>\n",
       "      <td>0.958101</td>\n",
       "      <td>0.985632</td>\n",
       "      <td>0.971671</td>\n",
       "      <td>0.046012</td>\n",
       "      <td>0.014368</td>\n",
       "      <td>0.995152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, lr merged, with RandomForestClassifier (with appended features)</th>\n",
       "      <td>0.970326</td>\n",
       "      <td>0.958101</td>\n",
       "      <td>0.985632</td>\n",
       "      <td>0.971671</td>\n",
       "      <td>0.046012</td>\n",
       "      <td>0.014368</td>\n",
       "      <td>0.995333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, rf, gb merged, with GradientBoostingClassifier</th>\n",
       "      <td>0.971810</td>\n",
       "      <td>0.966006</td>\n",
       "      <td>0.979885</td>\n",
       "      <td>0.972896</td>\n",
       "      <td>0.036810</td>\n",
       "      <td>0.020115</td>\n",
       "      <td>0.996307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, gb merged, with GradientBoostingClassifier</th>\n",
       "      <td>0.961424</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.962751</td>\n",
       "      <td>0.042945</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.994491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, gb merged, with GradientBoostingClassifier</th>\n",
       "      <td>0.962908</td>\n",
       "      <td>0.944904</td>\n",
       "      <td>0.985632</td>\n",
       "      <td>0.964838</td>\n",
       "      <td>0.061350</td>\n",
       "      <td>0.014368</td>\n",
       "      <td>0.995192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, lr merged, with GradientBoostingClassifier</th>\n",
       "      <td>0.955490</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>0.974138</td>\n",
       "      <td>0.957627</td>\n",
       "      <td>0.064417</td>\n",
       "      <td>0.025862</td>\n",
       "      <td>0.992547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, rf, gb merged, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.976261</td>\n",
       "      <td>0.977011</td>\n",
       "      <td>0.977011</td>\n",
       "      <td>0.977011</td>\n",
       "      <td>0.024540</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>0.995804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, gb merged, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.977745</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.027607</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.996589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, gb merged, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.979228</td>\n",
       "      <td>0.971751</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.980057</td>\n",
       "      <td>0.030675</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.996668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, lr merged, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.976261</td>\n",
       "      <td>0.971591</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.977143</td>\n",
       "      <td>0.030675</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.996342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Accuracy  Precision  \\\n",
       "Algorithms: lr, rf, gb merged, with LogisticReg...  0.974777   0.966197   \n",
       "Algorithms: rf, gb merged, with LogisticRegression  0.971810   0.960784   \n",
       "Algorithms: lr, gb merged, with LogisticRegression  0.973294   0.966102   \n",
       "Algorithms: rf, lr merged, with LogisticRegression  0.971810   0.963380   \n",
       "Algorithms: lr, rf, gb merged, with LogisticReg...  0.955490   0.946629   \n",
       "Algorithms: rf, gb merged, with LogisticRegress...  0.955490   0.946629   \n",
       "Algorithms: lr, gb merged, with LogisticRegress...  0.958457   0.951977   \n",
       "Algorithms: rf, lr merged, with LogisticRegress...  0.951039   0.943662   \n",
       "Algorithms: lr, rf, gb merged, with RandomFores...  0.965875   0.947658   \n",
       "Algorithms: rf, gb merged, with RandomForestCla...  0.965875   0.960340   \n",
       "Algorithms: lr, gb merged, with RandomForestCla...  0.959941   0.937330   \n",
       "Algorithms: rf, lr merged, with RandomForestCla...  0.952522   0.929348   \n",
       "Algorithms: lr, rf, gb merged, with RandomFores...  0.973294   0.963483   \n",
       "Algorithms: rf, gb merged, with RandomForestCla...  0.964392   0.960227   \n",
       "Algorithms: lr, gb merged, with RandomForestCla...  0.970326   0.958101   \n",
       "Algorithms: rf, lr merged, with RandomForestCla...  0.970326   0.958101   \n",
       "Algorithms: lr, rf, gb merged, with GradientBoo...  0.971810   0.966006   \n",
       "Algorithms: rf, gb merged, with GradientBoostin...  0.961424   0.960000   \n",
       "Algorithms: lr, gb merged, with GradientBoostin...  0.962908   0.944904   \n",
       "Algorithms: rf, lr merged, with GradientBoostin...  0.955490   0.941667   \n",
       "Algorithms: lr, rf, gb merged, with GradientBoo...  0.976261   0.977011   \n",
       "Algorithms: rf, gb merged, with GradientBoostin...  0.977745   0.974359   \n",
       "Algorithms: lr, gb merged, with GradientBoostin...  0.979228   0.971751   \n",
       "Algorithms: rf, lr merged, with GradientBoostin...  0.976261   0.971591   \n",
       "\n",
       "                                                      Recall  F1 Score  \\\n",
       "Algorithms: lr, rf, gb merged, with LogisticReg...  0.985632  0.975818   \n",
       "Algorithms: rf, gb merged, with LogisticRegression  0.985632  0.973050   \n",
       "Algorithms: lr, gb merged, with LogisticRegression  0.982759  0.974359   \n",
       "Algorithms: rf, lr merged, with LogisticRegression  0.982759  0.972973   \n",
       "Algorithms: lr, rf, gb merged, with LogisticReg...  0.968391  0.957386   \n",
       "Algorithms: rf, gb merged, with LogisticRegress...  0.968391  0.957386   \n",
       "Algorithms: lr, gb merged, with LogisticRegress...  0.968391  0.960114   \n",
       "Algorithms: rf, lr merged, with LogisticRegress...  0.962644  0.953058   \n",
       "Algorithms: lr, rf, gb merged, with RandomFores...  0.988506  0.967651   \n",
       "Algorithms: rf, gb merged, with RandomForestCla...  0.974138  0.967190   \n",
       "Algorithms: lr, gb merged, with RandomForestCla...  0.988506  0.962238   \n",
       "Algorithms: rf, lr merged, with RandomForestCla...  0.982759  0.955307   \n",
       "Algorithms: lr, rf, gb merged, with RandomFores...  0.985632  0.974432   \n",
       "Algorithms: rf, gb merged, with RandomForestCla...  0.971264  0.965714   \n",
       "Algorithms: lr, gb merged, with RandomForestCla...  0.985632  0.971671   \n",
       "Algorithms: rf, lr merged, with RandomForestCla...  0.985632  0.971671   \n",
       "Algorithms: lr, rf, gb merged, with GradientBoo...  0.979885  0.972896   \n",
       "Algorithms: rf, gb merged, with GradientBoostin...  0.965517  0.962751   \n",
       "Algorithms: lr, gb merged, with GradientBoostin...  0.985632  0.964838   \n",
       "Algorithms: rf, lr merged, with GradientBoostin...  0.974138  0.957627   \n",
       "Algorithms: lr, rf, gb merged, with GradientBoo...  0.977011  0.977011   \n",
       "Algorithms: rf, gb merged, with GradientBoostin...  0.982759  0.978541   \n",
       "Algorithms: lr, gb merged, with GradientBoostin...  0.988506  0.980057   \n",
       "Algorithms: rf, lr merged, with GradientBoostin...  0.982759  0.977143   \n",
       "\n",
       "                                                    False Positive Rate  \\\n",
       "Algorithms: lr, rf, gb merged, with LogisticReg...             0.036810   \n",
       "Algorithms: rf, gb merged, with LogisticRegression             0.042945   \n",
       "Algorithms: lr, gb merged, with LogisticRegression             0.036810   \n",
       "Algorithms: rf, lr merged, with LogisticRegression             0.039877   \n",
       "Algorithms: lr, rf, gb merged, with LogisticReg...             0.058282   \n",
       "Algorithms: rf, gb merged, with LogisticRegress...             0.058282   \n",
       "Algorithms: lr, gb merged, with LogisticRegress...             0.052147   \n",
       "Algorithms: rf, lr merged, with LogisticRegress...             0.061350   \n",
       "Algorithms: lr, rf, gb merged, with RandomFores...             0.058282   \n",
       "Algorithms: rf, gb merged, with RandomForestCla...             0.042945   \n",
       "Algorithms: lr, gb merged, with RandomForestCla...             0.070552   \n",
       "Algorithms: rf, lr merged, with RandomForestCla...             0.079755   \n",
       "Algorithms: lr, rf, gb merged, with RandomFores...             0.039877   \n",
       "Algorithms: rf, gb merged, with RandomForestCla...             0.042945   \n",
       "Algorithms: lr, gb merged, with RandomForestCla...             0.046012   \n",
       "Algorithms: rf, lr merged, with RandomForestCla...             0.046012   \n",
       "Algorithms: lr, rf, gb merged, with GradientBoo...             0.036810   \n",
       "Algorithms: rf, gb merged, with GradientBoostin...             0.042945   \n",
       "Algorithms: lr, gb merged, with GradientBoostin...             0.061350   \n",
       "Algorithms: rf, lr merged, with GradientBoostin...             0.064417   \n",
       "Algorithms: lr, rf, gb merged, with GradientBoo...             0.024540   \n",
       "Algorithms: rf, gb merged, with GradientBoostin...             0.027607   \n",
       "Algorithms: lr, gb merged, with GradientBoostin...             0.030675   \n",
       "Algorithms: rf, lr merged, with GradientBoostin...             0.030675   \n",
       "\n",
       "                                                    False Negative Rate  \\\n",
       "Algorithms: lr, rf, gb merged, with LogisticReg...             0.014368   \n",
       "Algorithms: rf, gb merged, with LogisticRegression             0.014368   \n",
       "Algorithms: lr, gb merged, with LogisticRegression             0.017241   \n",
       "Algorithms: rf, lr merged, with LogisticRegression             0.017241   \n",
       "Algorithms: lr, rf, gb merged, with LogisticReg...             0.031609   \n",
       "Algorithms: rf, gb merged, with LogisticRegress...             0.031609   \n",
       "Algorithms: lr, gb merged, with LogisticRegress...             0.031609   \n",
       "Algorithms: rf, lr merged, with LogisticRegress...             0.037356   \n",
       "Algorithms: lr, rf, gb merged, with RandomFores...             0.011494   \n",
       "Algorithms: rf, gb merged, with RandomForestCla...             0.025862   \n",
       "Algorithms: lr, gb merged, with RandomForestCla...             0.011494   \n",
       "Algorithms: rf, lr merged, with RandomForestCla...             0.017241   \n",
       "Algorithms: lr, rf, gb merged, with RandomFores...             0.014368   \n",
       "Algorithms: rf, gb merged, with RandomForestCla...             0.028736   \n",
       "Algorithms: lr, gb merged, with RandomForestCla...             0.014368   \n",
       "Algorithms: rf, lr merged, with RandomForestCla...             0.014368   \n",
       "Algorithms: lr, rf, gb merged, with GradientBoo...             0.020115   \n",
       "Algorithms: rf, gb merged, with GradientBoostin...             0.034483   \n",
       "Algorithms: lr, gb merged, with GradientBoostin...             0.014368   \n",
       "Algorithms: rf, lr merged, with GradientBoostin...             0.025862   \n",
       "Algorithms: lr, rf, gb merged, with GradientBoo...             0.022989   \n",
       "Algorithms: rf, gb merged, with GradientBoostin...             0.017241   \n",
       "Algorithms: lr, gb merged, with GradientBoostin...             0.011494   \n",
       "Algorithms: rf, lr merged, with GradientBoostin...             0.017241   \n",
       "\n",
       "                                                    Area Under ROC Curve  \n",
       "Algorithms: lr, rf, gb merged, with LogisticReg...              0.996747  \n",
       "Algorithms: rf, gb merged, with LogisticRegression              0.995355  \n",
       "Algorithms: lr, gb merged, with LogisticRegression              0.997144  \n",
       "Algorithms: rf, lr merged, with LogisticRegression              0.996421  \n",
       "Algorithms: lr, rf, gb merged, with LogisticReg...              0.975848  \n",
       "Algorithms: rf, gb merged, with LogisticRegress...              0.974076  \n",
       "Algorithms: lr, gb merged, with LogisticRegress...              0.973186  \n",
       "Algorithms: rf, lr merged, with LogisticRegress...              0.973891  \n",
       "Algorithms: lr, rf, gb merged, with RandomFores...              0.995394  \n",
       "Algorithms: rf, gb merged, with RandomForestCla...              0.996245  \n",
       "Algorithms: lr, gb merged, with RandomForestCla...              0.994980  \n",
       "Algorithms: rf, lr merged, with RandomForestCla...              0.990524  \n",
       "Algorithms: lr, rf, gb merged, with RandomFores...              0.995535  \n",
       "Algorithms: rf, gb merged, with RandomForestCla...              0.995610  \n",
       "Algorithms: lr, gb merged, with RandomForestCla...              0.995152  \n",
       "Algorithms: rf, lr merged, with RandomForestCla...              0.995333  \n",
       "Algorithms: lr, rf, gb merged, with GradientBoo...              0.996307  \n",
       "Algorithms: rf, gb merged, with GradientBoostin...              0.994491  \n",
       "Algorithms: lr, gb merged, with GradientBoostin...              0.995192  \n",
       "Algorithms: rf, lr merged, with GradientBoostin...              0.992547  \n",
       "Algorithms: lr, rf, gb merged, with GradientBoo...              0.995804  \n",
       "Algorithms: rf, gb merged, with GradientBoostin...              0.996589  \n",
       "Algorithms: lr, gb merged, with GradientBoostin...              0.996668  \n",
       "Algorithms: rf, lr merged, with GradientBoostin...              0.996342  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_stacking_balanced_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c386719d",
   "metadata": {},
   "source": [
    "In general, the addition of the initial features on the level 1 classifier gives better results, but even the best performance was worse than the previous best.\n",
    "\n",
    "This is likely because the level 0 classifiers were more specialized compared to training on both feature sets separately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef38cbc",
   "metadata": {},
   "source": [
    "The top 10 results will be added to the dataset for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0674bc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stacking_balanced_best = pd.concat([results_stacking_balanced_best, results_stacking_balanced_merged.sort_values(by=['F1 Score'], ascending = [False]).head(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ae8f4eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stacking_balanced_full = pd.concat([results_stacking_balanced_full, results_stacking_balanced_merged])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "95ee2de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>Area Under ROC Curve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, gb, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.980712</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>0.991379</td>\n",
       "      <td>0.981508</td>\n",
       "      <td>0.030675</td>\n",
       "      <td>0.008621</td>\n",
       "      <td>0.996783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, lr, gb, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.980712</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>0.991379</td>\n",
       "      <td>0.981508</td>\n",
       "      <td>0.030675</td>\n",
       "      <td>0.008621</td>\n",
       "      <td>0.996598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: all, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.979228</td>\n",
       "      <td>0.969101</td>\n",
       "      <td>0.991379</td>\n",
       "      <td>0.980114</td>\n",
       "      <td>0.033742</td>\n",
       "      <td>0.008621</td>\n",
       "      <td>0.996201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, gb, with GradientBoostingClassifier</th>\n",
       "      <td>0.979228</td>\n",
       "      <td>0.969101</td>\n",
       "      <td>0.991379</td>\n",
       "      <td>0.980114</td>\n",
       "      <td>0.033742</td>\n",
       "      <td>0.008621</td>\n",
       "      <td>0.996307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, gb merged, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.979228</td>\n",
       "      <td>0.971751</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.980057</td>\n",
       "      <td>0.030675</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.996668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, lr, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.979228</td>\n",
       "      <td>0.971751</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.980057</td>\n",
       "      <td>0.030675</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.996342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Accuracy  Precision  \\\n",
       "Algorithms: lr, gb, with GradientBoostingClassi...  0.980712   0.971831   \n",
       "Algorithms: rf, lr, gb, with GradientBoostingCl...  0.980712   0.971831   \n",
       "Algorithms: all, with GradientBoostingClassifie...  0.979228   0.969101   \n",
       "Algorithms: lr, gb, with GradientBoostingClassi...  0.979228   0.969101   \n",
       "Algorithms: lr, gb merged, with GradientBoostin...  0.979228   0.971751   \n",
       "Algorithms: rf, lr, with GradientBoostingClassi...  0.979228   0.971751   \n",
       "\n",
       "                                                      Recall  F1 Score  \\\n",
       "Algorithms: lr, gb, with GradientBoostingClassi...  0.991379  0.981508   \n",
       "Algorithms: rf, lr, gb, with GradientBoostingCl...  0.991379  0.981508   \n",
       "Algorithms: all, with GradientBoostingClassifie...  0.991379  0.980114   \n",
       "Algorithms: lr, gb, with GradientBoostingClassi...  0.991379  0.980114   \n",
       "Algorithms: lr, gb merged, with GradientBoostin...  0.988506  0.980057   \n",
       "Algorithms: rf, lr, with GradientBoostingClassi...  0.988506  0.980057   \n",
       "\n",
       "                                                    False Positive Rate  \\\n",
       "Algorithms: lr, gb, with GradientBoostingClassi...             0.030675   \n",
       "Algorithms: rf, lr, gb, with GradientBoostingCl...             0.030675   \n",
       "Algorithms: all, with GradientBoostingClassifie...             0.033742   \n",
       "Algorithms: lr, gb, with GradientBoostingClassi...             0.033742   \n",
       "Algorithms: lr, gb merged, with GradientBoostin...             0.030675   \n",
       "Algorithms: rf, lr, with GradientBoostingClassi...             0.030675   \n",
       "\n",
       "                                                    False Negative Rate  \\\n",
       "Algorithms: lr, gb, with GradientBoostingClassi...             0.008621   \n",
       "Algorithms: rf, lr, gb, with GradientBoostingCl...             0.008621   \n",
       "Algorithms: all, with GradientBoostingClassifie...             0.008621   \n",
       "Algorithms: lr, gb, with GradientBoostingClassi...             0.008621   \n",
       "Algorithms: lr, gb merged, with GradientBoostin...             0.011494   \n",
       "Algorithms: rf, lr, with GradientBoostingClassi...             0.011494   \n",
       "\n",
       "                                                    Area Under ROC Curve  \n",
       "Algorithms: lr, gb, with GradientBoostingClassi...              0.996783  \n",
       "Algorithms: rf, lr, gb, with GradientBoostingCl...              0.996598  \n",
       "Algorithms: all, with GradientBoostingClassifie...              0.996201  \n",
       "Algorithms: lr, gb, with GradientBoostingClassi...              0.996307  \n",
       "Algorithms: lr, gb merged, with GradientBoostin...              0.996668  \n",
       "Algorithms: rf, lr, with GradientBoostingClassi...              0.996342  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_stacking_balanced_best.sort_values(by=['F1 Score'], ascending = [False]).head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5d1e28",
   "metadata": {},
   "source": [
    "## Imbalanced Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fb5c5a",
   "metadata": {},
   "source": [
    "#### Train Initial Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cf171aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature_sets_imbalanced = [{'name': 'style', 'features': style_train_imbalanced['features']}, {'name': 'word2vec', 'features': word2vec_train_imbalanced['features']}]\n",
    "test_feature_sets_imbalanced = [{'name': 'style', 'features': style_test_imbalanced['features']}, {'name': 'word2vec', 'features': word2vec_test_imbalanced['features']}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ae15b4bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stacking_models_imbalanced = ml.train_models(train_feature_sets_imbalanced, style_train_imbalanced['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1be2813",
   "metadata": {},
   "source": [
    "### Single-algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2ed7ff3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stacking_imbalanced_single = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35dffe2d",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "485e9f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], exclude_models=['dt', 'rf', 'gb', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'rf', 'gb', 'nb'])\n",
    "results_stacking_imbalanced_single = pd.concat([results_stacking_imbalanced_single, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], exclude_models=['lr', 'rf', 'gb', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['lr', 'rf', 'gb', 'nb'])\n",
    "results_stacking_imbalanced_single = pd.concat([results_stacking_imbalanced_single, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], exclude_models=['lr', 'dt', 'gb', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['lr', 'dt', 'gb', 'nb'])\n",
    "results_stacking_imbalanced_single = pd.concat([results_stacking_imbalanced_single, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], exclude_models=['lr', 'dt', 'rf', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['lr', 'dt', 'rf', 'nb'])\n",
    "results_stacking_imbalanced_single = pd.concat([results_stacking_imbalanced_single, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], exclude_models=['lr', 'dt', 'rf', 'gb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['lr', 'dt', 'rf', 'gb'])\n",
    "results_stacking_imbalanced_single = pd.concat([results_stacking_imbalanced_single, stacked_preds['results']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4326cd1",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6db39d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=rf, exclude_models=['dt', 'rf', 'gb', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'rf', 'gb', 'nb'])\n",
    "results_stacking_imbalanced_single = pd.concat([results_stacking_imbalanced_single, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=rf, exclude_models=['lr', 'rf', 'gb', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['lr', 'rf', 'gb', 'nb'])\n",
    "results_stacking_imbalanced_single = pd.concat([results_stacking_imbalanced_single, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=rf, exclude_models=['lr', 'dt', 'gb', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['lr', 'dt', 'gb', 'nb'])\n",
    "results_stacking_imbalanced_single = pd.concat([results_stacking_imbalanced_single, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=rf, exclude_models=['lr', 'dt', 'rf', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['lr', 'dt', 'rf', 'nb'])\n",
    "results_stacking_imbalanced_single = pd.concat([results_stacking_imbalanced_single, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=rf, exclude_models=['lr', 'dt', 'rf', 'gb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['lr', 'dt', 'rf', 'gb'])\n",
    "results_stacking_imbalanced_single = pd.concat([results_stacking_imbalanced_single, stacked_preds['results']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f835fa",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0216ce62",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=gb, exclude_models=['dt', 'rf', 'gb', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'rf', 'gb', 'nb'])\n",
    "results_stacking_imbalanced_single = pd.concat([results_stacking_imbalanced_single, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=gb, exclude_models=['lr', 'rf', 'gb', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['lr', 'rf', 'gb', 'nb'])\n",
    "results_stacking_imbalanced_single = pd.concat([results_stacking_imbalanced_single, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=gb, exclude_models=['lr', 'dt', 'gb', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['lr', 'dt', 'gb', 'nb'])\n",
    "results_stacking_imbalanced_single = pd.concat([results_stacking_imbalanced_single, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=gb, exclude_models=['lr', 'dt', 'rf', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['lr', 'dt', 'rf', 'nb'])\n",
    "results_stacking_imbalanced_single = pd.concat([results_stacking_imbalanced_single, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=gb, exclude_models=['lr', 'dt', 'rf', 'gb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['lr', 'dt', 'rf', 'gb'])\n",
    "results_stacking_imbalanced_single = pd.concat([results_stacking_imbalanced_single, stacked_preds['results']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8bf20b33",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>Area Under ROC Curve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, with LogisticRegression</th>\n",
       "      <td>0.986757</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.923795</td>\n",
       "      <td>0.006517</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.992668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: dt, with LogisticRegression</th>\n",
       "      <td>0.981351</td>\n",
       "      <td>0.915309</td>\n",
       "      <td>0.867284</td>\n",
       "      <td>0.890650</td>\n",
       "      <td>0.007701</td>\n",
       "      <td>0.132716</td>\n",
       "      <td>0.983157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, with LogisticRegression</th>\n",
       "      <td>0.982703</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.864198</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.005924</td>\n",
       "      <td>0.135802</td>\n",
       "      <td>0.993216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: gb, with LogisticRegression</th>\n",
       "      <td>0.989730</td>\n",
       "      <td>0.944099</td>\n",
       "      <td>0.938272</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.005332</td>\n",
       "      <td>0.061728</td>\n",
       "      <td>0.995922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: nb, with LogisticRegression</th>\n",
       "      <td>0.968649</td>\n",
       "      <td>0.879562</td>\n",
       "      <td>0.743827</td>\n",
       "      <td>0.806020</td>\n",
       "      <td>0.009775</td>\n",
       "      <td>0.256173</td>\n",
       "      <td>0.984317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, with RandomForestClassifier</th>\n",
       "      <td>0.987027</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.922840</td>\n",
       "      <td>0.925697</td>\n",
       "      <td>0.006813</td>\n",
       "      <td>0.077160</td>\n",
       "      <td>0.993107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: dt, with RandomForestClassifier</th>\n",
       "      <td>0.980270</td>\n",
       "      <td>0.928328</td>\n",
       "      <td>0.839506</td>\n",
       "      <td>0.881686</td>\n",
       "      <td>0.006220</td>\n",
       "      <td>0.160494</td>\n",
       "      <td>0.985262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, with RandomForestClassifier</th>\n",
       "      <td>0.982703</td>\n",
       "      <td>0.936242</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.897106</td>\n",
       "      <td>0.005628</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>0.994269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: gb, with RandomForestClassifier</th>\n",
       "      <td>0.989459</td>\n",
       "      <td>0.935780</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.940092</td>\n",
       "      <td>0.006220</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.997452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: nb, with RandomForestClassifier</th>\n",
       "      <td>0.974054</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.820988</td>\n",
       "      <td>0.847134</td>\n",
       "      <td>0.011256</td>\n",
       "      <td>0.179012</td>\n",
       "      <td>0.986173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, with GradientBoostingClassifier</th>\n",
       "      <td>0.985135</td>\n",
       "      <td>0.906344</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.916031</td>\n",
       "      <td>0.009182</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.992312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: dt, with GradientBoostingClassifier</th>\n",
       "      <td>0.980811</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>0.886035</td>\n",
       "      <td>0.006813</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.986403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, with GradientBoostingClassifier</th>\n",
       "      <td>0.981892</td>\n",
       "      <td>0.921311</td>\n",
       "      <td>0.867284</td>\n",
       "      <td>0.893482</td>\n",
       "      <td>0.007109</td>\n",
       "      <td>0.132716</td>\n",
       "      <td>0.994401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: gb, with GradientBoostingClassifier</th>\n",
       "      <td>0.986486</td>\n",
       "      <td>0.917683</td>\n",
       "      <td>0.929012</td>\n",
       "      <td>0.923313</td>\n",
       "      <td>0.007998</td>\n",
       "      <td>0.070988</td>\n",
       "      <td>0.997242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: nb, with GradientBoostingClassifier</th>\n",
       "      <td>0.973784</td>\n",
       "      <td>0.867314</td>\n",
       "      <td>0.827160</td>\n",
       "      <td>0.846761</td>\n",
       "      <td>0.012145</td>\n",
       "      <td>0.172840</td>\n",
       "      <td>0.988396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Accuracy  Precision  \\\n",
       "Algorithms: lr, with LogisticRegression          0.986757   0.931034   \n",
       "Algorithms: dt, with LogisticRegression          0.981351   0.915309   \n",
       "Algorithms: rf, with LogisticRegression          0.982703   0.933333   \n",
       "Algorithms: gb, with LogisticRegression          0.989730   0.944099   \n",
       "Algorithms: nb, with LogisticRegression          0.968649   0.879562   \n",
       "Algorithms: lr, with RandomForestClassifier      0.987027   0.928571   \n",
       "Algorithms: dt, with RandomForestClassifier      0.980270   0.928328   \n",
       "Algorithms: rf, with RandomForestClassifier      0.982703   0.936242   \n",
       "Algorithms: gb, with RandomForestClassifier      0.989459   0.935780   \n",
       "Algorithms: nb, with RandomForestClassifier      0.974054   0.875000   \n",
       "Algorithms: lr, with GradientBoostingClassifier  0.985135   0.906344   \n",
       "Algorithms: dt, with GradientBoostingClassifier  0.980811   0.923077   \n",
       "Algorithms: rf, with GradientBoostingClassifier  0.981892   0.921311   \n",
       "Algorithms: gb, with GradientBoostingClassifier  0.986486   0.917683   \n",
       "Algorithms: nb, with GradientBoostingClassifier  0.973784   0.867314   \n",
       "\n",
       "                                                   Recall  F1 Score  \\\n",
       "Algorithms: lr, with LogisticRegression          0.916667  0.923795   \n",
       "Algorithms: dt, with LogisticRegression          0.867284  0.890650   \n",
       "Algorithms: rf, with LogisticRegression          0.864198  0.897436   \n",
       "Algorithms: gb, with LogisticRegression          0.938272  0.941176   \n",
       "Algorithms: nb, with LogisticRegression          0.743827  0.806020   \n",
       "Algorithms: lr, with RandomForestClassifier      0.922840  0.925697   \n",
       "Algorithms: dt, with RandomForestClassifier      0.839506  0.881686   \n",
       "Algorithms: rf, with RandomForestClassifier      0.861111  0.897106   \n",
       "Algorithms: gb, with RandomForestClassifier      0.944444  0.940092   \n",
       "Algorithms: nb, with RandomForestClassifier      0.820988  0.847134   \n",
       "Algorithms: lr, with GradientBoostingClassifier  0.925926  0.916031   \n",
       "Algorithms: dt, with GradientBoostingClassifier  0.851852  0.886035   \n",
       "Algorithms: rf, with GradientBoostingClassifier  0.867284  0.893482   \n",
       "Algorithms: gb, with GradientBoostingClassifier  0.929012  0.923313   \n",
       "Algorithms: nb, with GradientBoostingClassifier  0.827160  0.846761   \n",
       "\n",
       "                                                 False Positive Rate  \\\n",
       "Algorithms: lr, with LogisticRegression                     0.006517   \n",
       "Algorithms: dt, with LogisticRegression                     0.007701   \n",
       "Algorithms: rf, with LogisticRegression                     0.005924   \n",
       "Algorithms: gb, with LogisticRegression                     0.005332   \n",
       "Algorithms: nb, with LogisticRegression                     0.009775   \n",
       "Algorithms: lr, with RandomForestClassifier                 0.006813   \n",
       "Algorithms: dt, with RandomForestClassifier                 0.006220   \n",
       "Algorithms: rf, with RandomForestClassifier                 0.005628   \n",
       "Algorithms: gb, with RandomForestClassifier                 0.006220   \n",
       "Algorithms: nb, with RandomForestClassifier                 0.011256   \n",
       "Algorithms: lr, with GradientBoostingClassifier             0.009182   \n",
       "Algorithms: dt, with GradientBoostingClassifier             0.006813   \n",
       "Algorithms: rf, with GradientBoostingClassifier             0.007109   \n",
       "Algorithms: gb, with GradientBoostingClassifier             0.007998   \n",
       "Algorithms: nb, with GradientBoostingClassifier             0.012145   \n",
       "\n",
       "                                                 False Negative Rate  \\\n",
       "Algorithms: lr, with LogisticRegression                     0.083333   \n",
       "Algorithms: dt, with LogisticRegression                     0.132716   \n",
       "Algorithms: rf, with LogisticRegression                     0.135802   \n",
       "Algorithms: gb, with LogisticRegression                     0.061728   \n",
       "Algorithms: nb, with LogisticRegression                     0.256173   \n",
       "Algorithms: lr, with RandomForestClassifier                 0.077160   \n",
       "Algorithms: dt, with RandomForestClassifier                 0.160494   \n",
       "Algorithms: rf, with RandomForestClassifier                 0.138889   \n",
       "Algorithms: gb, with RandomForestClassifier                 0.055556   \n",
       "Algorithms: nb, with RandomForestClassifier                 0.179012   \n",
       "Algorithms: lr, with GradientBoostingClassifier             0.074074   \n",
       "Algorithms: dt, with GradientBoostingClassifier             0.148148   \n",
       "Algorithms: rf, with GradientBoostingClassifier             0.132716   \n",
       "Algorithms: gb, with GradientBoostingClassifier             0.070988   \n",
       "Algorithms: nb, with GradientBoostingClassifier             0.172840   \n",
       "\n",
       "                                                 Area Under ROC Curve  \n",
       "Algorithms: lr, with LogisticRegression                      0.992668  \n",
       "Algorithms: dt, with LogisticRegression                      0.983157  \n",
       "Algorithms: rf, with LogisticRegression                      0.993216  \n",
       "Algorithms: gb, with LogisticRegression                      0.995922  \n",
       "Algorithms: nb, with LogisticRegression                      0.984317  \n",
       "Algorithms: lr, with RandomForestClassifier                  0.993107  \n",
       "Algorithms: dt, with RandomForestClassifier                  0.985262  \n",
       "Algorithms: rf, with RandomForestClassifier                  0.994269  \n",
       "Algorithms: gb, with RandomForestClassifier                  0.997452  \n",
       "Algorithms: nb, with RandomForestClassifier                  0.986173  \n",
       "Algorithms: lr, with GradientBoostingClassifier              0.992312  \n",
       "Algorithms: dt, with GradientBoostingClassifier              0.986403  \n",
       "Algorithms: rf, with GradientBoostingClassifier              0.994401  \n",
       "Algorithms: gb, with GradientBoostingClassifier              0.997242  \n",
       "Algorithms: nb, with GradientBoostingClassifier              0.988396  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_stacking_imbalanced_single"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80470bc3",
   "metadata": {},
   "source": [
    "The results were somewhat consistent with those of the imbalanced dataset. Stacking the Gradient Boosting classifiers from the two different feature sets achieved better performance than the merged dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "db737c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stacking_imbalanced_full = results_stacking_imbalanced_single.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bd461c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stacking_imbalanced_best = results_stacking_imbalanced_single.sort_values(by=['F1 Score'], ascending = [False]).head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec2738d",
   "metadata": {},
   "source": [
    "### Multi-algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ea7df94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stacking_imbalanced_multi = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62f9ca6",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1e0223b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], exclude_models=[])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=[], result_row_name=\"Algorithms: all, with LogisticRegression\")\n",
    "results_stacking_imbalanced_multi = pd.concat([results_stacking_imbalanced_multi, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], exclude_models=['dt', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb'])\n",
    "results_stacking_imbalanced_multi = pd.concat([results_stacking_imbalanced_multi, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], exclude_models=['dt', 'nb', 'lr'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'lr'])\n",
    "results_stacking_imbalanced_multi = pd.concat([results_stacking_imbalanced_multi, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], exclude_models=['dt', 'nb', 'rf'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'rf'])\n",
    "results_stacking_imbalanced_multi = pd.concat([results_stacking_imbalanced_multi, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], exclude_models=['dt', 'nb', 'gb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb'])\n",
    "results_stacking_imbalanced_multi = pd.concat([results_stacking_imbalanced_multi, stacked_preds['results']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7af8cb",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7b6008eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=rf, exclude_models=[])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=[], result_row_name=\"Algorithms: all, with RandomForestClassifier\")\n",
    "results_stacking_imbalanced_multi = pd.concat([results_stacking_imbalanced_multi, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=rf, exclude_models=['dt', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb'])\n",
    "results_stacking_imbalanced_multi = pd.concat([results_stacking_imbalanced_multi, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=rf, exclude_models=['dt', 'nb', 'lr'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'lr'])\n",
    "results_stacking_imbalanced_multi = pd.concat([results_stacking_imbalanced_multi, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=rf, exclude_models=['dt', 'nb', 'rf'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'rf'])\n",
    "results_stacking_imbalanced_multi = pd.concat([results_stacking_imbalanced_multi, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=rf, exclude_models=['dt', 'nb', 'gb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb'])\n",
    "results_stacking_imbalanced_multi = pd.concat([results_stacking_imbalanced_multi, stacked_preds['results']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c102a6",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6188f736",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=gb, exclude_models=[])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=[], result_row_name=\"Algorithms: all, with GradientBoostingClassifier\")\n",
    "results_stacking_imbalanced_multi = pd.concat([results_stacking_imbalanced_multi, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=gb, exclude_models=['dt', 'nb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb'])\n",
    "results_stacking_imbalanced_multi = pd.concat([results_stacking_imbalanced_multi, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=gb, exclude_models=['dt', 'nb', 'lr'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'lr'])\n",
    "results_stacking_imbalanced_multi = pd.concat([results_stacking_imbalanced_multi, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=gb, exclude_models=['dt', 'nb', 'rf'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'rf'])\n",
    "results_stacking_imbalanced_multi = pd.concat([results_stacking_imbalanced_multi, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=gb, exclude_models=['dt', 'nb', 'gb'])\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb'])\n",
    "results_stacking_imbalanced_multi = pd.concat([results_stacking_imbalanced_multi, stacked_preds['results']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8314c00c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>Area Under ROC Curve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Algorithms: all, with LogisticRegression</th>\n",
       "      <td>0.989459</td>\n",
       "      <td>0.943925</td>\n",
       "      <td>0.935185</td>\n",
       "      <td>0.939535</td>\n",
       "      <td>0.005332</td>\n",
       "      <td>0.064815</td>\n",
       "      <td>0.995641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, lr, gb, with LogisticRegression</th>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.947040</td>\n",
       "      <td>0.938272</td>\n",
       "      <td>0.942636</td>\n",
       "      <td>0.005036</td>\n",
       "      <td>0.061728</td>\n",
       "      <td>0.995882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, gb, with LogisticRegression</th>\n",
       "      <td>0.989189</td>\n",
       "      <td>0.940994</td>\n",
       "      <td>0.935185</td>\n",
       "      <td>0.938080</td>\n",
       "      <td>0.005628</td>\n",
       "      <td>0.064815</td>\n",
       "      <td>0.995323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, gb, with LogisticRegression</th>\n",
       "      <td>0.990270</td>\n",
       "      <td>0.947205</td>\n",
       "      <td>0.941358</td>\n",
       "      <td>0.944272</td>\n",
       "      <td>0.005036</td>\n",
       "      <td>0.058642</td>\n",
       "      <td>0.996256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, lr, with LogisticRegression</th>\n",
       "      <td>0.987838</td>\n",
       "      <td>0.937304</td>\n",
       "      <td>0.922840</td>\n",
       "      <td>0.930016</td>\n",
       "      <td>0.005924</td>\n",
       "      <td>0.077160</td>\n",
       "      <td>0.995168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: all, with RandomForestClassifier</th>\n",
       "      <td>0.991351</td>\n",
       "      <td>0.953416</td>\n",
       "      <td>0.947531</td>\n",
       "      <td>0.950464</td>\n",
       "      <td>0.004443</td>\n",
       "      <td>0.052469</td>\n",
       "      <td>0.997648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, lr, gb, with RandomForestClassifier</th>\n",
       "      <td>0.990270</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.938272</td>\n",
       "      <td>0.944099</td>\n",
       "      <td>0.004739</td>\n",
       "      <td>0.061728</td>\n",
       "      <td>0.994959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, gb, with RandomForestClassifier</th>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.952681</td>\n",
       "      <td>0.932099</td>\n",
       "      <td>0.942278</td>\n",
       "      <td>0.004443</td>\n",
       "      <td>0.067901</td>\n",
       "      <td>0.997260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, gb, with RandomForestClassifier</th>\n",
       "      <td>0.991081</td>\n",
       "      <td>0.953271</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.948837</td>\n",
       "      <td>0.004443</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.997355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, lr, with RandomForestClassifier</th>\n",
       "      <td>0.988378</td>\n",
       "      <td>0.946032</td>\n",
       "      <td>0.919753</td>\n",
       "      <td>0.932707</td>\n",
       "      <td>0.005036</td>\n",
       "      <td>0.080247</td>\n",
       "      <td>0.994868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: all, with GradientBoostingClassifier</th>\n",
       "      <td>0.991081</td>\n",
       "      <td>0.944954</td>\n",
       "      <td>0.953704</td>\n",
       "      <td>0.949309</td>\n",
       "      <td>0.005332</td>\n",
       "      <td>0.046296</td>\n",
       "      <td>0.994784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, lr, gb, with GradientBoostingClassifier</th>\n",
       "      <td>0.990270</td>\n",
       "      <td>0.941718</td>\n",
       "      <td>0.947531</td>\n",
       "      <td>0.944615</td>\n",
       "      <td>0.005628</td>\n",
       "      <td>0.052469</td>\n",
       "      <td>0.997313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, gb, with GradientBoostingClassifier</th>\n",
       "      <td>0.985946</td>\n",
       "      <td>0.922360</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.919505</td>\n",
       "      <td>0.007405</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.997366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, gb, with GradientBoostingClassifier</th>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.938838</td>\n",
       "      <td>0.947531</td>\n",
       "      <td>0.943164</td>\n",
       "      <td>0.005924</td>\n",
       "      <td>0.052469</td>\n",
       "      <td>0.997219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, lr, with GradientBoostingClassifier</th>\n",
       "      <td>0.986486</td>\n",
       "      <td>0.920245</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.007701</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.994659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Accuracy  Precision  \\\n",
       "Algorithms: all, with LogisticRegression            0.989459   0.943925   \n",
       "Algorithms: rf, lr, gb, with LogisticRegression     0.990000   0.947040   \n",
       "Algorithms: rf, gb, with LogisticRegression         0.989189   0.940994   \n",
       "Algorithms: lr, gb, with LogisticRegression         0.990270   0.947205   \n",
       "Algorithms: rf, lr, with LogisticRegression         0.987838   0.937304   \n",
       "Algorithms: all, with RandomForestClassifier        0.991351   0.953416   \n",
       "Algorithms: rf, lr, gb, with RandomForestClassi...  0.990270   0.950000   \n",
       "Algorithms: rf, gb, with RandomForestClassifier     0.990000   0.952681   \n",
       "Algorithms: lr, gb, with RandomForestClassifier     0.991081   0.953271   \n",
       "Algorithms: rf, lr, with RandomForestClassifier     0.988378   0.946032   \n",
       "Algorithms: all, with GradientBoostingClassifier    0.991081   0.944954   \n",
       "Algorithms: rf, lr, gb, with GradientBoostingCl...  0.990270   0.941718   \n",
       "Algorithms: rf, gb, with GradientBoostingClassi...  0.985946   0.922360   \n",
       "Algorithms: lr, gb, with GradientBoostingClassi...  0.990000   0.938838   \n",
       "Algorithms: rf, lr, with GradientBoostingClassi...  0.986486   0.920245   \n",
       "\n",
       "                                                      Recall  F1 Score  \\\n",
       "Algorithms: all, with LogisticRegression            0.935185  0.939535   \n",
       "Algorithms: rf, lr, gb, with LogisticRegression     0.938272  0.942636   \n",
       "Algorithms: rf, gb, with LogisticRegression         0.935185  0.938080   \n",
       "Algorithms: lr, gb, with LogisticRegression         0.941358  0.944272   \n",
       "Algorithms: rf, lr, with LogisticRegression         0.922840  0.930016   \n",
       "Algorithms: all, with RandomForestClassifier        0.947531  0.950464   \n",
       "Algorithms: rf, lr, gb, with RandomForestClassi...  0.938272  0.944099   \n",
       "Algorithms: rf, gb, with RandomForestClassifier     0.932099  0.942278   \n",
       "Algorithms: lr, gb, with RandomForestClassifier     0.944444  0.948837   \n",
       "Algorithms: rf, lr, with RandomForestClassifier     0.919753  0.932707   \n",
       "Algorithms: all, with GradientBoostingClassifier    0.953704  0.949309   \n",
       "Algorithms: rf, lr, gb, with GradientBoostingCl...  0.947531  0.944615   \n",
       "Algorithms: rf, gb, with GradientBoostingClassi...  0.916667  0.919505   \n",
       "Algorithms: lr, gb, with GradientBoostingClassi...  0.947531  0.943164   \n",
       "Algorithms: rf, lr, with GradientBoostingClassi...  0.925926  0.923077   \n",
       "\n",
       "                                                    False Positive Rate  \\\n",
       "Algorithms: all, with LogisticRegression                       0.005332   \n",
       "Algorithms: rf, lr, gb, with LogisticRegression                0.005036   \n",
       "Algorithms: rf, gb, with LogisticRegression                    0.005628   \n",
       "Algorithms: lr, gb, with LogisticRegression                    0.005036   \n",
       "Algorithms: rf, lr, with LogisticRegression                    0.005924   \n",
       "Algorithms: all, with RandomForestClassifier                   0.004443   \n",
       "Algorithms: rf, lr, gb, with RandomForestClassi...             0.004739   \n",
       "Algorithms: rf, gb, with RandomForestClassifier                0.004443   \n",
       "Algorithms: lr, gb, with RandomForestClassifier                0.004443   \n",
       "Algorithms: rf, lr, with RandomForestClassifier                0.005036   \n",
       "Algorithms: all, with GradientBoostingClassifier               0.005332   \n",
       "Algorithms: rf, lr, gb, with GradientBoostingCl...             0.005628   \n",
       "Algorithms: rf, gb, with GradientBoostingClassi...             0.007405   \n",
       "Algorithms: lr, gb, with GradientBoostingClassi...             0.005924   \n",
       "Algorithms: rf, lr, with GradientBoostingClassi...             0.007701   \n",
       "\n",
       "                                                    False Negative Rate  \\\n",
       "Algorithms: all, with LogisticRegression                       0.064815   \n",
       "Algorithms: rf, lr, gb, with LogisticRegression                0.061728   \n",
       "Algorithms: rf, gb, with LogisticRegression                    0.064815   \n",
       "Algorithms: lr, gb, with LogisticRegression                    0.058642   \n",
       "Algorithms: rf, lr, with LogisticRegression                    0.077160   \n",
       "Algorithms: all, with RandomForestClassifier                   0.052469   \n",
       "Algorithms: rf, lr, gb, with RandomForestClassi...             0.061728   \n",
       "Algorithms: rf, gb, with RandomForestClassifier                0.067901   \n",
       "Algorithms: lr, gb, with RandomForestClassifier                0.055556   \n",
       "Algorithms: rf, lr, with RandomForestClassifier                0.080247   \n",
       "Algorithms: all, with GradientBoostingClassifier               0.046296   \n",
       "Algorithms: rf, lr, gb, with GradientBoostingCl...             0.052469   \n",
       "Algorithms: rf, gb, with GradientBoostingClassi...             0.083333   \n",
       "Algorithms: lr, gb, with GradientBoostingClassi...             0.052469   \n",
       "Algorithms: rf, lr, with GradientBoostingClassi...             0.074074   \n",
       "\n",
       "                                                    Area Under ROC Curve  \n",
       "Algorithms: all, with LogisticRegression                        0.995641  \n",
       "Algorithms: rf, lr, gb, with LogisticRegression                 0.995882  \n",
       "Algorithms: rf, gb, with LogisticRegression                     0.995323  \n",
       "Algorithms: lr, gb, with LogisticRegression                     0.996256  \n",
       "Algorithms: rf, lr, with LogisticRegression                     0.995168  \n",
       "Algorithms: all, with RandomForestClassifier                    0.997648  \n",
       "Algorithms: rf, lr, gb, with RandomForestClassi...              0.994959  \n",
       "Algorithms: rf, gb, with RandomForestClassifier                 0.997260  \n",
       "Algorithms: lr, gb, with RandomForestClassifier                 0.997355  \n",
       "Algorithms: rf, lr, with RandomForestClassifier                 0.994868  \n",
       "Algorithms: all, with GradientBoostingClassifier                0.994784  \n",
       "Algorithms: rf, lr, gb, with GradientBoostingCl...              0.997313  \n",
       "Algorithms: rf, gb, with GradientBoostingClassi...              0.997366  \n",
       "Algorithms: lr, gb, with GradientBoostingClassi...              0.997219  \n",
       "Algorithms: rf, lr, with GradientBoostingClassi...              0.994659  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_stacking_imbalanced_multi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd442e7e",
   "metadata": {},
   "source": [
    "Of course, these models performed better on average than the stacking only of different feature sets. On the imbalanced dataset, Naive Bayes and Decision Tree did have some impact on the prediction accuracy. The best results were achieved when all algorithms were used as level 0 classifiers and Gradient Boosting or Random Forest were used on level 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b89718ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stacking_imbalanced_best = pd.concat([results_stacking_imbalanced_best, results_stacking_imbalanced_multi.sort_values(by=['F1 Score'], ascending = [False]).head(12)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d88996f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stacking_imbalanced_full = pd.concat([results_stacking_imbalanced_full, results_stacking_imbalanced_multi])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bc5c50",
   "metadata": {},
   "source": [
    "### Appending all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "800c2b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stacking_imbalanced_append = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f780e5",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9a189f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], exclude_models=[], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=[], append_features=True, result_row_name=\"Algorithms: all, with LogisticRegression (with appended features)\")\n",
    "results_stacking_imbalanced_append = pd.concat([results_stacking_imbalanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], exclude_models=['dt', 'nb'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb'], append_features=True)\n",
    "results_stacking_imbalanced_append = pd.concat([results_stacking_imbalanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], exclude_models=['dt', 'nb', 'lr'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'lr'], append_features=True)\n",
    "results_stacking_imbalanced_append = pd.concat([results_stacking_imbalanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], exclude_models=['dt', 'nb', 'rf'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'rf'], append_features=True)\n",
    "results_stacking_imbalanced_append = pd.concat([results_stacking_imbalanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], exclude_models=['dt', 'nb', 'gb'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb'], append_features=True)\n",
    "results_stacking_imbalanced_append = pd.concat([results_stacking_imbalanced_append, stacked_preds['results']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ae87f7",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ad0fa9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=rf, exclude_models=[], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=[], append_features=True, result_row_name=\"Algorithms: all, with RandomForestClassifier (with appended features)\")\n",
    "results_stacking_imbalanced_append = pd.concat([results_stacking_imbalanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=rf, exclude_models=['dt', 'nb'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb'], append_features=True)\n",
    "results_stacking_imbalanced_append = pd.concat([results_stacking_imbalanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=rf, exclude_models=['dt', 'nb', 'lr'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'lr'], append_features=True)\n",
    "results_stacking_imbalanced_append = pd.concat([results_stacking_imbalanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=rf, exclude_models=['dt', 'nb', 'rf'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'rf'], append_features=True)\n",
    "results_stacking_imbalanced_append = pd.concat([results_stacking_imbalanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=rf, exclude_models=['dt', 'nb', 'gb'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb'], append_features=True)\n",
    "results_stacking_imbalanced_append = pd.concat([results_stacking_imbalanced_append, stacked_preds['results']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944bae83",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "72796493",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=gb, exclude_models=[], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=[], append_features=True, result_row_name=\"Algorithms: all, with GradientBoostingClassifier (with appended features)\")\n",
    "results_stacking_imbalanced_append = pd.concat([results_stacking_imbalanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=gb, exclude_models=['dt', 'nb'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb'], append_features=True)\n",
    "results_stacking_imbalanced_append = pd.concat([results_stacking_imbalanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=gb, exclude_models=['dt', 'nb', 'lr'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'lr'], append_features=True)\n",
    "results_stacking_imbalanced_append = pd.concat([results_stacking_imbalanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=gb, exclude_models=['dt', 'nb', 'rf'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'rf'], append_features=True)\n",
    "results_stacking_imbalanced_append = pd.concat([results_stacking_imbalanced_append, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(stacking_models_imbalanced, train_feature_sets_imbalanced, style_train_imbalanced['target'], final_classifier=gb, exclude_models=['dt', 'nb', 'gb'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(stacking_models_imbalanced, test_feature_sets_imbalanced, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb'], append_features=True)\n",
    "results_stacking_imbalanced_append = pd.concat([results_stacking_imbalanced_append, stacked_preds['results']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8da36db6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>Area Under ROC Curve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Algorithms: all, with LogisticRegression (with appended features)</th>\n",
       "      <td>0.975405</td>\n",
       "      <td>0.892256</td>\n",
       "      <td>0.817901</td>\n",
       "      <td>0.853462</td>\n",
       "      <td>0.009479</td>\n",
       "      <td>0.182099</td>\n",
       "      <td>0.986839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, lr, gb, with LogisticRegression (with appended features)</th>\n",
       "      <td>0.975135</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.839506</td>\n",
       "      <td>0.855346</td>\n",
       "      <td>0.011848</td>\n",
       "      <td>0.160494</td>\n",
       "      <td>0.977626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, gb, with LogisticRegression (with appended features)</th>\n",
       "      <td>0.975405</td>\n",
       "      <td>0.865204</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>0.858476</td>\n",
       "      <td>0.012737</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.985631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, gb, with LogisticRegression (with appended features)</th>\n",
       "      <td>0.977568</td>\n",
       "      <td>0.887460</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>0.869291</td>\n",
       "      <td>0.010367</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.986768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, lr, with LogisticRegression (with appended features)</th>\n",
       "      <td>0.972703</td>\n",
       "      <td>0.863192</td>\n",
       "      <td>0.817901</td>\n",
       "      <td>0.839937</td>\n",
       "      <td>0.012441</td>\n",
       "      <td>0.182099</td>\n",
       "      <td>0.978714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: all, with RandomForestClassifier (with appended features)</th>\n",
       "      <td>0.990270</td>\n",
       "      <td>0.964516</td>\n",
       "      <td>0.922840</td>\n",
       "      <td>0.943218</td>\n",
       "      <td>0.003258</td>\n",
       "      <td>0.077160</td>\n",
       "      <td>0.997298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, lr, gb, with RandomForestClassifier (with appended features)</th>\n",
       "      <td>0.990811</td>\n",
       "      <td>0.958861</td>\n",
       "      <td>0.935185</td>\n",
       "      <td>0.946875</td>\n",
       "      <td>0.003851</td>\n",
       "      <td>0.064815</td>\n",
       "      <td>0.997661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, gb, with RandomForestClassifier (with appended features)</th>\n",
       "      <td>0.986486</td>\n",
       "      <td>0.956667</td>\n",
       "      <td>0.885802</td>\n",
       "      <td>0.919872</td>\n",
       "      <td>0.003851</td>\n",
       "      <td>0.114198</td>\n",
       "      <td>0.995491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, gb, with RandomForestClassifier (with appended features)</th>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.964401</td>\n",
       "      <td>0.919753</td>\n",
       "      <td>0.941548</td>\n",
       "      <td>0.003258</td>\n",
       "      <td>0.080247</td>\n",
       "      <td>0.997247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, lr, with RandomForestClassifier (with appended features)</th>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.961415</td>\n",
       "      <td>0.922840</td>\n",
       "      <td>0.941732</td>\n",
       "      <td>0.003555</td>\n",
       "      <td>0.077160</td>\n",
       "      <td>0.997043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: all, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.991351</td>\n",
       "      <td>0.953416</td>\n",
       "      <td>0.947531</td>\n",
       "      <td>0.950464</td>\n",
       "      <td>0.004443</td>\n",
       "      <td>0.052469</td>\n",
       "      <td>0.998227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, lr, gb, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.991351</td>\n",
       "      <td>0.953416</td>\n",
       "      <td>0.947531</td>\n",
       "      <td>0.950464</td>\n",
       "      <td>0.004443</td>\n",
       "      <td>0.052469</td>\n",
       "      <td>0.998245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, gb, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.987568</td>\n",
       "      <td>0.916168</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.930091</td>\n",
       "      <td>0.008294</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.996213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, gb, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.991351</td>\n",
       "      <td>0.950617</td>\n",
       "      <td>0.950617</td>\n",
       "      <td>0.950617</td>\n",
       "      <td>0.004739</td>\n",
       "      <td>0.049383</td>\n",
       "      <td>0.998202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, lr, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.990270</td>\n",
       "      <td>0.941718</td>\n",
       "      <td>0.947531</td>\n",
       "      <td>0.944615</td>\n",
       "      <td>0.005628</td>\n",
       "      <td>0.052469</td>\n",
       "      <td>0.998234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Accuracy  Precision  \\\n",
       "Algorithms: all, with LogisticRegression (with ...  0.975405   0.892256   \n",
       "Algorithms: rf, lr, gb, with LogisticRegression...  0.975135   0.871795   \n",
       "Algorithms: rf, gb, with LogisticRegression (wi...  0.975405   0.865204   \n",
       "Algorithms: lr, gb, with LogisticRegression (wi...  0.977568   0.887460   \n",
       "Algorithms: rf, lr, with LogisticRegression (wi...  0.972703   0.863192   \n",
       "Algorithms: all, with RandomForestClassifier (w...  0.990270   0.964516   \n",
       "Algorithms: rf, lr, gb, with RandomForestClassi...  0.990811   0.958861   \n",
       "Algorithms: rf, gb, with RandomForestClassifier...  0.986486   0.956667   \n",
       "Algorithms: lr, gb, with RandomForestClassifier...  0.990000   0.964401   \n",
       "Algorithms: rf, lr, with RandomForestClassifier...  0.990000   0.961415   \n",
       "Algorithms: all, with GradientBoostingClassifie...  0.991351   0.953416   \n",
       "Algorithms: rf, lr, gb, with GradientBoostingCl...  0.991351   0.953416   \n",
       "Algorithms: rf, gb, with GradientBoostingClassi...  0.987568   0.916168   \n",
       "Algorithms: lr, gb, with GradientBoostingClassi...  0.991351   0.950617   \n",
       "Algorithms: rf, lr, with GradientBoostingClassi...  0.990270   0.941718   \n",
       "\n",
       "                                                      Recall  F1 Score  \\\n",
       "Algorithms: all, with LogisticRegression (with ...  0.817901  0.853462   \n",
       "Algorithms: rf, lr, gb, with LogisticRegression...  0.839506  0.855346   \n",
       "Algorithms: rf, gb, with LogisticRegression (wi...  0.851852  0.858476   \n",
       "Algorithms: lr, gb, with LogisticRegression (wi...  0.851852  0.869291   \n",
       "Algorithms: rf, lr, with LogisticRegression (wi...  0.817901  0.839937   \n",
       "Algorithms: all, with RandomForestClassifier (w...  0.922840  0.943218   \n",
       "Algorithms: rf, lr, gb, with RandomForestClassi...  0.935185  0.946875   \n",
       "Algorithms: rf, gb, with RandomForestClassifier...  0.885802  0.919872   \n",
       "Algorithms: lr, gb, with RandomForestClassifier...  0.919753  0.941548   \n",
       "Algorithms: rf, lr, with RandomForestClassifier...  0.922840  0.941732   \n",
       "Algorithms: all, with GradientBoostingClassifie...  0.947531  0.950464   \n",
       "Algorithms: rf, lr, gb, with GradientBoostingCl...  0.947531  0.950464   \n",
       "Algorithms: rf, gb, with GradientBoostingClassi...  0.944444  0.930091   \n",
       "Algorithms: lr, gb, with GradientBoostingClassi...  0.950617  0.950617   \n",
       "Algorithms: rf, lr, with GradientBoostingClassi...  0.947531  0.944615   \n",
       "\n",
       "                                                    False Positive Rate  \\\n",
       "Algorithms: all, with LogisticRegression (with ...             0.009479   \n",
       "Algorithms: rf, lr, gb, with LogisticRegression...             0.011848   \n",
       "Algorithms: rf, gb, with LogisticRegression (wi...             0.012737   \n",
       "Algorithms: lr, gb, with LogisticRegression (wi...             0.010367   \n",
       "Algorithms: rf, lr, with LogisticRegression (wi...             0.012441   \n",
       "Algorithms: all, with RandomForestClassifier (w...             0.003258   \n",
       "Algorithms: rf, lr, gb, with RandomForestClassi...             0.003851   \n",
       "Algorithms: rf, gb, with RandomForestClassifier...             0.003851   \n",
       "Algorithms: lr, gb, with RandomForestClassifier...             0.003258   \n",
       "Algorithms: rf, lr, with RandomForestClassifier...             0.003555   \n",
       "Algorithms: all, with GradientBoostingClassifie...             0.004443   \n",
       "Algorithms: rf, lr, gb, with GradientBoostingCl...             0.004443   \n",
       "Algorithms: rf, gb, with GradientBoostingClassi...             0.008294   \n",
       "Algorithms: lr, gb, with GradientBoostingClassi...             0.004739   \n",
       "Algorithms: rf, lr, with GradientBoostingClassi...             0.005628   \n",
       "\n",
       "                                                    False Negative Rate  \\\n",
       "Algorithms: all, with LogisticRegression (with ...             0.182099   \n",
       "Algorithms: rf, lr, gb, with LogisticRegression...             0.160494   \n",
       "Algorithms: rf, gb, with LogisticRegression (wi...             0.148148   \n",
       "Algorithms: lr, gb, with LogisticRegression (wi...             0.148148   \n",
       "Algorithms: rf, lr, with LogisticRegression (wi...             0.182099   \n",
       "Algorithms: all, with RandomForestClassifier (w...             0.077160   \n",
       "Algorithms: rf, lr, gb, with RandomForestClassi...             0.064815   \n",
       "Algorithms: rf, gb, with RandomForestClassifier...             0.114198   \n",
       "Algorithms: lr, gb, with RandomForestClassifier...             0.080247   \n",
       "Algorithms: rf, lr, with RandomForestClassifier...             0.077160   \n",
       "Algorithms: all, with GradientBoostingClassifie...             0.052469   \n",
       "Algorithms: rf, lr, gb, with GradientBoostingCl...             0.052469   \n",
       "Algorithms: rf, gb, with GradientBoostingClassi...             0.055556   \n",
       "Algorithms: lr, gb, with GradientBoostingClassi...             0.049383   \n",
       "Algorithms: rf, lr, with GradientBoostingClassi...             0.052469   \n",
       "\n",
       "                                                    Area Under ROC Curve  \n",
       "Algorithms: all, with LogisticRegression (with ...              0.986839  \n",
       "Algorithms: rf, lr, gb, with LogisticRegression...              0.977626  \n",
       "Algorithms: rf, gb, with LogisticRegression (wi...              0.985631  \n",
       "Algorithms: lr, gb, with LogisticRegression (wi...              0.986768  \n",
       "Algorithms: rf, lr, with LogisticRegression (wi...              0.978714  \n",
       "Algorithms: all, with RandomForestClassifier (w...              0.997298  \n",
       "Algorithms: rf, lr, gb, with RandomForestClassi...              0.997661  \n",
       "Algorithms: rf, gb, with RandomForestClassifier...              0.995491  \n",
       "Algorithms: lr, gb, with RandomForestClassifier...              0.997247  \n",
       "Algorithms: rf, lr, with RandomForestClassifier...              0.997043  \n",
       "Algorithms: all, with GradientBoostingClassifie...              0.998227  \n",
       "Algorithms: rf, lr, gb, with GradientBoostingCl...              0.998245  \n",
       "Algorithms: rf, gb, with GradientBoostingClassi...              0.996213  \n",
       "Algorithms: lr, gb, with GradientBoostingClassi...              0.998202  \n",
       "Algorithms: rf, lr, with GradientBoostingClassi...              0.998234  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_stacking_imbalanced_append"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53342ec1",
   "metadata": {},
   "source": [
    "Adding the initial feature sets to the final classifier also mostly harms performance on the imbalanced dataset. The best performing model now only barely performed better than without the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "380c0f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stacking_imbalanced_best = pd.concat([results_stacking_imbalanced_best, results_stacking_imbalanced_append.sort_values(by=['F1 Score'], ascending = [False]).head(6)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4161c43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stacking_imbalanced_full = pd.concat([results_stacking_imbalanced_full, results_stacking_imbalanced_append])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8ba91b",
   "metadata": {},
   "source": [
    "### Merged Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "097252fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature_sets_imbalanced_merged = [{'name': 'merge', 'features': style_content_train_imbalanced}]\n",
    "test_feature_sets_imbalanced_merged = [{'name': 'merge', 'features': style_content_test_imbalanced}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1650fcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_merged_imbalanced = {'model' : lr_style_content_imbalanced, 'scaler': lr_style_content_imbalanced_scaler}\n",
    "nb_merged_imbalanced = {'model' : nb_style_content_imbalanced, 'scaler': nb_style_content_imbalanced_scaler}\n",
    "\n",
    "merged_models_imbalanced = [{'name' : 'lr', 'features' : 'merge', 'model' : lr_merged_imbalanced},\n",
    "                          {'name' : 'dt', 'features' : 'merge', 'model' : dt_style_content_imbalanced},\n",
    "                          {'name' : 'rf', 'features' : 'merge', 'model' : rf_style_content_imbalanced},\n",
    "                          {'name' : 'gb', 'features' : 'merge', 'model' : gb_style_content_imbalanced},\n",
    "                          {'name' : 'nb', 'features' : 'merge', 'model' : nb_merged_imbalanced}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e26d815e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stacking_imbalanced_merged = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7384bf08",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "863e7864",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_clf = ml.train_stacked_models(merged_models_imbalanced, train_feature_sets_imbalanced_merged, style_train_imbalanced['target'], exclude_models=['dt', 'nb'], append_features=False)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_imbalanced, test_feature_sets_imbalanced_merged, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb'], append_features=False, result_row_name=\"Algorithms: lr, rf, gb merged, with LogisticRegression\")\n",
    "results_stacking_imbalanced_merged = pd.concat([results_stacking_imbalanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_imbalanced, train_feature_sets_imbalanced_merged, style_train_imbalanced['target'], exclude_models=['dt', 'nb', 'lr'], append_features=False)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_imbalanced, test_feature_sets_imbalanced_merged, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'lr'], append_features=False, result_row_name=\"Algorithms: rf, gb merged, with LogisticRegression\")\n",
    "results_stacking_imbalanced_merged = pd.concat([results_stacking_imbalanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_imbalanced, train_feature_sets_imbalanced_merged, style_train_imbalanced['target'], exclude_models=['dt', 'nb', 'rf'], append_features=False)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_imbalanced, test_feature_sets_imbalanced_merged, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'rf'], append_features=False, result_row_name=\"Algorithms: lr, gb merged, with LogisticRegression\")\n",
    "results_stacking_imbalanced_merged = pd.concat([results_stacking_imbalanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_imbalanced, train_feature_sets_imbalanced_merged, style_train_imbalanced['target'], exclude_models=['dt', 'nb', 'gb'], append_features=False)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_imbalanced, test_feature_sets_imbalanced_merged, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb'], append_features=False, result_row_name=\"Algorithms: rf, lr merged, with LogisticRegression\")\n",
    "results_stacking_imbalanced_merged = pd.concat([results_stacking_imbalanced_merged, stacked_preds['results']])\n",
    "\n",
    "# Append features\n",
    "stacked_clf = ml.train_stacked_models(merged_models_imbalanced, train_feature_sets_imbalanced_merged, style_train_imbalanced['target'], exclude_models=['dt', 'nb'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_imbalanced, test_feature_sets_imbalanced_merged, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb'], append_features=True, result_row_name=\"Algorithms: lr, rf, gb merged, with LogisticRegression (with appended features)\")\n",
    "results_stacking_imbalanced_merged = pd.concat([results_stacking_imbalanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_imbalanced, train_feature_sets_imbalanced_merged, style_train_imbalanced['target'], exclude_models=['dt', 'nb', 'lr'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_imbalanced, test_feature_sets_imbalanced_merged, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'lr'], append_features=True, result_row_name=\"Algorithms: rf, gb merged, with LogisticRegression (with appended features)\")\n",
    "results_stacking_imbalanced_merged = pd.concat([results_stacking_imbalanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_imbalanced, train_feature_sets_imbalanced_merged, style_train_imbalanced['target'], exclude_models=['dt', 'nb', 'rf'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_imbalanced, test_feature_sets_imbalanced_merged, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'rf'], append_features=True, result_row_name=\"Algorithms: lr, gb merged, with LogisticRegression (with appended features)\")\n",
    "results_stacking_imbalanced_merged = pd.concat([results_stacking_imbalanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_imbalanced, train_feature_sets_imbalanced_merged, style_train_imbalanced['target'], exclude_models=['dt', 'nb', 'gb'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_imbalanced, test_feature_sets_imbalanced_merged, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb'], append_features=True, result_row_name=\"Algorithms: rf, lr merged, with LogisticRegression (with appended features)\")\n",
    "results_stacking_imbalanced_merged = pd.concat([results_stacking_imbalanced_merged, stacked_preds['results']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeaf03c2",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8834a342",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_clf = ml.train_stacked_models(merged_models_imbalanced, train_feature_sets_imbalanced_merged, style_train_imbalanced['target'], final_classifier=rf, exclude_models=['dt', 'nb'], append_features=False)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_imbalanced, test_feature_sets_imbalanced_merged, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb'], append_features=False, result_row_name=\"Algorithms: lr, rf, gb merged, with RandomForestClassifier\")\n",
    "results_stacking_imbalanced_merged = pd.concat([results_stacking_imbalanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_imbalanced, train_feature_sets_imbalanced_merged, style_train_imbalanced['target'], final_classifier=rf, exclude_models=['dt', 'nb', 'lr'], append_features=False)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_imbalanced, test_feature_sets_imbalanced_merged, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'lr'], append_features=False, result_row_name=\"Algorithms: rf, gb merged, with RandomForestClassifier\")\n",
    "results_stacking_imbalanced_merged = pd.concat([results_stacking_imbalanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_imbalanced, train_feature_sets_imbalanced_merged, style_train_imbalanced['target'], final_classifier=rf, exclude_models=['dt', 'nb', 'rf'], append_features=False)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_imbalanced, test_feature_sets_imbalanced_merged, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'rf'], append_features=False, result_row_name=\"Algorithms: lr, gb merged, with RandomForestClassifier\")\n",
    "results_stacking_imbalanced_merged = pd.concat([results_stacking_imbalanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_imbalanced, train_feature_sets_imbalanced_merged, style_train_imbalanced['target'], final_classifier=rf, exclude_models=['dt', 'nb', 'gb'], append_features=False)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_imbalanced, test_feature_sets_imbalanced_merged, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb'], append_features=False, result_row_name=\"Algorithms: rf, lr merged, with RandomForestClassifier\")\n",
    "results_stacking_imbalanced_merged = pd.concat([results_stacking_imbalanced_merged, stacked_preds['results']])\n",
    "\n",
    "# Append features\n",
    "stacked_clf = ml.train_stacked_models(merged_models_imbalanced, train_feature_sets_imbalanced_merged, style_train_imbalanced['target'], final_classifier=rf, exclude_models=['dt', 'nb'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_imbalanced, test_feature_sets_imbalanced_merged, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb'], append_features=True, result_row_name=\"Algorithms: lr, rf, gb merged, with RandomForestClassifier (with appended features)\")\n",
    "results_stacking_imbalanced_merged = pd.concat([results_stacking_imbalanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_imbalanced, train_feature_sets_imbalanced_merged, style_train_imbalanced['target'], final_classifier=rf, exclude_models=['dt', 'nb', 'lr'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_imbalanced, test_feature_sets_imbalanced_merged, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'lr'], append_features=True, result_row_name=\"Algorithms: rf, gb merged, with RandomForestClassifier (with appended features)\")\n",
    "results_stacking_imbalanced_merged = pd.concat([results_stacking_imbalanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_imbalanced, train_feature_sets_imbalanced_merged, style_train_imbalanced['target'], final_classifier=rf, exclude_models=['dt', 'nb', 'rf'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_imbalanced, test_feature_sets_imbalanced_merged, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'rf'], append_features=True, result_row_name=\"Algorithms: lr, gb merged, with RandomForestClassifier (with appended features)\")\n",
    "results_stacking_imbalanced_merged = pd.concat([results_stacking_imbalanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_imbalanced, train_feature_sets_imbalanced_merged, style_train_imbalanced['target'], final_classifier=rf, exclude_models=['dt', 'nb', 'gb'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_imbalanced, test_feature_sets_imbalanced_merged, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb'], append_features=True, result_row_name=\"Algorithms: rf, lr merged, with RandomForestClassifier (with appended features)\")\n",
    "results_stacking_imbalanced_merged = pd.concat([results_stacking_imbalanced_merged, stacked_preds['results']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0e3fa2",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8c2e1bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_clf = ml.train_stacked_models(merged_models_imbalanced, train_feature_sets_imbalanced_merged, style_train_imbalanced['target'], final_classifier=gb, exclude_models=['dt', 'nb'], append_features=False)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_imbalanced, test_feature_sets_imbalanced_merged, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb'], append_features=False, result_row_name=\"Algorithms: lr, rf, gb merged, with GradientBoostingClassifier\")\n",
    "results_stacking_imbalanced_merged = pd.concat([results_stacking_imbalanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_imbalanced, train_feature_sets_imbalanced_merged, style_train_imbalanced['target'], final_classifier=gb, exclude_models=['dt', 'nb', 'lr'], append_features=False)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_imbalanced, test_feature_sets_imbalanced_merged, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'lr'], append_features=False, result_row_name=\"Algorithms: rf, gb merged, with GradientBoostingClassifier\")\n",
    "results_stacking_imbalanced_merged = pd.concat([results_stacking_imbalanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_imbalanced, train_feature_sets_imbalanced_merged, style_train_imbalanced['target'], final_classifier=gb, exclude_models=['dt', 'nb', 'rf'], append_features=False)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_imbalanced, test_feature_sets_imbalanced_merged, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'rf'], append_features=False, result_row_name=\"Algorithms: lr, gb merged, with GradientBoostingClassifier\")\n",
    "results_stacking_imbalanced_merged = pd.concat([results_stacking_imbalanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_imbalanced, train_feature_sets_imbalanced_merged, style_train_imbalanced['target'], final_classifier=gb, exclude_models=['dt', 'nb', 'gb'], append_features=False)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_imbalanced, test_feature_sets_imbalanced_merged, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb'], append_features=False, result_row_name=\"Algorithms: rf, lr merged, with GradientBoostingClassifier\")\n",
    "results_stacking_imbalanced_merged = pd.concat([results_stacking_imbalanced_merged, stacked_preds['results']])\n",
    "\n",
    "# Append features\n",
    "stacked_clf = ml.train_stacked_models(merged_models_imbalanced, train_feature_sets_imbalanced_merged, style_train_imbalanced['target'], final_classifier=gb, exclude_models=['dt', 'nb'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_imbalanced, test_feature_sets_imbalanced_merged, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb'], append_features=True, result_row_name=\"Algorithms: lr, rf, gb merged, with GradientBoostingClassifier (with appended features)\")\n",
    "results_stacking_imbalanced_merged = pd.concat([results_stacking_imbalanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_imbalanced, train_feature_sets_imbalanced_merged, style_train_imbalanced['target'], final_classifier=gb, exclude_models=['dt', 'nb', 'lr'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_imbalanced, test_feature_sets_imbalanced_merged, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'lr'], append_features=True, result_row_name=\"Algorithms: rf, gb merged, with GradientBoostingClassifier (with appended features)\")\n",
    "results_stacking_imbalanced_merged = pd.concat([results_stacking_imbalanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_imbalanced, train_feature_sets_imbalanced_merged, style_train_imbalanced['target'], final_classifier=gb, exclude_models=['dt', 'nb', 'rf'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_imbalanced, test_feature_sets_imbalanced_merged, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'rf'], append_features=True, result_row_name=\"Algorithms: lr, gb merged, with GradientBoostingClassifier (with appended features)\")\n",
    "results_stacking_imbalanced_merged = pd.concat([results_stacking_imbalanced_merged, stacked_preds['results']])\n",
    "\n",
    "stacked_clf = ml.train_stacked_models(merged_models_imbalanced, train_feature_sets_imbalanced_merged, style_train_imbalanced['target'], final_classifier=gb, exclude_models=['dt', 'nb', 'gb'], append_features=True)\n",
    "stacked_preds = ml.test_stacked_models(merged_models_imbalanced, test_feature_sets_imbalanced_merged, style_test_imbalanced['target'], stacked_clf, exclude_models=['dt', 'nb', 'gb'], append_features=True, result_row_name=\"Algorithms: rf, lr merged, with GradientBoostingClassifier (with appended features)\")\n",
    "results_stacking_imbalanced_merged = pd.concat([results_stacking_imbalanced_merged, stacked_preds['results']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8f524cae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>Area Under ROC Curve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, rf, gb merged, with LogisticRegression</th>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.929012</td>\n",
       "      <td>0.942097</td>\n",
       "      <td>0.004147</td>\n",
       "      <td>0.070988</td>\n",
       "      <td>0.998106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, gb merged, with LogisticRegression</th>\n",
       "      <td>0.987568</td>\n",
       "      <td>0.931677</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.928793</td>\n",
       "      <td>0.006517</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.996373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, gb merged, with LogisticRegression</th>\n",
       "      <td>0.989459</td>\n",
       "      <td>0.949527</td>\n",
       "      <td>0.929012</td>\n",
       "      <td>0.939158</td>\n",
       "      <td>0.004739</td>\n",
       "      <td>0.070988</td>\n",
       "      <td>0.998186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, lr merged, with LogisticRegression</th>\n",
       "      <td>0.990811</td>\n",
       "      <td>0.964744</td>\n",
       "      <td>0.929012</td>\n",
       "      <td>0.946541</td>\n",
       "      <td>0.003258</td>\n",
       "      <td>0.070988</td>\n",
       "      <td>0.997569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, rf, gb merged, with LogisticRegression (with appended features)</th>\n",
       "      <td>0.977297</td>\n",
       "      <td>0.892157</td>\n",
       "      <td>0.842593</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.009775</td>\n",
       "      <td>0.157407</td>\n",
       "      <td>0.987852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, gb merged, with LogisticRegression (with appended features)</th>\n",
       "      <td>0.976486</td>\n",
       "      <td>0.881029</td>\n",
       "      <td>0.845679</td>\n",
       "      <td>0.862992</td>\n",
       "      <td>0.010960</td>\n",
       "      <td>0.154321</td>\n",
       "      <td>0.985168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, gb merged, with LogisticRegression (with appended features)</th>\n",
       "      <td>0.976757</td>\n",
       "      <td>0.891447</td>\n",
       "      <td>0.836420</td>\n",
       "      <td>0.863057</td>\n",
       "      <td>0.009775</td>\n",
       "      <td>0.163580</td>\n",
       "      <td>0.984063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, lr merged, with LogisticRegression (with appended features)</th>\n",
       "      <td>0.977027</td>\n",
       "      <td>0.881789</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>0.866562</td>\n",
       "      <td>0.010960</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.985733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, rf, gb merged, with RandomForestClassifier</th>\n",
       "      <td>0.988378</td>\n",
       "      <td>0.932308</td>\n",
       "      <td>0.935185</td>\n",
       "      <td>0.933744</td>\n",
       "      <td>0.006517</td>\n",
       "      <td>0.064815</td>\n",
       "      <td>0.997964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, gb merged, with RandomForestClassifier</th>\n",
       "      <td>0.986486</td>\n",
       "      <td>0.922840</td>\n",
       "      <td>0.922840</td>\n",
       "      <td>0.922840</td>\n",
       "      <td>0.007405</td>\n",
       "      <td>0.077160</td>\n",
       "      <td>0.996386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, gb merged, with RandomForestClassifier</th>\n",
       "      <td>0.989459</td>\n",
       "      <td>0.946708</td>\n",
       "      <td>0.932099</td>\n",
       "      <td>0.939347</td>\n",
       "      <td>0.005036</td>\n",
       "      <td>0.067901</td>\n",
       "      <td>0.997932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, lr merged, with RandomForestClassifier</th>\n",
       "      <td>0.987838</td>\n",
       "      <td>0.934579</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.006220</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.997445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, rf, gb merged, with RandomForestClassifier (with appended features)</th>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.961415</td>\n",
       "      <td>0.922840</td>\n",
       "      <td>0.941732</td>\n",
       "      <td>0.003555</td>\n",
       "      <td>0.077160</td>\n",
       "      <td>0.997127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, gb merged, with RandomForestClassifier (with appended features)</th>\n",
       "      <td>0.987838</td>\n",
       "      <td>0.948553</td>\n",
       "      <td>0.910494</td>\n",
       "      <td>0.929134</td>\n",
       "      <td>0.004739</td>\n",
       "      <td>0.089506</td>\n",
       "      <td>0.994640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, gb merged, with RandomForestClassifier (with appended features)</th>\n",
       "      <td>0.990270</td>\n",
       "      <td>0.967532</td>\n",
       "      <td>0.919753</td>\n",
       "      <td>0.943038</td>\n",
       "      <td>0.002962</td>\n",
       "      <td>0.080247</td>\n",
       "      <td>0.997018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, lr merged, with RandomForestClassifier (with appended features)</th>\n",
       "      <td>0.987838</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.927536</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.996637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, rf, gb merged, with GradientBoostingClassifier</th>\n",
       "      <td>0.987297</td>\n",
       "      <td>0.920973</td>\n",
       "      <td>0.935185</td>\n",
       "      <td>0.928025</td>\n",
       "      <td>0.007701</td>\n",
       "      <td>0.064815</td>\n",
       "      <td>0.997022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, gb merged, with GradientBoostingClassifier</th>\n",
       "      <td>0.984324</td>\n",
       "      <td>0.903030</td>\n",
       "      <td>0.919753</td>\n",
       "      <td>0.911315</td>\n",
       "      <td>0.009479</td>\n",
       "      <td>0.080247</td>\n",
       "      <td>0.996308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, gb merged, with GradientBoostingClassifier</th>\n",
       "      <td>0.988919</td>\n",
       "      <td>0.935385</td>\n",
       "      <td>0.938272</td>\n",
       "      <td>0.936826</td>\n",
       "      <td>0.006220</td>\n",
       "      <td>0.061728</td>\n",
       "      <td>0.996911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, lr merged, with GradientBoostingClassifier</th>\n",
       "      <td>0.987838</td>\n",
       "      <td>0.929231</td>\n",
       "      <td>0.932099</td>\n",
       "      <td>0.930663</td>\n",
       "      <td>0.006813</td>\n",
       "      <td>0.067901</td>\n",
       "      <td>0.996473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, rf, gb merged, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.990541</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.945904</td>\n",
       "      <td>0.005036</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.994871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, gb merged, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.989730</td>\n",
       "      <td>0.941358</td>\n",
       "      <td>0.941358</td>\n",
       "      <td>0.941358</td>\n",
       "      <td>0.005628</td>\n",
       "      <td>0.058642</td>\n",
       "      <td>0.997372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, gb merged, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.991081</td>\n",
       "      <td>0.953271</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.948837</td>\n",
       "      <td>0.004443</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.998220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, lr merged, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.991622</td>\n",
       "      <td>0.956386</td>\n",
       "      <td>0.947531</td>\n",
       "      <td>0.951938</td>\n",
       "      <td>0.004147</td>\n",
       "      <td>0.052469</td>\n",
       "      <td>0.997899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Accuracy  Precision  \\\n",
       "Algorithms: lr, rf, gb merged, with LogisticReg...  0.990000   0.955556   \n",
       "Algorithms: rf, gb merged, with LogisticRegression  0.987568   0.931677   \n",
       "Algorithms: lr, gb merged, with LogisticRegression  0.989459   0.949527   \n",
       "Algorithms: rf, lr merged, with LogisticRegression  0.990811   0.964744   \n",
       "Algorithms: lr, rf, gb merged, with LogisticReg...  0.977297   0.892157   \n",
       "Algorithms: rf, gb merged, with LogisticRegress...  0.976486   0.881029   \n",
       "Algorithms: lr, gb merged, with LogisticRegress...  0.976757   0.891447   \n",
       "Algorithms: rf, lr merged, with LogisticRegress...  0.977027   0.881789   \n",
       "Algorithms: lr, rf, gb merged, with RandomFores...  0.988378   0.932308   \n",
       "Algorithms: rf, gb merged, with RandomForestCla...  0.986486   0.922840   \n",
       "Algorithms: lr, gb merged, with RandomForestCla...  0.989459   0.946708   \n",
       "Algorithms: rf, lr merged, with RandomForestCla...  0.987838   0.934579   \n",
       "Algorithms: lr, rf, gb merged, with RandomFores...  0.990000   0.961415   \n",
       "Algorithms: rf, gb merged, with RandomForestCla...  0.987838   0.948553   \n",
       "Algorithms: lr, gb merged, with RandomForestCla...  0.990270   0.967532   \n",
       "Algorithms: rf, lr merged, with RandomForestCla...  0.987838   0.969697   \n",
       "Algorithms: lr, rf, gb merged, with GradientBoo...  0.987297   0.920973   \n",
       "Algorithms: rf, gb merged, with GradientBoostin...  0.984324   0.903030   \n",
       "Algorithms: lr, gb merged, with GradientBoostin...  0.988919   0.935385   \n",
       "Algorithms: rf, lr merged, with GradientBoostin...  0.987838   0.929231   \n",
       "Algorithms: lr, rf, gb merged, with GradientBoo...  0.990541   0.947368   \n",
       "Algorithms: rf, gb merged, with GradientBoostin...  0.989730   0.941358   \n",
       "Algorithms: lr, gb merged, with GradientBoostin...  0.991081   0.953271   \n",
       "Algorithms: rf, lr merged, with GradientBoostin...  0.991622   0.956386   \n",
       "\n",
       "                                                      Recall  F1 Score  \\\n",
       "Algorithms: lr, rf, gb merged, with LogisticReg...  0.929012  0.942097   \n",
       "Algorithms: rf, gb merged, with LogisticRegression  0.925926  0.928793   \n",
       "Algorithms: lr, gb merged, with LogisticRegression  0.929012  0.939158   \n",
       "Algorithms: rf, lr merged, with LogisticRegression  0.929012  0.946541   \n",
       "Algorithms: lr, rf, gb merged, with LogisticReg...  0.842593  0.866667   \n",
       "Algorithms: rf, gb merged, with LogisticRegress...  0.845679  0.862992   \n",
       "Algorithms: lr, gb merged, with LogisticRegress...  0.836420  0.863057   \n",
       "Algorithms: rf, lr merged, with LogisticRegress...  0.851852  0.866562   \n",
       "Algorithms: lr, rf, gb merged, with RandomFores...  0.935185  0.933744   \n",
       "Algorithms: rf, gb merged, with RandomForestCla...  0.922840  0.922840   \n",
       "Algorithms: lr, gb merged, with RandomForestCla...  0.932099  0.939347   \n",
       "Algorithms: rf, lr merged, with RandomForestCla...  0.925926  0.930233   \n",
       "Algorithms: lr, rf, gb merged, with RandomFores...  0.922840  0.941732   \n",
       "Algorithms: rf, gb merged, with RandomForestCla...  0.910494  0.929134   \n",
       "Algorithms: lr, gb merged, with RandomForestCla...  0.919753  0.943038   \n",
       "Algorithms: rf, lr merged, with RandomForestCla...  0.888889  0.927536   \n",
       "Algorithms: lr, rf, gb merged, with GradientBoo...  0.935185  0.928025   \n",
       "Algorithms: rf, gb merged, with GradientBoostin...  0.919753  0.911315   \n",
       "Algorithms: lr, gb merged, with GradientBoostin...  0.938272  0.936826   \n",
       "Algorithms: rf, lr merged, with GradientBoostin...  0.932099  0.930663   \n",
       "Algorithms: lr, rf, gb merged, with GradientBoo...  0.944444  0.945904   \n",
       "Algorithms: rf, gb merged, with GradientBoostin...  0.941358  0.941358   \n",
       "Algorithms: lr, gb merged, with GradientBoostin...  0.944444  0.948837   \n",
       "Algorithms: rf, lr merged, with GradientBoostin...  0.947531  0.951938   \n",
       "\n",
       "                                                    False Positive Rate  \\\n",
       "Algorithms: lr, rf, gb merged, with LogisticReg...             0.004147   \n",
       "Algorithms: rf, gb merged, with LogisticRegression             0.006517   \n",
       "Algorithms: lr, gb merged, with LogisticRegression             0.004739   \n",
       "Algorithms: rf, lr merged, with LogisticRegression             0.003258   \n",
       "Algorithms: lr, rf, gb merged, with LogisticReg...             0.009775   \n",
       "Algorithms: rf, gb merged, with LogisticRegress...             0.010960   \n",
       "Algorithms: lr, gb merged, with LogisticRegress...             0.009775   \n",
       "Algorithms: rf, lr merged, with LogisticRegress...             0.010960   \n",
       "Algorithms: lr, rf, gb merged, with RandomFores...             0.006517   \n",
       "Algorithms: rf, gb merged, with RandomForestCla...             0.007405   \n",
       "Algorithms: lr, gb merged, with RandomForestCla...             0.005036   \n",
       "Algorithms: rf, lr merged, with RandomForestCla...             0.006220   \n",
       "Algorithms: lr, rf, gb merged, with RandomFores...             0.003555   \n",
       "Algorithms: rf, gb merged, with RandomForestCla...             0.004739   \n",
       "Algorithms: lr, gb merged, with RandomForestCla...             0.002962   \n",
       "Algorithms: rf, lr merged, with RandomForestCla...             0.002666   \n",
       "Algorithms: lr, rf, gb merged, with GradientBoo...             0.007701   \n",
       "Algorithms: rf, gb merged, with GradientBoostin...             0.009479   \n",
       "Algorithms: lr, gb merged, with GradientBoostin...             0.006220   \n",
       "Algorithms: rf, lr merged, with GradientBoostin...             0.006813   \n",
       "Algorithms: lr, rf, gb merged, with GradientBoo...             0.005036   \n",
       "Algorithms: rf, gb merged, with GradientBoostin...             0.005628   \n",
       "Algorithms: lr, gb merged, with GradientBoostin...             0.004443   \n",
       "Algorithms: rf, lr merged, with GradientBoostin...             0.004147   \n",
       "\n",
       "                                                    False Negative Rate  \\\n",
       "Algorithms: lr, rf, gb merged, with LogisticReg...             0.070988   \n",
       "Algorithms: rf, gb merged, with LogisticRegression             0.074074   \n",
       "Algorithms: lr, gb merged, with LogisticRegression             0.070988   \n",
       "Algorithms: rf, lr merged, with LogisticRegression             0.070988   \n",
       "Algorithms: lr, rf, gb merged, with LogisticReg...             0.157407   \n",
       "Algorithms: rf, gb merged, with LogisticRegress...             0.154321   \n",
       "Algorithms: lr, gb merged, with LogisticRegress...             0.163580   \n",
       "Algorithms: rf, lr merged, with LogisticRegress...             0.148148   \n",
       "Algorithms: lr, rf, gb merged, with RandomFores...             0.064815   \n",
       "Algorithms: rf, gb merged, with RandomForestCla...             0.077160   \n",
       "Algorithms: lr, gb merged, with RandomForestCla...             0.067901   \n",
       "Algorithms: rf, lr merged, with RandomForestCla...             0.074074   \n",
       "Algorithms: lr, rf, gb merged, with RandomFores...             0.077160   \n",
       "Algorithms: rf, gb merged, with RandomForestCla...             0.089506   \n",
       "Algorithms: lr, gb merged, with RandomForestCla...             0.080247   \n",
       "Algorithms: rf, lr merged, with RandomForestCla...             0.111111   \n",
       "Algorithms: lr, rf, gb merged, with GradientBoo...             0.064815   \n",
       "Algorithms: rf, gb merged, with GradientBoostin...             0.080247   \n",
       "Algorithms: lr, gb merged, with GradientBoostin...             0.061728   \n",
       "Algorithms: rf, lr merged, with GradientBoostin...             0.067901   \n",
       "Algorithms: lr, rf, gb merged, with GradientBoo...             0.055556   \n",
       "Algorithms: rf, gb merged, with GradientBoostin...             0.058642   \n",
       "Algorithms: lr, gb merged, with GradientBoostin...             0.055556   \n",
       "Algorithms: rf, lr merged, with GradientBoostin...             0.052469   \n",
       "\n",
       "                                                    Area Under ROC Curve  \n",
       "Algorithms: lr, rf, gb merged, with LogisticReg...              0.998106  \n",
       "Algorithms: rf, gb merged, with LogisticRegression              0.996373  \n",
       "Algorithms: lr, gb merged, with LogisticRegression              0.998186  \n",
       "Algorithms: rf, lr merged, with LogisticRegression              0.997569  \n",
       "Algorithms: lr, rf, gb merged, with LogisticReg...              0.987852  \n",
       "Algorithms: rf, gb merged, with LogisticRegress...              0.985168  \n",
       "Algorithms: lr, gb merged, with LogisticRegress...              0.984063  \n",
       "Algorithms: rf, lr merged, with LogisticRegress...              0.985733  \n",
       "Algorithms: lr, rf, gb merged, with RandomFores...              0.997964  \n",
       "Algorithms: rf, gb merged, with RandomForestCla...              0.996386  \n",
       "Algorithms: lr, gb merged, with RandomForestCla...              0.997932  \n",
       "Algorithms: rf, lr merged, with RandomForestCla...              0.997445  \n",
       "Algorithms: lr, rf, gb merged, with RandomFores...              0.997127  \n",
       "Algorithms: rf, gb merged, with RandomForestCla...              0.994640  \n",
       "Algorithms: lr, gb merged, with RandomForestCla...              0.997018  \n",
       "Algorithms: rf, lr merged, with RandomForestCla...              0.996637  \n",
       "Algorithms: lr, rf, gb merged, with GradientBoo...              0.997022  \n",
       "Algorithms: rf, gb merged, with GradientBoostin...              0.996308  \n",
       "Algorithms: lr, gb merged, with GradientBoostin...              0.996911  \n",
       "Algorithms: rf, lr merged, with GradientBoostin...              0.996473  \n",
       "Algorithms: lr, rf, gb merged, with GradientBoo...              0.994871  \n",
       "Algorithms: rf, gb merged, with GradientBoostin...              0.997372  \n",
       "Algorithms: lr, gb merged, with GradientBoostin...              0.998220  \n",
       "Algorithms: rf, lr merged, with GradientBoostin...              0.997899  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_stacking_imbalanced_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e05466",
   "metadata": {},
   "source": [
    "This did not perform as consistently as on the balanced dataset, but a model managed to outperform everything else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f6335811",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stacking_imbalanced_best = pd.concat([results_stacking_imbalanced_best, results_stacking_imbalanced_merged.sort_values(by=['F1 Score'], ascending = [False]).head(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a7405bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stacking_imbalanced_full = pd.concat([results_stacking_imbalanced_full, results_stacking_imbalanced_merged])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e69d51b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>Area Under ROC Curve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, lr merged, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.991622</td>\n",
       "      <td>0.956386</td>\n",
       "      <td>0.947531</td>\n",
       "      <td>0.951938</td>\n",
       "      <td>0.004147</td>\n",
       "      <td>0.052469</td>\n",
       "      <td>0.997899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: lr, gb, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.991351</td>\n",
       "      <td>0.950617</td>\n",
       "      <td>0.950617</td>\n",
       "      <td>0.950617</td>\n",
       "      <td>0.004739</td>\n",
       "      <td>0.049383</td>\n",
       "      <td>0.998202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: all, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.991351</td>\n",
       "      <td>0.953416</td>\n",
       "      <td>0.947531</td>\n",
       "      <td>0.950464</td>\n",
       "      <td>0.004443</td>\n",
       "      <td>0.052469</td>\n",
       "      <td>0.998227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: rf, lr, gb, with GradientBoostingClassifier (with appended features)</th>\n",
       "      <td>0.991351</td>\n",
       "      <td>0.953416</td>\n",
       "      <td>0.947531</td>\n",
       "      <td>0.950464</td>\n",
       "      <td>0.004443</td>\n",
       "      <td>0.052469</td>\n",
       "      <td>0.998245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: all, with RandomForestClassifier</th>\n",
       "      <td>0.991351</td>\n",
       "      <td>0.953416</td>\n",
       "      <td>0.947531</td>\n",
       "      <td>0.950464</td>\n",
       "      <td>0.004443</td>\n",
       "      <td>0.052469</td>\n",
       "      <td>0.997648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms: all, with GradientBoostingClassifier</th>\n",
       "      <td>0.991081</td>\n",
       "      <td>0.944954</td>\n",
       "      <td>0.953704</td>\n",
       "      <td>0.949309</td>\n",
       "      <td>0.005332</td>\n",
       "      <td>0.046296</td>\n",
       "      <td>0.994784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Accuracy  Precision  \\\n",
       "Algorithms: rf, lr merged, with GradientBoostin...  0.991622   0.956386   \n",
       "Algorithms: lr, gb, with GradientBoostingClassi...  0.991351   0.950617   \n",
       "Algorithms: all, with GradientBoostingClassifie...  0.991351   0.953416   \n",
       "Algorithms: rf, lr, gb, with GradientBoostingCl...  0.991351   0.953416   \n",
       "Algorithms: all, with RandomForestClassifier        0.991351   0.953416   \n",
       "Algorithms: all, with GradientBoostingClassifier    0.991081   0.944954   \n",
       "\n",
       "                                                      Recall  F1 Score  \\\n",
       "Algorithms: rf, lr merged, with GradientBoostin...  0.947531  0.951938   \n",
       "Algorithms: lr, gb, with GradientBoostingClassi...  0.950617  0.950617   \n",
       "Algorithms: all, with GradientBoostingClassifie...  0.947531  0.950464   \n",
       "Algorithms: rf, lr, gb, with GradientBoostingCl...  0.947531  0.950464   \n",
       "Algorithms: all, with RandomForestClassifier        0.947531  0.950464   \n",
       "Algorithms: all, with GradientBoostingClassifier    0.953704  0.949309   \n",
       "\n",
       "                                                    False Positive Rate  \\\n",
       "Algorithms: rf, lr merged, with GradientBoostin...             0.004147   \n",
       "Algorithms: lr, gb, with GradientBoostingClassi...             0.004739   \n",
       "Algorithms: all, with GradientBoostingClassifie...             0.004443   \n",
       "Algorithms: rf, lr, gb, with GradientBoostingCl...             0.004443   \n",
       "Algorithms: all, with RandomForestClassifier                   0.004443   \n",
       "Algorithms: all, with GradientBoostingClassifier               0.005332   \n",
       "\n",
       "                                                    False Negative Rate  \\\n",
       "Algorithms: rf, lr merged, with GradientBoostin...             0.052469   \n",
       "Algorithms: lr, gb, with GradientBoostingClassi...             0.049383   \n",
       "Algorithms: all, with GradientBoostingClassifie...             0.052469   \n",
       "Algorithms: rf, lr, gb, with GradientBoostingCl...             0.052469   \n",
       "Algorithms: all, with RandomForestClassifier                   0.052469   \n",
       "Algorithms: all, with GradientBoostingClassifier               0.046296   \n",
       "\n",
       "                                                    Area Under ROC Curve  \n",
       "Algorithms: rf, lr merged, with GradientBoostin...              0.997899  \n",
       "Algorithms: lr, gb, with GradientBoostingClassi...              0.998202  \n",
       "Algorithms: all, with GradientBoostingClassifie...              0.998227  \n",
       "Algorithms: rf, lr, gb, with GradientBoostingCl...              0.998245  \n",
       "Algorithms: all, with RandomForestClassifier                    0.997648  \n",
       "Algorithms: all, with GradientBoostingClassifier                0.994784  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_stacking_imbalanced_best.sort_values(by=['F1 Score'], ascending = [False]).head(6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
